{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politeness prediction with ConvoKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a simple classifier to predict the politeness level of a request by considering the politeness strategies used, as seen in the paper [A computational approach to politeness with application to social factors](https://www.cs.cornell.edu/~cristian/Politeness.html), using ConvoKit. Note that this notebook is *not* intended to reproduce the paper results: legacy code for reproducibility is available at this [repository](https://github.com/sudhof/politeness). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import convokit\n",
    "from convokit import Corpus, User, Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from typing import List, Dict, Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: load annotated dataset\n",
    "\n",
    "We will be using the wikipedia annotations from the [Stanford Politeness Corpus](https://www.cs.cornell.edu/~cristian/Politeness.html). \n",
    "\n",
    "Code below demonstrates how to convert the original CSV file into the corpus format expected by ConvoKit, but this resultant corpus can also be directly downloaded using the helper function `download(\"wiki-politeness-annotated\")`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: annotate the corpus with politeness strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get politeness strategies for each utterance, we will first obtain dependency parses for the utterances, and then check for strategy use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Parser' from 'convokit' (/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e36e523c7ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvokit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPolitenessStrategies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Parser' from 'convokit' (/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/__init__.py)"
     ]
    }
   ],
   "source": [
    "from convokit import Parser, PolitenessStrategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding dependency parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/wiki-politeness-annotated\n"
     ]
    }
   ],
   "source": [
    "wiki_corpus = Corpus(convokit.download(\"wiki-politeness-annotated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ed6f1e285e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mannotator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwiki_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Parser' is not defined"
     ]
    }
   ],
   "source": [
    "annotator = Parser()\n",
    "wiki_corpus = annotator.fit_transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding strategy information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies()\n",
    "wiki_corpus = ps.transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how a processed utterance now look. Dependency parses are stored in `parsed`, and politeness strategies are in `politeness_strategies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utterance({'id': 629705, 'user': User([('name', 'wiki_user')]), 'root': 629705, 'reply_to': None, 'timestamp': 'NOT_RECORDED', 'text': \"Where did you learn English? How come you're taking on a third language?\", 'meta': {'Normalized Score': -1.1200492637766977, 'Binary': -1, 'Annotations': {'A2UFD1I8ZO1V4G': 13, 'A2YFPO0N4GIS25': 9, 'AYG3MF094634L': 11, 'A38WUWONC7EXTO': 11, 'A15DM9BMKZZJQ6': 5}, 'parsed': Where did you learn English? How come you're taking on a third language?, 'politeness_strategies': {'feature_politeness_==Please==': 0, 'feature_politeness_==Please_start==': 0, 'feature_politeness_==Indirect_(btw)==': 0, 'feature_politeness_==Hedges==': 0, 'feature_politeness_==Factuality==': 0, 'feature_politeness_==Deference==': 0, 'feature_politeness_==Gratitude==': 0, 'feature_politeness_==Apologizing==': 0, 'feature_politeness_==1st_person_pl.==': 0, 'feature_politeness_==1st_person==': 0, 'feature_politeness_==1st_person_start==': 0, 'feature_politeness_==2nd_person==': 1, 'feature_politeness_==2nd_person_start==': 0, 'feature_politeness_==Indirect_(greeting)==': 0, 'feature_politeness_==Direct_question==': 1, 'feature_politeness_==Direct_start==': 0, 'feature_politeness_==SUBJUNCTIVE==': 0, 'feature_politeness_==INDICATIVE==': 0, 'feature_politeness_==HASHEDGE==': 0, 'feature_politeness_==HASPOSITIVE==': 0, 'feature_politeness_==HASNEGATIVE==': 0}}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_corpus.get_utterance(629705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to save the corpus by doing `wiki_corpus.dump(\"wiki-politeness-annotated\")` for further exploration. Note that if you do not specify a base path, data will be saved to `.convokit/saved-corpora` in your home directory by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. predict politeness \n",
    "\n",
    "We will see how a simple classifier considering the use of politeness strategies perform. Note that this is only for demonstration, and not geared towards achieving best performance. \n",
    "\n",
    "(Most of the code below are adapted from [here](https://github.com/sudhof/politeness/blob/master/scripts/train_model.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import svm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this prediction task, we will only consider the polite vs. impolite group (i.e., those with \"Binary\" field being either +1 or -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_corpus = Corpus(utterances=[utt for utt in wiki_corpus.iter_utterances() if utt.meta[\"Binary\"] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(obj_type=\"utterance\", \n",
    "                        pred_feats=[\"politeness_strategies\"], \n",
    "                        label_func=lambda utt: utt.meta['Binary'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(binary_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this classifier to predict politeness labels for Utterances. As an example, we will use some test utterances, but you can also consider use this classifier to predict on new utterances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [485293, 252109, 623560, 328144, 627508]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predicting for test utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to check predicted politeness label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test utterance:\n",
      "Blocked, templated.  Next?\n",
      "------------------------\n",
      "Result: impolite, probability estimates = [0.81661222 0.18338778]\n",
      "\n",
      "1\n",
      "test utterance:\n",
      "Stephan, what did you mean by ''\"Is English your native language? You seem to fill in a lot of things not said with your assumptions.\"'' on my talk?\n",
      "------------------------\n",
      "Result: impolite, probability estimates = [0.77826906 0.22173094]\n",
      "\n",
      "2\n",
      "test utterance:\n",
      "I see you created a nonsense article yesterday because you were bored. If I unblock you will you disrupt more?\n",
      "------------------------\n",
      "Result: polite, probability estimates = [0.37926959 0.62073041]\n",
      "\n",
      "3\n",
      "test utterance:\n",
      "I have no need to search the interwebs, all that matters is it offends people and is a violation of NPOV and MoS. \"All Wikipedia articles and other encyclopedic content must be written from a neutral point of view (NPOV), representing fairly and without bias all significant views (that have been published by reliable sources)\" - ess-eff is a bias term for a minority group of fans, put it this way: is there an SF-channel, or how often is the clichxe9 ess-eff used outside fan-groups?\n",
      "------------------------\n",
      "Result: impolite, probability estimates = [0.51026863 0.48973137]\n",
      "\n",
      "4\n",
      "test utterance:\n",
      "I responded to your talk page comment, encouraging you to try your hand at reworking it.  Good analysis of a potential problem, so why not take a whack at it?\n",
      "------------------------\n",
      "Result: polite, probability estimates = [0.27921517 0.72078483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2label = {1: \"polite\", 0: \"impolite\"}\n",
    "\n",
    "for i, idx in enumerate(test_ids):\n",
    "    print(i)\n",
    "    test_utt = binary_corpus.get_utterance(idx)\n",
    "    \n",
    "    print(\"test utterance:\\n{}\".format(test_utt.text))\n",
    "    print(\"------------------------\")\n",
    "    y_pred, y_prob = classifier.evaluate(obj=test_utt)\n",
    "    \n",
    "    print(\"Result: {}, probability estimates = {}\\n\".format(pred2label[y_pred[0]], y_prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that this is an implementation of a politeness classifier is trained on a specific dataset (wikipedia) and on a specific binarization of politeness classes. Depending on your scenario, you might find it is preferable to directly use the politeness strategies, as exemplified in the [conversations gone awry example](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/conversations-gone-awry/Conversations_Gone_Awry_Prediction.ipynb), rather than a politeness label/score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
