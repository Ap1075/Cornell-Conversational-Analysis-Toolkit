{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "from convokit import TextParser, TensorDecomposer, Corpus, download\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from convokit import download\n",
    "from convokit.prompt_types import PromptTypeWrapper\n",
    "from convokit import PolitenessStrategies\n",
    "from convokit import Corpus\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/examples/conversations-gone-awry/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "awry_corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 2010\n",
      "Number of Utterances: 6363\n",
      "Number of Conversations: 1168\n"
     ]
    }
   ],
   "source": [
    "awry_corpus = awry_corpus.filter_conversations_by(lambda convo: convo.meta['annotation_year'] == '2018')\n",
    "awry_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/wiki-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py:1069: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n"
     ]
    }
   ],
   "source": [
    "full_corpus = Corpus(download('wiki-corpus'))\n",
    "full_corpus.load_info('utterance',['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/prompt_types/promptTypeWrapper.py:52: FutureWarning: get_info() is deprecated and will be removed in a future release. Use retrieve_meta() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/391294 utterances processed\n",
      "20000/391294 utterances processed\n",
      "30000/391294 utterances processed\n",
      "40000/391294 utterances processed\n",
      "50000/391294 utterances processed\n",
      "60000/391294 utterances processed\n",
      "70000/391294 utterances processed\n",
      "80000/391294 utterances processed\n",
      "90000/391294 utterances processed\n",
      "100000/391294 utterances processed\n",
      "110000/391294 utterances processed\n",
      "120000/391294 utterances processed\n",
      "130000/391294 utterances processed\n",
      "140000/391294 utterances processed\n",
      "150000/391294 utterances processed\n",
      "160000/391294 utterances processed\n",
      "170000/391294 utterances processed\n",
      "180000/391294 utterances processed\n",
      "190000/391294 utterances processed\n",
      "200000/391294 utterances processed\n",
      "210000/391294 utterances processed\n",
      "220000/391294 utterances processed\n",
      "230000/391294 utterances processed\n",
      "240000/391294 utterances processed\n",
      "250000/391294 utterances processed\n",
      "260000/391294 utterances processed\n",
      "270000/391294 utterances processed\n",
      "280000/391294 utterances processed\n",
      "290000/391294 utterances processed\n",
      "300000/391294 utterances processed\n",
      "310000/391294 utterances processed\n",
      "320000/391294 utterances processed\n",
      "330000/391294 utterances processed\n",
      "340000/391294 utterances processed\n",
      "350000/391294 utterances processed\n",
      "360000/391294 utterances processed\n",
      "370000/391294 utterances processed\n",
      "380000/391294 utterances processed\n",
      "390000/391294 utterances processed\n",
      "391294/391294 utterances processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/prompt_types/promptTypeWrapper.py:54: FutureWarning: get_info() is deprecated and will be removed in a future release. Use retrieve_meta() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/391294 utterances processed\n",
      "20000/391294 utterances processed\n",
      "30000/391294 utterances processed\n",
      "40000/391294 utterances processed\n",
      "50000/391294 utterances processed\n",
      "60000/391294 utterances processed\n",
      "70000/391294 utterances processed\n",
      "80000/391294 utterances processed\n",
      "90000/391294 utterances processed\n",
      "100000/391294 utterances processed\n",
      "110000/391294 utterances processed\n",
      "120000/391294 utterances processed\n",
      "130000/391294 utterances processed\n",
      "140000/391294 utterances processed\n",
      "150000/391294 utterances processed\n",
      "160000/391294 utterances processed\n",
      "170000/391294 utterances processed\n",
      "180000/391294 utterances processed\n",
      "190000/391294 utterances processed\n",
      "200000/391294 utterances processed\n",
      "210000/391294 utterances processed\n",
      "220000/391294 utterances processed\n",
      "230000/391294 utterances processed\n",
      "240000/391294 utterances processed\n",
      "250000/391294 utterances processed\n",
      "260000/391294 utterances processed\n"
     ]
    }
   ],
   "source": [
    "pt_model = PromptTypeWrapper(n_types=6, use_prompt_motifs=False, root_only=False,\n",
    "                            questions_only=False, enforce_caps=False, min_support=20, min_df=100,\n",
    "                            svd__n_components=50, max_dist=1., random_state=1000)\n",
    "pt_model.fit(full_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model.summarize(full_corpus, k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_NAMES = ['Prompt: Casual', 'Prompt: Moderation', 'Prompt: Coordination', 'Prompt: Contention',\n",
    "             'Prompt: Editing', 'Prompt: Procedures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awry_corpus = pt_model.transform(awry_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
