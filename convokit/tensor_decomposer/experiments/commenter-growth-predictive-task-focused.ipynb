{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, HyperConvo, TensorDecomposer, download, Classifier\n",
    "from convokit import extract_feats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download the reddit corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/reddit-corpus\n"
     ]
    }
   ],
   "source": [
    "# corpus = Corpus(filename=\"convokit/thread_generator/fake-corpus-trajectory-40\")\n",
    "# corpus = Corpus(filename=\"convokit/thread_generator/annotated-fake-trajectory-40\")\n",
    "corpus = Corpus(download('reddit-corpus'))\n",
    "# corpus = Corpus(filename=\"convokit/tensor_decomposer/experiments/reddit-trajectory-subset-annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 521777\n",
      "Number of Utterances: 2004262\n",
      "Number of Conversations: 84979\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = set(corpus.get_conversation_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Utterance, Speaker\n",
    "filler_utts = [Utterance(id=cid, conversation_id=cid, speaker=Speaker(id='534rehwh3h')) for cid in convo_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in filler_utts:\n",
    "    utt.timestamp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x1354b46d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.add_utterances(filler_utts, warnings=True, with_checks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84979"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_convos = {c.id for c in corpus.iter_conversations() if c.check_integrity(verbose=False)}\n",
    "len(full_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_comment_ids = [utt.id for utt in corpus.iter_utterances() if utt.reply_to in convo_ids]\n",
    "corpus = corpus.reindex_conversations(top_level_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 521777\n",
      "Number of Utterances: 2004262\n",
      "Number of Conversations: 100000\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_statsary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "longest_path_ids = []\n",
    "for convo in corpus.iter_conversations():\n",
    "    longest_path = random.choice(convo.get_longest_paths())\n",
    "    convo.meta['longest_path'] = len(longest_path)\n",
    "    longest_path_ids.extend([utt.id for utt in longest_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_path_ids = set(longest_path_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lengths = [convo.meta['longest_path'] for convo in corpus.iter_conversations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b7f41910>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import seaborn as sns\n",
    "sns.countplot(path_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.filter_utterances_by(lambda utt: utt.id in longest_path_ids and \n",
    "                                     utt.get_conversation().meta['longest_path'] >= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 129207\n",
      "Number of Utterances: 508962\n",
      "Number of Conversations: 45881\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dump('reddit-focused-8', base_path='convokit/tensor_decomposer/experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('convokit/tensor_decomposer/experiments/reddit-focused-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnOddSmith\n",
      "    JdPhoenix\n",
      "        PG-13_Woodhouse\n",
      "            JdPhoenix\n",
      "                PG-13_Woodhouse\n",
      "                    Ilyak1986\n",
      "                        PG-13_Woodhouse\n",
      "                            Ilyak1986\n",
      "                                PG-13_Woodhouse\n"
     ]
    }
   ],
   "source": [
    "corpus.random_conversation().print_conversation_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_range = range(2, 7+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def multi_hyperconv_transform(corpus, hyperconv_range):\n",
    "    hc_transformers = [HyperConvo(prefix_len=i, feat_name=\"hyperconvo-{}\".format(i), invalid_val=-1) for i in hyperconv_range]\n",
    "    for idx, hc in enumerate(list(reversed(hc_transformers))):\n",
    "        print(hyperconv_range[-1]-idx)\n",
    "        hc.transform(corpus)\n",
    "multi_hyperconv_transform(corpus, hyperconv_range)\n",
    "# corpus.dump('annotated-fake-trajectory-40', base_path=\"convokit/thread_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grown = 0\n",
    "thresh = 1.5\n",
    "for convo in corpus.iter_conversations(lambda convo: convo.meta['longest_path'] >= 14):\n",
    "    utts16 = convo.get_chronological_utterance_list()[:14]\n",
    "    utts8 = utts16[:7]\n",
    "    num_spkrs_8 = len(set(utt.speaker.id for utt in utts8))\n",
    "    num_spkrs_16 = len(set(utt.speaker.id for utt in utts16))\n",
    "    convo.meta['grown'] = (num_spkrs_16 / num_spkrs_8) >= thresh\n",
    "    grown += (num_spkrs_16 / num_spkrs_8) >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(corpus.iter_conversations(lambda convo: convo.meta['longest_path'] >= 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Classifier\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = Pipeline([(\"standardScaler\", StandardScaler(with_mean=False)),\n",
    "                            (\"logreg\", LogisticRegression(solver='liblinear'))])\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "\n",
    "pca = PCA(n_components=20, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperconvo classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(obj_type=\"conversation\", pred_feats=['hyperconvo-7'], labeller=lambda convo: convo.meta['grown'],\n",
    "                clf_feat_name='hyperconv-pred', clf_prob_feat_name='hyperconv-pred-score',  clf=model\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "long14 = lambda convo: convo.meta['longest_path'] >= 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf.evaluate_with_cv(corpus, selector=long14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000559759219151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.classifier.Classifier at 0x187559e50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(corpus, selector=long14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-7\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X = csr_matrix(feats_df.values.astype('float64'))\n",
    "y = np.array([convo.meta['grown'] for convo in corpus.iter_conversations(selector=long14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(X[train], y[train])\n",
    "    predict_proba = model.predict_proba(X[test])\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232041817116005\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "X = scale(X.toarray())\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    model.fit(pca.fit_transform(X[train]), y[train])\n",
    "    predict_proba = model.predict_proba(pca.transform(X[test]))\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged rep: HC-2 to HC-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations(long14):\n",
    "    d = defaultdict(int)\n",
    "    for idx in hyperconv_range:\n",
    "        for k, v in convo.meta['hyperconvo-{}'.format(idx)].items():\n",
    "            d[k] += v\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        d[k] = v / len(hyperconv_range)\n",
    "    convo.meta['hyperconvo-avg'] = dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-avg\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X = csr_matrix(feats_df.values.astype('float64'))\n",
    "y = np.array([convo.meta['grown'] for convo in corpus.iter_conversations(selector=long14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234789264619349\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "X = scale(X.toarray())\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(X[train], y[train])\n",
    "    predict_proba = model.predict_proba(X[test])\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6237111883866623\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(pca.fit_transform(X[train]), y[train])\n",
    "    predict_proba = model.predict_proba(pca.transform(X[test]))\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated rep: HC-2 to HC-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations(long14):\n",
    "    d = dict()\n",
    "    for idx in hyperconv_range:\n",
    "        for k, v in convo.meta['hyperconvo-{}'.format(idx)].items():\n",
    "            d[k+str(idx)] = v\n",
    "    \n",
    "    convo.meta['hyperconvo-concat'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-concat\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X = csr_matrix(feats_df.values.astype('float64'))\n",
    "y = np.array([convo.meta['grown'] for convo in corpus.iter_conversations(selector=long14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6172415691895714\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "X = scale(X.toarray())\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(pca.fit_transform(X[train]), y[train])\n",
    "    predict_proba = model.predict_proba(pca.transform(X[test]))\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank-20 non-negative TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "def scale_by_comment_idx(tensor):\n",
    "    tensor = tensor.copy()\n",
    "    for i in range(tensor.shape[0]):\n",
    "        tensor[i, :, :] = scale(tensor[i, :, :])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDecomposer(obj_type=\"conversation\",\n",
    "                      feature_set=[\"hyperconvo-{}\".format(i) for i in range(2, 7)],\n",
    "                      group_func=lambda convo: convo.get_utterance(convo.id).meta['subreddit'],\n",
    "                      rank=20, tensor_func='tensortools-ncp-bcd', normalize_func=scale_by_comment_idx\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tensor...Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing tensor...NCP_BCD: iteration 1, objective 0.9752328449871601, improvement inf.\n",
      "NCP_BCD: iteration 2, objective 0.9482366291273642, improvement 0.026996215859795947.\n",
      "NCP_BCD: iteration 3, objective 0.9281696790812498, improvement 0.020066950046114362.\n",
      "NCP_BCD: iteration 4, objective 0.9108438533747785, improvement 0.017325825706471343.\n",
      "NCP_BCD: iteration 5, objective 0.8897067825668089, improvement 0.02113707080796956.\n",
      "NCP_BCD: iteration 6, objective 0.8686007327871634, improvement 0.021106049779645475.\n",
      "NCP_BCD: iteration 7, objective 0.8521243708926308, improvement 0.01647636189453261.\n",
      "NCP_BCD: iteration 8, objective 0.8408816883387459, improvement 0.011242682553884942.\n",
      "NCP_BCD: iteration 9, objective 0.8315439231981193, improvement 0.009337765140626564.\n",
      "NCP_BCD: iteration 10, objective 0.8233344429122232, improvement 0.008209480285896076.\n",
      "NCP_BCD: iteration 11, objective 0.8167002777792959, improvement 0.006634165132927361.\n",
      "NCP_BCD: iteration 12, objective 0.8127938527489751, improvement 0.003906425030320793.\n",
      "NCP_BCD: iteration 13, objective 0.8107345011186743, improvement 0.0020593516303007986.\n",
      "NCP_BCD: iteration 14, objective 0.809140257000621, improvement 0.0015942441180533118.\n",
      "NCP_BCD: iteration 15, objective 0.8076102656008232, improvement 0.0015299913997978143.\n",
      "NCP_BCD: iteration 16, objective 0.8057577228085121, improvement 0.0018525427923110627.\n",
      "NCP_BCD: iteration 17, objective 0.803607984246603, improvement 0.0021497385619091425.\n",
      "NCP_BCD: iteration 18, objective 0.8009321417473123, improvement 0.002675842499290648.\n",
      "NCP_BCD: iteration 19, objective 0.7981979821012992, improvement 0.00273415964601309.\n",
      "NCP_BCD: iteration 20, objective 0.7961503277604297, improvement 0.002047654340869509.\n",
      "NCP_BCD: iteration 21, objective 0.7951095579892147, improvement 0.0010407697712150332.\n",
      "NCP_BCD: iteration 22, objective 0.7945866780378119, improvement 0.000522879951402766.\n",
      "NCP_BCD: iteration 23, objective 0.7939682523103774, improvement 0.0006184257274345351.\n",
      "NCP_BCD: iteration 24, objective 0.7932200778422801, improvement 0.0007481744680972735.\n",
      "NCP_BCD: iteration 25, objective 0.7924382121023709, improvement 0.0007818657399092377.\n",
      "NCP_BCD: iteration 26, objective 0.7915970947547688, improvement 0.0008411173476020606.\n",
      "NCP_BCD: iteration 27, objective 0.7906378129374716, improvement 0.0009592818172972084.\n",
      "NCP_BCD: iteration 28, objective 0.7896296080528271, improvement 0.0010082048846444813.\n",
      "NCP_BCD: iteration 29, objective 0.7887919665015853, improvement 0.0008376415512417745.\n",
      "NCP_BCD: iteration 30, objective 0.7883870159101599, improvement 0.00040495059142542367.\n",
      "NCP_BCD: iteration 31, objective 0.7882869792859972, improvement 0.00010003662416269155.\n",
      "NCP_BCD: iteration 32, objective 0.7881627754605769, improvement 0.0001242038254203326.\n",
      "NCP_BCD: iteration 33, objective 0.7880871122968633, improvement 7.566316371354631e-05.\n",
      "NCP_BCD: iteration 34, objective 0.7880299637338468, improvement 5.714856301652915e-05.\n",
      "NCP_BCD: iteration 35, objective 0.7879709471953175, improvement 5.901653852935507e-05.\n",
      "NCP_BCD: iteration 36, objective 0.7879082283558605, improvement 6.271883945696555e-05.\n",
      "NCP_BCD: iteration 37, objective 0.7878419567778683, improvement 6.627157799221628e-05.\n",
      "NCP_BCD: iteration 38, objective 0.7877715390039692, improvement 7.041777389904524e-05.\n",
      "NCP_BCD: iteration 39, objective 0.787693838951523, improvement 7.770005244622791e-05.\n",
      "NCP_BCD: iteration 40, objective 0.7876042589650554, improvement 8.95799864676361e-05.\n",
      "NCP_BCD: iteration 41, objective 0.7874967040165431, improvement 0.00010755494851222291.\n",
      "NCP_BCD: iteration 42, objective 0.7873648596882294, improvement 0.00013184432831370163.\n",
      "NCP_BCD: iteration 43, objective 0.7872113369039785, improvement 0.000153522784250959.\n",
      "NCP_BCD: iteration 44, objective 0.7870528759754157, improvement 0.00015846092856275362.\n",
      "NCP_BCD: iteration 45, objective 0.7868955022706665, improvement 0.00015737370474921963.\n",
      "NCP_BCD: iteration 46, objective 0.7867553294370513, improvement 0.00014017283361522637.\n",
      "NCP_BCD: iteration 47, objective 0.7866403475298736, improvement 0.00011498190717773582.\n",
      "NCP_BCD: iteration 48, objective 0.7865343686159088, improvement 0.0001059789139647993.\n",
      "NCP_BCD: iteration 49, objective 0.7864149427653415, improvement 0.00011942585056723409.\n",
      "NCP_BCD: iteration 50, objective 0.7862664067125866, improvement 0.00014853605275488846.\n",
      "NCP_BCD: iteration 51, objective 0.78609552159681, improvement 0.00017088511577667553.\n",
      "NCP_BCD: iteration 52, objective 0.7859367707347819, improvement 0.00015875086202810085.\n",
      "NCP_BCD: iteration 53, objective 0.7858025414447614, improvement 0.00013422929002049333.\n",
      "NCP_BCD: iteration 54, objective 0.7856602904715846, improvement 0.00014225097317677182.\n",
      "NCP_BCD: iteration 55, objective 0.7854916901595053, improvement 0.00016860031207932558.\n",
      "NCP_BCD: iteration 56, objective 0.7852885164713332, improvement 0.0002031736881720203.\n",
      "NCP_BCD: iteration 57, objective 0.7850373762196008, improvement 0.00025114025173245125.\n",
      "NCP_BCD: iteration 58, objective 0.7847023229901144, improvement 0.0003350532294863484.\n",
      "NCP_BCD: iteration 59, objective 0.7842534841535823, improvement 0.0004488388365321283.\n",
      "NCP_BCD: iteration 60, objective 0.783667135882622, improvement 0.0005863482709602685.\n",
      "NCP_BCD: iteration 61, objective 0.7829262891224951, improvement 0.0007408467601269786.\n",
      "NCP_BCD: iteration 62, objective 0.7820436550022017, improvement 0.0008826341202933241.\n",
      "NCP_BCD: iteration 63, objective 0.7811336649155274, improvement 0.0009099900866743615.\n",
      "NCP_BCD: iteration 64, objective 0.7803558444667136, improvement 0.0007778204488138041.\n",
      "NCP_BCD: iteration 65, objective 0.7797733985396512, improvement 0.0005824459270623583.\n",
      "NCP_BCD: iteration 66, objective 0.7793820761138853, improvement 0.00039132242576589427.\n",
      "NCP_BCD: iteration 67, objective 0.7791475364369609, improvement 0.000234539676924439.\n",
      "NCP_BCD: iteration 68, objective 0.779028064079923, improvement 0.0001194723570379086.\n",
      "NCP_BCD: iteration 69, objective 0.7789835896825843, improvement 4.447439733867853e-05.\n",
      "NCP_BCD: iteration 70, objective 0.7789849983757792, improvement -1.4086931948709136e-06.\n",
      "Converged after 70 iterations, 23.739093124000647 seconds. Objective: 0.7789849983757792.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.tensor_decomposer.tensorDecomposer.TensorDecomposer at 0x130c91b50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.fit(corpus, selector=lambda convo: convo.meta['longest_path'] >= 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x12f51cfd0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.transform(corpus, selector=lambda convo: convo.meta['longest_path'] >= 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import BoWClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tensor = BoWClassifier(obj_type=\"conversation\", vector_name='tensor_factor', labeller=lambda convo: convo.meta['grown'],\n",
    "                clf_feat_name='tensor-pred', clf_prob_feat_name='tensor-pred-score', clf=model\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf_tensor.evaluate_with_cv(corpus, selector=lambda convo: convo.meta['longest_path'] >= 14, cv=KFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000543819676896"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.bow_classifier.BoWClassifier at 0x1874e1350>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tensor.fit(corpus, selector=long14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, issparse\n",
    "X = []\n",
    "y = []\n",
    "for obj in corpus.iter_objs('conversation', long14):\n",
    "    X.append(obj.meta['tensor_factor'])\n",
    "    y.append(obj.meta['grown'])\n",
    "if issparse(X[0]): # for csr_matrix\n",
    "    X = vstack(X)\n",
    "else: # for non-compressed numpy arrays\n",
    "    X = np.vstack(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.615434769825202\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(X[train], y[train])\n",
    "    predict_proba = model.predict_proba(X[test])\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-7\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X_hc7 = csr_matrix(feats_df.values.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-avg\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X_hc_avg = csr_matrix(feats_df.values.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_to_feats = extract_feats_dict(corpus, \"conversation\", [\"hyperconvo-concat\"], long14)\n",
    "feats_df = pd.DataFrame.from_dict(obj_id_to_feats, orient='index').reindex(index = list(obj_id_to_feats))\n",
    "X_hc_concat = csr_matrix(feats_df.values.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, issparse\n",
    "X_tensor = []\n",
    "y = []\n",
    "for obj in corpus.iter_objs('conversation', long14):\n",
    "    X_tensor.append(obj.meta['tensor_factor'])\n",
    "if issparse(X[0]): # for csr_matrix\n",
    "    X_tensor = vstack(X_tensor)\n",
    "else: # for non-compressed numpy arrays\n",
    "    X_tensor = np.vstack(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([convo.meta['grown'] for convo in corpus.iter_conversations(long14)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperconvo-7 (PCA) + TCA (rank 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745332287375828\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "X = scale(X_hc7.toarray())\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    X_combi_train = np.hstack((pca.fit_transform(X[train]), X_tensor[train])) \n",
    "    model.fit(X_combi_train, y[train])\n",
    "    X_combi_test = np.hstack((pca.fit_transform(X[test]), X_tensor[test]))\n",
    "    predict_proba = model.predict_proba(X_combi_test)\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HC-Avg (PCA) + TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509109467616744\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "# X = scale(X_hc_avg.toarray())\n",
    "X = X_hc_avg.toarray()\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    X_combi_train = np.hstack((pca.fit_transform(X[train]), X_tensor[train])) \n",
    "    model.fit(X_combi_train, y[train])\n",
    "    X_combi_test = np.hstack((pca.fit_transform(X[test]), X_tensor[test]))\n",
    "    predict_proba = model.predict_proba(X_combi_test)\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HC-Concat (PCA) + TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.5       ,  1.        ,  0.5       ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.        ,  0.5       ,\n",
       "        0.5       ,  1.        ,  1.        ,  0.5       ,  0.5       ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.5       ,  0.5       ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.5       ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -1.        , -1.        ,\n",
       "       -1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -1.        , -1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.5       ,  1.        ,  1.        ,\n",
       "        0.5       ,  0.66666667,  1.        ,  0.66666667,  0.        ,\n",
       "        0.69314718,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.5       ,  1.        ,\n",
       "        0.66666667,  1.        ,  1.        ,  1.        ,  0.66666667,\n",
       "        0.        ,  0.        ,  0.69314718,  0.69314718,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.5       ,  1.        ,  0.5       ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.        ,  0.5       ,\n",
       "        0.5       ,  1.        ,  1.        ,  0.5       ,  0.5       ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.5       ,  0.5       ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.5       ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.33333333,  1.        ,  1.        ,\n",
       "        0.33333333,  0.75      ,  1.        ,  0.75      ,  0.        ,\n",
       "        1.09861229,  1.        ,  2.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.66666667,  0.33333333,  1.        ,  1.        ,\n",
       "        0.        ,  1.        ,  0.33333333,  0.33333333,  1.5       ,\n",
       "        0.75      ,  1.5       ,  1.        ,  1.        ,  0.75      ,\n",
       "        0.5       ,  0.        ,  0.63651417,  1.09861229,  0.5       ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  2.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.5       ,  1.        ,  1.        ,\n",
       "        0.5       ,  0.66666667,  1.        ,  0.66666667,  0.        ,\n",
       "        0.69314718,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.5       ,  1.        ,\n",
       "        0.66666667,  1.        ,  1.        ,  1.        ,  0.66666667,\n",
       "        0.        ,  0.        ,  0.69314718,  0.69314718,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.25      ,  1.        ,  1.        ,\n",
       "        0.25      ,  0.8       ,  1.        ,  0.8       ,  0.        ,\n",
       "        1.38629436,  1.        ,  2.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.5       ,  0.25      ,  2.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.25      ,  2.        ,\n",
       "        0.8       ,  2.        ,  1.        ,  1.        ,  0.8       ,\n",
       "        1.        ,  0.        ,  0.69314718,  1.38629436,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  3.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.33333333,  1.        ,  1.        ,\n",
       "        0.33333333,  0.75      ,  1.        ,  0.75      ,  0.        ,\n",
       "        1.09861229,  1.        ,  2.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.66666667,  0.33333333,  1.        ,  1.        ,\n",
       "        0.        ,  1.        ,  0.33333333,  0.33333333,  1.5       ,\n",
       "        0.75      ,  1.5       ,  1.        ,  1.        ,  0.75      ,\n",
       "        0.5       ,  0.        ,  0.63651417,  1.09861229,  0.5       ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  2.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.2       ,  1.        ,  1.        ,\n",
       "        0.2       ,  0.83333333,  1.        ,  0.83333333,  0.        ,\n",
       "        1.60943791,  1.        ,  3.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.6       ,  0.2       ,  2.        ,  1.        ,\n",
       "        0.        ,  1.        ,  0.4       ,  0.2       ,  2.5       ,\n",
       "        0.83333333,  2.5       ,  1.        ,  1.        ,  0.83333333,\n",
       "        1.        ,  0.        ,  0.67301167,  1.60943791,  0.66666667,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  4.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.25      ,  1.        ,  1.        ,\n",
       "        0.25      ,  0.8       ,  1.        ,  0.8       ,  0.        ,\n",
       "        1.38629436,  1.        ,  2.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.5       ,  0.25      ,  2.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.25      ,  2.        ,\n",
       "        0.8       ,  2.        ,  1.        ,  1.        ,  0.8       ,\n",
       "        1.        ,  0.        ,  0.69314718,  1.38629436,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  3.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.16666667,  1.        ,  1.        ,\n",
       "        0.16666667,  0.85714286,  1.        ,  0.85714286,  0.        ,\n",
       "        1.79175947,  1.        ,  3.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.5       ,  0.16666667,  3.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.5       ,  0.16666667,  3.        ,\n",
       "        0.85714286,  3.        ,  1.        ,  1.        ,  0.85714286,\n",
       "        1.        ,  0.        ,  0.69314718,  1.79175947,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  5.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.2       ,  1.        ,  1.        ,\n",
       "        0.2       ,  0.83333333,  1.        ,  0.83333333,  0.        ,\n",
       "        1.60943791,  1.        ,  3.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.6       ,  0.2       ,  2.        ,  1.        ,\n",
       "        0.        ,  1.        ,  0.4       ,  0.2       ,  2.5       ,\n",
       "        0.83333333,  2.5       ,  1.        ,  1.        ,  0.83333333,\n",
       "        1.        ,  0.        ,  0.67301167,  1.60943791,  0.66666667,\n",
       "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.5       ,  0.5       ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.69314718,  0.69314718,  1.        ,  1.        ,\n",
       "        1.        ,  4.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hc_concat.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507870116498549\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "# X = scale(X_hc_concat.toarray())\n",
    "X = X_hc_concat.toarray()\n",
    "for train, test in kfold.split(X, y):\n",
    "    X_combi_train = np.hstack((pca.fit_transform(X[train]), X_tensor[train])) \n",
    "    model.fit(X_combi_train, y[train])\n",
    "    X_combi_test = np.hstack((pca.fit_transform(X[test]), X_tensor[test]))\n",
    "    predict_proba = model.predict_proba(X_combi_test)\n",
    "    roc_scores.append(roc_auc_score(y_true=y[test], y_score=[x[1] for x in predict_proba]))\n",
    "\n",
    "print(np.mean(roc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130e01710>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(X[:, 514])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6771.20878630641"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(X[:,514]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130e4b690>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(X_hc_concat.toarray()[:, 514])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
