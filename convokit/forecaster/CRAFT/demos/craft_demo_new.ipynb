{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT demo (inference only) using ConvoKit\n",
    "\n",
    "This example notebook shows how an already-trained CRAFT model can be applied to conversational data to predict future derailment. This example uses the fully trained Wikiconv-based model as reported in the \"Trouble on the Horizon\" paper, and applies it to ConvoKit's version of the labeled Wikiconv corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Forecaster, Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "craft_model = convokit.CRAFTModel(device_type=\"cpu\", batch_size=100, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Forecaster(forecaster_model = craft_model,\n",
    "                        convo_structure=\"linear\",\n",
    "                        text_func = lambda utt: utt.meta[\"tokens\"][:(MAX_LENGTH-1)],\n",
    "                        utt_selector_func = lambda utt: not utt.meta[\"is_section_header\"],\n",
    "                        convo_selector_func = (lambda convo: convo.meta[\"split\"] == \"test\"),\n",
    "                        forecast_feat_name=\"prediction\", forecast_prob_feat_name=\"score\",\n",
    "                        skip_broken_convos=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled Wikiconv corpus from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import craft_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in corpus.iter_utterances():\n",
    "    utt.add_meta(\"tokens\", craft_tokenize(craft_model.voc, utt.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 2.3%\n",
      "Iteration: 2; Percent complete: 4.5%\n",
      "Iteration: 3; Percent complete: 6.8%\n",
      "Iteration: 4; Percent complete: 9.1%\n",
      "Iteration: 5; Percent complete: 11.4%\n",
      "Iteration: 6; Percent complete: 13.6%\n",
      "Iteration: 7; Percent complete: 15.9%\n",
      "Iteration: 8; Percent complete: 18.2%\n",
      "Iteration: 9; Percent complete: 20.5%\n",
      "Iteration: 10; Percent complete: 22.7%\n",
      "Iteration: 11; Percent complete: 25.0%\n",
      "Iteration: 12; Percent complete: 27.3%\n",
      "Iteration: 13; Percent complete: 29.5%\n",
      "Iteration: 14; Percent complete: 31.8%\n",
      "Iteration: 15; Percent complete: 34.1%\n",
      "Iteration: 16; Percent complete: 36.4%\n",
      "Iteration: 17; Percent complete: 38.6%\n",
      "Iteration: 18; Percent complete: 40.9%\n",
      "Iteration: 19; Percent complete: 43.2%\n",
      "Iteration: 20; Percent complete: 45.5%\n",
      "Iteration: 21; Percent complete: 47.7%\n",
      "Iteration: 22; Percent complete: 50.0%\n",
      "Iteration: 23; Percent complete: 52.3%\n",
      "Iteration: 24; Percent complete: 54.5%\n",
      "Iteration: 25; Percent complete: 56.8%\n",
      "Iteration: 26; Percent complete: 59.1%\n",
      "Iteration: 27; Percent complete: 61.4%\n",
      "Iteration: 28; Percent complete: 63.6%\n",
      "Iteration: 29; Percent complete: 65.9%\n",
      "Iteration: 30; Percent complete: 68.2%\n",
      "Iteration: 31; Percent complete: 70.5%\n",
      "Iteration: 32; Percent complete: 72.7%\n",
      "Iteration: 33; Percent complete: 75.0%\n",
      "Iteration: 34; Percent complete: 77.3%\n",
      "Iteration: 35; Percent complete: 79.5%\n",
      "Iteration: 36; Percent complete: 81.8%\n",
      "Iteration: 37; Percent complete: 84.1%\n",
      "Iteration: 38; Percent complete: 86.4%\n",
      "Iteration: 39; Percent complete: 88.6%\n",
      "Iteration: 40; Percent complete: 90.9%\n",
      "Iteration: 41; Percent complete: 93.2%\n",
      "Iteration: 42; Percent complete: 95.5%\n",
      "Iteration: 43; Percent complete: 97.7%\n",
      "Iteration: 44; Percent complete: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x1355d8b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = forecaster.summarize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321135697.24198.24203</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543745847.6482.6482</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543744374.5479.5479</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543745021.5797.5797</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331340599.40316.40316</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321121382.23625.23625</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460109460.1971.1971</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225473649.54867.54867</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298858175.66603.66603</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460109049.1391.1391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842629999.15335.15335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372485964.3133.3133</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15645423.4447.4447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613952013.104331.104331</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115763664.26665.26665</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248545066.95711.95711</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115765271.26922.26922</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115913278.27337.27337</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361782822.25771.25771</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248030755.212669.212669</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prediction     score\n",
       "utt_id                                       \n",
       "321135697.24198.24203           1.0  0.983886\n",
       "543745847.6482.6482             1.0  0.983051\n",
       "543744374.5479.5479             1.0  0.982532\n",
       "543745021.5797.5797             1.0  0.981838\n",
       "331340599.40316.40316           1.0  0.980444\n",
       "321121382.23625.23625           1.0  0.979750\n",
       "460109460.1971.1971             1.0  0.978715\n",
       "225473649.54867.54867           1.0  0.978543\n",
       "298858175.66603.66603           1.0  0.977676\n",
       "460109049.1391.1391             1.0  0.977149\n",
       "842629999.15335.15335           1.0  0.976865\n",
       "372485964.3133.3133             1.0  0.976525\n",
       "15645423.4447.4447              1.0  0.976274\n",
       "613952013.104331.104331         1.0  0.976042\n",
       "115763664.26665.26665           1.0  0.974236\n",
       "248545066.95711.95711           1.0  0.974149\n",
       "115765271.26922.26922           1.0  0.974104\n",
       "115913278.27337.27337           1.0  0.973913\n",
       "361782822.25771.25771           1.0  0.973864\n",
       "248030755.212669.212669         1.0  0.973372"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CRAFT inference demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
