{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT demo (inference only) using ConvoKit\n",
    "\n",
    "This example notebook shows how an already-trained CRAFT model can be applied to conversational data to predict future derailment. This example uses the fully trained Wikiconv-based model as reported in the \"Trouble on the Horizon\" paper, and applies it to ConvoKit's version of the labeled Wikiconv corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Forecaster, Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "craft_model = convokit.CRAFTModel(device_type=\"cpu\", batch_size=100, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Forecaster(forecaster_model = craft_model,\n",
    "                        convo_structure=\"linear\",\n",
    "                        text_func = lambda utt: utt.meta[\"tokens\"][:(MAX_LENGTH-1)],\n",
    "                        utt_selector_func = lambda utt: not utt.meta[\"is_section_header\"],\n",
    "                        convo_selector_func = (lambda convo: convo.meta[\"split\"] == \"test\"),\n",
    "                        forecast_feat_name=\"prediction\", forecast_prob_feat_name=\"score\",\n",
    "                        skip_broken_convos=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled Wikiconv corpus from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import craft_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in corpus.iter_utterances():\n",
    "    utt.add_meta(\"tokens\", craft_tokenize(craft_model.voc, utt.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 2.3%\n",
      "Iteration: 2; Percent complete: 4.5%\n",
      "Iteration: 3; Percent complete: 6.8%\n",
      "Iteration: 4; Percent complete: 9.1%\n",
      "Iteration: 5; Percent complete: 11.4%\n",
      "Iteration: 6; Percent complete: 13.6%\n",
      "Iteration: 7; Percent complete: 15.9%\n",
      "Iteration: 8; Percent complete: 18.2%\n",
      "Iteration: 9; Percent complete: 20.5%\n",
      "Iteration: 10; Percent complete: 22.7%\n",
      "Iteration: 11; Percent complete: 25.0%\n",
      "Iteration: 12; Percent complete: 27.3%\n",
      "Iteration: 13; Percent complete: 29.5%\n",
      "Iteration: 14; Percent complete: 31.8%\n",
      "Iteration: 15; Percent complete: 34.1%\n",
      "Iteration: 16; Percent complete: 36.4%\n",
      "Iteration: 17; Percent complete: 38.6%\n",
      "Iteration: 18; Percent complete: 40.9%\n",
      "Iteration: 19; Percent complete: 43.2%\n",
      "Iteration: 20; Percent complete: 45.5%\n",
      "Iteration: 21; Percent complete: 47.7%\n",
      "Iteration: 22; Percent complete: 50.0%\n",
      "Iteration: 23; Percent complete: 52.3%\n",
      "Iteration: 24; Percent complete: 54.5%\n",
      "Iteration: 25; Percent complete: 56.8%\n",
      "Iteration: 26; Percent complete: 59.1%\n",
      "Iteration: 27; Percent complete: 61.4%\n",
      "Iteration: 28; Percent complete: 63.6%\n",
      "Iteration: 29; Percent complete: 65.9%\n",
      "Iteration: 30; Percent complete: 68.2%\n",
      "Iteration: 31; Percent complete: 70.5%\n",
      "Iteration: 32; Percent complete: 72.7%\n",
      "Iteration: 33; Percent complete: 75.0%\n",
      "Iteration: 34; Percent complete: 77.3%\n"
     ]
    }
   ],
   "source": [
    "forecaster.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = forecaster.summarize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CRAFT inference demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
