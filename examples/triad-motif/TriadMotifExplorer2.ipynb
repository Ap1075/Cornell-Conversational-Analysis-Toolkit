{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/calebchiam/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/reddit-corpus-small\n"
     ]
    }
   ],
   "source": [
    "corpus = convokit.Corpus(filename=convokit.download(\"reddit-corpus-small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = corpus.utterance_threads(prefix_len=10, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'e58slx0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = convokit.HyperConvo(prefix_len=10, min_thread_len=10, include_root=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_motifs = hc.retrieve_motifs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_motif_path_stats = hc.retrieve_motif_pathway_stats(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b88c1d77e404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mend_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mend_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for thread_id, path_dict in threads_motifs.items():\n",
    "    if thread_motif_path_stats[thread_id][('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'INCOMING_TRIADS')] >= 1 and \\\n",
    "    thread_motif_path_stats[thread_id][('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'INCOMING_TRIADS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif2 = path_dict[('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'DYADIC_TRIADS', 'INCOMING_1TO3_TRIADS', 'DIRECIPROCAL_TRIADS', 'DIRECIPROCAL_2TO3_TRIADS')][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = threads['t1_c2zdwxx']\n",
    "hg = hc._make_hypergraph(uts=spec)\n",
    "hg.extract_motifs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif3 = hg.extract_motifs()['DIRECIPROCAL_2TO3_TRIADS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_motif(motif3, text_limit=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_motif(motif3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_motif(motif3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_motif(motif1, text_limit = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_motif(motif1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relaxing conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the math, we find that we have 1220 motifs with triadic closure. Probably a fair bit less if we exclude motifs that have edges with deleted texts. Let's relax the condition by having the \"User posting a top level comment\" be relaxed to \"User posting any comment\" and having two other Users respond to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict2 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for motif_type, motif_instances in triad_dict.items():\n",
    "    for motif_instance in motif_instances:\n",
    "        if len(motif_instance.edges) == 0: continue \n",
    "        num_replies_to_root = 0\n",
    "        \n",
    "        utts_replied_to = [edge_set[0]['reply_to'] for edge_set in motif_instance.edges]\n",
    "        if max(Counter(utts_replied_to).values()) == 2:\n",
    "            path_dict2[get_development_path(motif_instance)].append(motif_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the machinery to do more interesting analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_paths(path_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(path_dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2 = {k: len(v) for k, v in path_dict2.items()}\n",
    "end_state = defaultdict(int)\n",
    "for path, count in pd2.items():\n",
    "    end_state[path[-1]] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in path_dict2:\n",
    "    print(path)\n",
    "    print(len(path_dict2[path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding non-triadic closure motifs, this gives a total of 2046 motifs with triadic closure to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we filter out [deleted]'s, we remove 614 motif instances, giving us 1432 motifs to work with. (Filtering step not shown here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_deleted_text(motif_inst):\n",
    "    for edge in motif_inst.edges:\n",
    "        if edge[0]['text'] == \"[deleted]\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize some of these to verify correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path, instances in path_dict2_trunc.items():\n",
    "#     motif_a = instances[0]\n",
    "#     print(motif_a.edges[0][0]['top_level_comment'])\n",
    "#     viz_motif(motif_a, text_limit=40)\n",
    "#     replay_motif(motif_a)\n",
    "#     print()\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can predict when triadic closure happens. As triadic closure happens at different points in a triad's development, we have to take care to compare like-to-like and that we are examining the same kind of triadic closure; incoming / unidirectional / outgoing -> incoming_2to3 are three different types of triadic closure, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus more on the '2to3' type of triadic closure, as in: \n",
    "- incoming -> incoming_2to3 \n",
    "- direciprocal -> direciprocal_2to3\n",
    "- incoming_1to3 -> outgoing_reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in path_dict2_trunc:\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incoming vs incoming_2to3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_motifs['t1_c2yz6ed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dict of thread_ids to motifs (disambiguated by paths)\n",
    "threads_paths = defaultdict(dict)\n",
    "for thread, motif_dict in threads_motifs.items():\n",
    "    for motif_type_instances in motif_dict.values():\n",
    "        for motif_inst in motif_type_instances:\n",
    "            path = get_development_path(motif_inst)\n",
    "            if path not in threads_motifs[thread]:\n",
    "                threads_paths[thread][path] = [motif_inst]\n",
    "            else:\n",
    "                threads_paths[thread][path].append(motif_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responds_to_same_utt(motif_instance):\n",
    "    utts_replied_to = [edge_set[0]['reply_to'] for edge_set in motif_instance.edges]\n",
    "    return max(Counter(utts_replied_to).values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_pos_neg(threads_paths, pos_types, neg_types):\n",
    "    pos, neg = [], []\n",
    "    for thread, paths in threads_paths.items(): # thread is top-level-comment\n",
    "#         print(paths)\n",
    "        pos_instances = [triad_instance for pos_type in pos_types for triad_instance in paths.get(pos_type, []) \n",
    "                         if not has_deleted_text(triad_instance) and responds_to_same_utt(triad_instance)]\n",
    "        neg_instances = [triad_instance for neg_type in neg_types for triad_instance in paths.get(neg_type, []) \n",
    "                         if not has_deleted_text(triad_instance) and responds_to_same_utt(triad_instance)]\n",
    "        \n",
    "#         print(len(pos_instances), len(neg_instances))\n",
    "        if len(pos_instances) == 0 or len(neg_instances) == 0: continue\n",
    "        \n",
    "        pos.append(random.choice(pos_instances))\n",
    "        neg.append(random.choice(neg_instances))\n",
    "        \n",
    "    print(\"- {} positive, {} negative pts\".format(len(pos), len(neg)))  \n",
    "    return pos, neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_types = []\n",
    "for k in pd2:\n",
    "    if str(k).startswith(\"('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'INCOMING_TRIADS', 'INCOMING_2TO3_TRIADS'\"):\n",
    "        pos_types.append(k)\n",
    "pos_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = generate_pos_neg(threads_paths, \n",
    "                            pos_types = pos_types, \n",
    "                            neg_types = [('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'INCOMING_TRIADS')]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_motif(random.choice(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [1]*len(pos) + [0]*len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "motifs_text = []\n",
    "for motif_inst in pos + neg:\n",
    "    # BOW baseline text\n",
    "    # motif_text taken from first two edges\n",
    "    time_sorted_edges = sorted([e[0] for e in motif_inst.edges], key=lambda x: x['timestamp'])\n",
    "    text1 = \" \".join([\"1_\"+w for w in time_sorted_edges[0]['text'].split(\" \")])\n",
    "    text2 = \" \".join([\"2_\"+w for w in time_sorted_edges[1]['text'].split(\" \")])\n",
    "    motif_text = text1 + \" \" + text2\n",
    "    motifs_text.append(motif_text)\n",
    "    \n",
    "text_train, text_test, y_train, y_test = train_test_split(motifs_text, ys, test_size=0.3, random_state=42)\n",
    "cv = CountVectorizer(min_df=0.05, max_df=0.8, ngram_range=(1, 3)) # excluding stop_words field improves performance\n",
    "X_train = cv.fit_transform(text_train)\n",
    "X_test = cv.transform(text_test)\n",
    "        \n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "print(\"- BOW: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_coefs = sorted(list(zip(cv.get_feature_names(), clf.coef_[0])), key=lambda x: abs(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time diff between first/second edge, length of first edge text, length of second edge text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_motif(motif_inst):\n",
    "    time_sorted_edges = sorted([e[0] for e in motif_inst.edges], key=lambda x: x['timestamp'])\n",
    "    time_diff = time_sorted_edges[1]['timestamp'] - time_sorted_edges[0]['timestamp']\n",
    "    num_words_1 = len(list(time_sorted_edges[0]['text'].split(\" \")))\n",
    "    num_words_2 = len(list(time_sorted_edges[1]['text'].split(\" \")))\n",
    "    return [time_diff, num_words_1, num_words_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "for motif_inst in pos + neg:\n",
    "    X2.append(get_features_from_motif(motif_inst))\n",
    "\n",
    "X2 = np.array(X2)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, ys, test_size=0.2, random_state=42)\n",
    "        \n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X2_train, y2_train)\n",
    "\n",
    "train_acc = clf.score(X2_train, y2_train)\n",
    "test_acc = clf.score(X2_test, y2_test)\n",
    "print(\"- Basic features: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW + Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "for motif_inst in pos + neg:\n",
    "    X2.append(get_features_from_motif(motif_inst))\n",
    "\n",
    "X_combi = list(zip(motifs_text, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combi, ys, test_size=0.2, random_state=42)\n",
    "cv = CountVectorizer(min_df=0.05, max_df=0.8, ngram_range=(1,2)) \n",
    "X_bow_train = cv.fit_transform([x[0] for x in X_train]).todense()\n",
    "X_bow_test = cv.transform([x[0] for x in X_test]).todense()\n",
    "\n",
    "X_combi_train = []\n",
    "X_combi_test = []\n",
    "# print(X_bow_train[0].tolist()[0])\n",
    "\n",
    "for row in range(len(X_train)):\n",
    "    X_combi_train.append(X_bow_train[row].tolist()[0] + X_train[row][1])\n",
    "\n",
    "for row in range(len(X_test)):\n",
    "    X_combi_test.append(X_bow_test[row].tolist()[0] + X_test[row][1])\n",
    "\n",
    "X_combi_train = np.array(X_combi_train)\n",
    "X_combi_test = np.array(X_combi_test)\n",
    "# print(X_combi_train)\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_combi_train, y_train)\n",
    "\n",
    "print(X_combi_train.shape)\n",
    "\n",
    "train_acc = clf.score(X_combi_train, y_train)\n",
    "test_acc = clf.score(X_combi_test, y_test)\n",
    "print(\"- Combined: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tightening conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No better than chance. Maybe if we focus on those that include the User that posts a top-level-comment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responds_to_same_toplvlcomm(motif_instance):\n",
    "    num_replies_to_root = 0\n",
    "    for edge_set in motif_instance.edges:\n",
    "        if edge_set[0]['root']: \n",
    "            num_replies_to_root += 1\n",
    "    return num_replies_to_root==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_neg2(threads_paths, pos_types, neg_types):\n",
    "    pos, neg = [], []\n",
    "    for thread in threads_paths: # thread is top-level-comment\n",
    "        paths = threads_paths[thread]\n",
    "#         print(paths)\n",
    "        pos_instances = [triad_instance for pos_type in pos_types for triad_instance in paths.get(pos_type, []) \n",
    "                         if not has_deleted_text(triad_instance) and responds_to_same_toplvlcomm(triad_instance)]\n",
    "        neg_instances = [triad_instance for neg_type in neg_types for triad_instance in paths.get(neg_type, []) \n",
    "                         if not has_deleted_text(triad_instance) and responds_to_same_toplvlcomm(triad_instance)]\n",
    "        \n",
    "#         print(len(pos_instances), len(neg_instances))\n",
    "        if len(pos_instances) == 0 or len(neg_instances) == 0: continue\n",
    "        \n",
    "        pos.append(random.choice(pos_instances))\n",
    "        neg.append(random.choice(neg_instances))\n",
    "        \n",
    "    print(\"- {} positive, {} negative pts\".format(len(pos), len(neg)))  \n",
    "    return pos, neg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = generate_pos_neg2(threads_paths, \n",
    "                            pos_types = pos_types, \n",
    "                            neg_types = [('NO_EDGE_TRIADS', 'SINGLE_EDGE_TRIADS', 'INCOMING_TRIADS')]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [1]*len(pos) + [0]*len(neg)\n",
    "random.seed(42)\n",
    "\n",
    "motifs_text = []\n",
    "for motif_inst in pos + neg:\n",
    "    # BOW baseline text\n",
    "    # motif_text taken from first two edges\n",
    "    time_sorted_edges = sorted([e[0] for e in motif_inst.edges], key=lambda x: x['timestamp'])\n",
    "    text1 = \" \".join([w for w in time_sorted_edges[0]['text'].split(\" \")])\n",
    "    text2 = \" \".join([w for w in time_sorted_edges[1]['text'].split(\" \")])\n",
    "    motif_text = text1 + \" \" + text2\n",
    "    motifs_text.append(motif_text)\n",
    "    \n",
    "text_train, text_test, y_train, y_test = train_test_split(motifs_text, ys, test_size=0.2, random_state=42)\n",
    "cv = CountVectorizer(min_df=0.05, max_df=0.8, ngram_range=(1, 3)) # excluding stop_words field improves performance\n",
    "X_train = cv.fit_transform(text_train)\n",
    "X_test = cv.transform(text_test)\n",
    "        \n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "print(\"- BOW: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))\n",
    "\n",
    "#57% train and test accuracy (text1/text2 not distinguished, 0.05 / 0.8, no stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_coefs = sorted(list(zip(cv.get_feature_names(), clf.coef_[0])), key=lambda x: abs(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "for motif_inst in pos + neg:\n",
    "    X2.append(get_features_from_motif(motif_inst))\n",
    "\n",
    "X2 = np.array(X2)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, ys, test_size=0.3, random_state=42)\n",
    "        \n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X2_train, y2_train)\n",
    "\n",
    "train_acc = clf.score(X2_train, y2_train)\n",
    "test_acc = clf.score(X2_test, y2_test)\n",
    "print(\"- Basic features: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "for motif_inst in pos + neg:\n",
    "    X2.append(get_features_from_motif(motif_inst))\n",
    "\n",
    "X_combi = list(zip(motifs_text, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combi, ys, test_size=0.3, random_state=42)\n",
    "cv = CountVectorizer(min_df=0.05, max_df=0.8, ngram_range=(1,3)) \n",
    "X_bow_train = cv.fit_transform([x[0] for x in X_train]).todense()\n",
    "X_bow_test = cv.transform([x[0] for x in X_test]).todense()\n",
    "\n",
    "X_combi_train = []\n",
    "X_combi_test = []\n",
    "# print(X_bow_train[0].tolist()[0])\n",
    "\n",
    "for row in range(len(X_train)):\n",
    "    X_combi_train.append(X_bow_train[row].tolist()[0] + X_train[row][1])\n",
    "\n",
    "for row in range(len(X_test)):\n",
    "    X_combi_test.append(X_bow_test[row].tolist()[0] + X_test[row][1])\n",
    "\n",
    "X_combi_train = np.array(X_combi_train)\n",
    "X_combi_test = np.array(X_combi_test)\n",
    "# print(X_combi_train)\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_combi_train, y_train)\n",
    "\n",
    "print(X_combi_train.shape)\n",
    "\n",
    "train_acc = clf.score(X_combi_train, y_train)\n",
    "test_acc = clf.score(X_combi_test, y_test)\n",
    "print(\"- Combined: {:.4f} train, {:.4f} test\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
