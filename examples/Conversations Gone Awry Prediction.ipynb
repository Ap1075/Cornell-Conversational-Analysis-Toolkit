{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Conversations Gone Awry With Convokit\n",
    "\n",
    "This interactive tutorial demonstrates how to predict whether a conversation will eventually lead to a personal attack, as seen in the paper [Conversations Gone Awry: Detecting Early Signs of Conversational Failure](http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html) using the tools provided by convokit. It also serves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import json\n",
    "import itertools\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "from convokit import Corpus, QuestionTypology, download, MotifsExtractor, QuestionTypologyUtils, PolitenessStrategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Conversations Gone Awry corpus, provided as part of convokit\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\")):\n",
    "    download(\"conversations-gone-awry-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a convokit Corpus object from the downloaded data. The Corpus class provides functionality for\n",
    "# convenient manipulation of text corpora.\n",
    "awry_corpus = Corpus(filename=os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract prompt types features\n",
    "\n",
    "In this step, we will extract the first of the two types of pragmatic features seen in the paper: prompt types. We can learn prompt types and compute types for each utterance in the corpus using convokit's QuestionTypology class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train the QuestionTypology object on convokit's wiki corpus. Let's first download the corpus...\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"wiki-corpus\")):\n",
    "    download(\"wiki-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a QuestionTypology object on the downloaded wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building q-a matrices\n",
      "matrix dir /home/jonathan/research/Cornell-Conversational-Analysis-Toolkit/convokit/downloads/wiki-corpus-awry-matrix exists!\n",
      "\treading arcs and motifs\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tbuilding matrices\n",
      "\twriting stuff\n",
      "reading question tidxes\n",
      "reading question leaves\n",
      "reading answer tidxes\n",
      "reading question didxes\n",
      "reading answer didxes\n",
      "reading question terms\n",
      "reading answer terms\n",
      "reading docs\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# some parameters to get us started. Note that \"dataset name\" refers not to the name of the *source* dataset,\n",
    "# but the name we want to give to trained output files of the QuestionTypology object. We could have given\n",
    "# any name we liked - we chose \"wiki-corpus-awry\" to keep things clear.\n",
    "dataset_name = \"wiki-corpus-awry\"\n",
    "num_clusters = 6\n",
    "\n",
    "# load the wiki corpus into a convokit Corpus object\n",
    "data_dir = os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), 'downloads')\n",
    "corpus = Corpus(filename=os.path.join(data_dir, 'wiki-corpus'))\n",
    "\n",
    "# if this is our first time running this example, we need to fit motifs on the\n",
    "# dataset. If we have run it before, just load the previously computed motifs\n",
    "motifs_dir = os.path.join(data_dir, dataset_name + \"-motifs\")\n",
    "if not os.path.exists(motifs_dir):\n",
    "    motifs_dir = None\n",
    "\n",
    "questionTypology = QuestionTypology(corpus, data_dir, dataset_name=dataset_name, motifs_dir=motifs_dir,\n",
    "                                    num_dims=50, num_clusters=6, question_threshold=100, answer_threshold=100, \n",
    "                                    verbose=1000000, random_seed=2018, questions_only=False, enforce_formatting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the QuestionTypology object has been trained, we can use it to compute prompt types for our awry corpus (notice that this is a different corpus from what the QuestionTypology object was trained on!). For our purposes, we want the raw features, which are distances from the centers of the KMeans clusters corresponding to each prompt type. We can get these using the `get_qtype_dists` method. Note that in most other situations, where we want just the prompt type, we can use the QuestionTypology object as a Callable, which will return an integer prompt type for each utterance in the corpus. We could also use the `compute_type` function, which is aliased to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = questionTypology.get_qtype_dists(awry_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.940986</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.877994</td>\n",
       "      <td>0.896294</td>\n",
       "      <td>0.941438</td>\n",
       "      <td>0.920327</td>\n",
       "      <td>I notice that earier that  moved wiki_link to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.941246</td>\n",
       "      <td>1.128140</td>\n",
       "      <td>1.029870</td>\n",
       "      <td>0.962165</td>\n",
       "      <td>1.082793</td>\n",
       "      <td>0.967436</td>\n",
       "      <td>Chen was known in the poker world as \"William\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.962016</td>\n",
       "      <td>1.056367</td>\n",
       "      <td>0.907733</td>\n",
       "      <td>0.911899</td>\n",
       "      <td>1.110880</td>\n",
       "      <td>1.012163</td>\n",
       "      <td>I see what you saying I just read his pokersta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>1.060801</td>\n",
       "      <td>1.124947</td>\n",
       "      <td>1.148784</td>\n",
       "      <td>0.937019</td>\n",
       "      <td>0.975150</td>\n",
       "      <td>0.942102</td>\n",
       "      <td>No more than two editors advocated deletion.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.962161</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>1.019503</td>\n",
       "      <td>0.766240</td>\n",
       "      <td>0.976699</td>\n",
       "      <td>In the future please don't close Afds when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0.958134</td>\n",
       "      <td>1.042828</td>\n",
       "      <td>1.035856</td>\n",
       "      <td>0.942605</td>\n",
       "      <td>1.055383</td>\n",
       "      <td>0.965266</td>\n",
       "      <td>That simply isn't true.  If you read the comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.946467</td>\n",
       "      <td>1.066047</td>\n",
       "      <td>0.869980</td>\n",
       "      <td>0.832726</td>\n",
       "      <td>1.119957</td>\n",
       "      <td>1.008414</td>\n",
       "      <td>Somehow, I suspect you may wish to participate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.969626</td>\n",
       "      <td>0.884449</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>1.009570</td>\n",
       "      <td>0.653972</td>\n",
       "      <td>0.943597</td>\n",
       "      <td>I assume your deliberate lying has a point, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.092351</td>\n",
       "      <td>1.014784</td>\n",
       "      <td>1.203938</td>\n",
       "      <td>1.131129</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>1.007752</td>\n",
       "      <td>== Could you stop reverting my corrections ==\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.945306</td>\n",
       "      <td>0.722245</td>\n",
       "      <td>0.857123</td>\n",
       "      <td>1.035595</td>\n",
       "      <td>0.798275</td>\n",
       "      <td>0.988061</td>\n",
       "      <td>If you have problems with my edits to the 4WD ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.940986   0.979943   0.877994   0.896294   0.941438   \n",
       "146842219.12874.12874   0.941246   1.128140   1.029870   0.962165   1.082793   \n",
       "146860774.13072.13072   0.962016   1.056367   0.907733   0.911899   1.110880   \n",
       "143890867.11944.11926   1.060801   1.124947   1.148784   0.937019   0.975150   \n",
       "143902946.11991.11991   0.962161   0.853946   0.955107   1.019503   0.766240   \n",
       "143945536.12065.12065   0.958134   1.042828   1.035856   0.942605   1.055383   \n",
       "144052463.12169.12169   0.946467   1.066047   0.869980   0.832726   1.119957   \n",
       "144065917.12226.12226   0.969626   0.884449   0.964716   1.009570   0.653972   \n",
       "127296808.516.516       1.092351   1.014784   1.203938   1.131129   0.693798   \n",
       "127296808.534.516       0.945306   0.722245   0.857123   1.035595   0.798275   \n",
       "\n",
       "                       km_5_dist  \\\n",
       "146743638.12667.12652   0.920327   \n",
       "146842219.12874.12874   0.967436   \n",
       "146860774.13072.13072   1.012163   \n",
       "143890867.11944.11926   0.942102   \n",
       "143902946.11991.11991   0.976699   \n",
       "143945536.12065.12065   0.965266   \n",
       "144052463.12169.12169   1.008414   \n",
       "144065917.12226.12226   0.943597   \n",
       "127296808.516.516       1.007752   \n",
       "127296808.534.516       0.988061   \n",
       "\n",
       "                                                                 content  \n",
       "146743638.12667.12652  I notice that earier that  moved wiki_link to ...  \n",
       "146842219.12874.12874  Chen was known in the poker world as \"William\"...  \n",
       "146860774.13072.13072  I see what you saying I just read his pokersta...  \n",
       "143890867.11944.11926  No more than two editors advocated deletion.  ...  \n",
       "143902946.11991.11991  In the future please don't close Afds when you...  \n",
       "143945536.12065.12065  That simply isn't true.  If you read the comme...  \n",
       "144052463.12169.12169  Somehow, I suspect you may wish to participate...  \n",
       "144065917.12226.12226  I assume your deliberate lying has a point, bu...  \n",
       "127296808.516.516        == Could you stop reverting my corrections ==\\n  \n",
       "127296808.534.516      If you have problems with my edits to the 4WD ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at what the output looks like\n",
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a little bit of cleaning up of the prompt types table. First off, we don't need the content column, as we are just interested in using the prompt type features themselves. Second, in the paper we assigned a max distance cutoff, such that distances were capped at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = prompt_types.drop(columns=\"content\")\n",
    "prompt_types[prompt_types > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.940986</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.877994</td>\n",
       "      <td>0.896294</td>\n",
       "      <td>0.941438</td>\n",
       "      <td>0.920327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.941246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.962016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907733</td>\n",
       "      <td>0.911899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937019</td>\n",
       "      <td>0.975150</td>\n",
       "      <td>0.942102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.962161</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766240</td>\n",
       "      <td>0.976699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0.958134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.946467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869980</td>\n",
       "      <td>0.832726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.969626</td>\n",
       "      <td>0.884449</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653972</td>\n",
       "      <td>0.943597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.945306</td>\n",
       "      <td>0.722245</td>\n",
       "      <td>0.857123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798275</td>\n",
       "      <td>0.988061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.940986   0.979943   0.877994   0.896294   0.941438   \n",
       "146842219.12874.12874   0.941246   1.000000   1.000000   0.962165   1.000000   \n",
       "146860774.13072.13072   0.962016   1.000000   0.907733   0.911899   1.000000   \n",
       "143890867.11944.11926   1.000000   1.000000   1.000000   0.937019   0.975150   \n",
       "143902946.11991.11991   0.962161   0.853946   0.955107   1.000000   0.766240   \n",
       "143945536.12065.12065   0.958134   1.000000   1.000000   0.942605   1.000000   \n",
       "144052463.12169.12169   0.946467   1.000000   0.869980   0.832726   1.000000   \n",
       "144065917.12226.12226   0.969626   0.884449   0.964716   1.000000   0.653972   \n",
       "127296808.516.516       1.000000   1.000000   1.000000   1.000000   0.693798   \n",
       "127296808.534.516       0.945306   0.722245   0.857123   1.000000   0.798275   \n",
       "\n",
       "                       km_5_dist  \n",
       "146743638.12667.12652   0.920327  \n",
       "146842219.12874.12874   0.967436  \n",
       "146860774.13072.13072   1.000000  \n",
       "143890867.11944.11926   0.942102  \n",
       "143902946.11991.11991   0.976699  \n",
       "143945536.12065.12065   0.965266  \n",
       "144052463.12169.12169   1.000000  \n",
       "144065917.12226.12226   0.943597  \n",
       "127296808.516.516       1.000000  \n",
       "127296808.534.516       0.988061  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract politeness strategies features\n",
    "\n",
    "Now we will extract the second type of pragmatic features described in the paper: politeness strategies. We can do this using convokit's PolitenessStrategies class. This class does not require any training, so we can just apply it directly to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The politeness strategy features themselves can be accessed via the `feature_df` field of the PolitenessStrategies object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==HASHEDGE==  \\\n",
       "146743638.12652.12652                                0   \n",
       "146743638.12667.12652                                1   \n",
       "146842219.12874.12874                                1   \n",
       "146860774.13072.13072                                1   \n",
       "143890867.11926.11926                                0   \n",
       "143890867.11944.11926                                1   \n",
       "143902946.11991.11991                                0   \n",
       "143945536.12065.12065                                0   \n",
       "144052463.12169.12169                                1   \n",
       "144065917.12226.12226                                1   \n",
       "\n",
       "                       feature_politeness_==HASNEGATIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   1   \n",
       "144065917.12226.12226                                   1   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "146743638.12652.12652                                       0   \n",
       "146743638.12667.12652                                       1   \n",
       "146842219.12874.12874                                       0   \n",
       "146860774.13072.13072                                       0   \n",
       "143890867.11926.11926                                       0   \n",
       "143890867.11944.11926                                       0   \n",
       "143902946.11991.11991                                       0   \n",
       "143945536.12065.12065                                       0   \n",
       "144052463.12169.12169                                       0   \n",
       "144065917.12226.12226                                       0   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  1   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Please_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    0   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    1   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    1   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    0   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    0   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                                      ...                  \\\n",
       "146743638.12652.12652                 ...                   \n",
       "146743638.12667.12652                 ...                   \n",
       "146842219.12874.12874                 ...                   \n",
       "146860774.13072.13072                 ...                   \n",
       "143890867.11926.11926                 ...                   \n",
       "143890867.11944.11926                 ...                   \n",
       "143902946.11991.11991                 ...                   \n",
       "143945536.12065.12065                 ...                   \n",
       "144052463.12169.12169                 ...                   \n",
       "144065917.12226.12226                 ...                   \n",
       "\n",
       "                       feature_politeness_==Hedges==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              1   \n",
       "146842219.12874.12874                              1   \n",
       "146860774.13072.13072                              1   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              0   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              1   \n",
       "144065917.12226.12226                              1   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 0   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        1   \n",
       "146842219.12874.12874                                        1   \n",
       "146860774.13072.13072                                        1   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        1   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              0   \n",
       "146842219.12874.12874                              0   \n",
       "146860774.13072.13072                              0   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              1   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              0   \n",
       "144065917.12226.12226                              0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  1   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  1   \n",
       "\n",
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==Factuality==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Gratitude==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 1   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        0   \n",
       "146842219.12874.12874                                        0   \n",
       "146860774.13072.13072                                        0   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        0   \n",
       "\n",
       "                       feature_politeness_==HASPOSITIVE==  \n",
       "146743638.12652.12652                                   0  \n",
       "146743638.12667.12652                                   1  \n",
       "146842219.12874.12874                                   1  \n",
       "146860774.13072.13072                                   1  \n",
       "143890867.11926.11926                                   0  \n",
       "143890867.11944.11926                                   1  \n",
       "143902946.11991.11991                                   1  \n",
       "143945536.12065.12065                                   1  \n",
       "144052463.12169.12169                                   0  \n",
       "144065917.12226.12226                                   0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_strategies = ps.feature_df\n",
    "politeness_strategies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create pair data\n",
    "\n",
    "The prediction task defined in the paper is a paired task. The corpus downloaded from convokit already includes metadata about how conversations were paired for the paper, so we don't need to do any of the hard work here. Instead, we'll format the pair information into a table for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to directly map conversation IDs to their comments. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for comment_id in awry_corpus.utterances:\n",
    "    comment = awry_corpus.utterances[comment_id]\n",
    "    # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "    # them as they are not utterances\n",
    "    if not comment.other[\"is_section_header\"]:\n",
    "        comment_ids.append(comment_id)\n",
    "        convo_ids.append(comment.root)\n",
    "        timestamps.append(comment.timestamp)\n",
    "        page_ids.append(comment.other[\"awry_info\"][\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for comment in awry_corpus.utterances.values():\n",
    "    if comment.other[\"awry_info\"][\"conversation_has_personal_attack\"] and comment.root not in awry_convo_ids:\n",
    "        awry_convo_ids.add(comment.root)\n",
    "        good_convo_map[comment.root] = comment.other[\"awry_info\"][\"pair_id\"]\n",
    "        page_id_map[comment.root] = comment.other[\"awry_info\"][\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Construct feature matrix\n",
    "\n",
    "Now that we have the pair data, we can construct a table of pragmatic features for each pair, to use in prediction. This table will consist of the prompt types and politeness strategies for the first and second comment of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_convo(convo_id):\n",
    "    \n",
    "    # first, get the first two comments (IDs) by timestamp in the conversation\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==convo_id].sort_values(by=\"timestamp\")\n",
    "    first_id = comments_sorted.iloc[0].name\n",
    "    second_id = comments_sorted.iloc[1].name\n",
    "    # get prompt type features\n",
    "    try:\n",
    "        first_prompts = prompt_types.loc[first_id]\n",
    "    except:\n",
    "        first_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=prompt_types.columns)\n",
    "    try:\n",
    "        second_prompts = prompt_types.loc[second_id].rename({c: c + \"_second\" for c in prompt_types.columns})\n",
    "    except:\n",
    "        second_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=[c + \"_second\" for c in prompt_types.columns])\n",
    "    prompts = first_prompts.append(second_prompts)\n",
    "    # get politeness strategies features\n",
    "    first_politeness = politeness_strategies.loc[first_id]\n",
    "    second_politeness = politeness_strategies.loc[second_id].rename({c: c + \"_second\" for c in politeness_strategies.columns})\n",
    "    politeness = first_politeness.append(second_politeness)\n",
    "    return politeness.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = pairs_df.bad_conversation_id.append(pairs_df.conversation_id, ignore_index=True)\n",
    "feats = [features_for_convo(cid) for cid in convo_ids]\n",
    "feature_table = pd.DataFrame(data=np.vstack([f.values for f in feats]), columns=feats[0].index, index=convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper, we dropped the sentiment lexicon based features (HASPOSITIVE and HASNEGATIVE), opting\n",
    "# to instead use them as a baseline. We do this here as well to be consistent with the paper.\n",
    "feature_table = feature_table.drop(columns=[\"feature_politeness_==HASPOSITIVE==\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==\",\n",
    "                                            \"feature_politeness_==HASPOSITIVE==_second\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==_second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>...</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>km_0_dist_second</th>\n",
       "      <th>km_1_dist_second</th>\n",
       "      <th>km_2_dist_second</th>\n",
       "      <th>km_3_dist_second</th>\n",
       "      <th>km_4_dist_second</th>\n",
       "      <th>km_5_dist_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111356473.3090.3090</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729520</td>\n",
       "      <td>0.941425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899890</td>\n",
       "      <td>0.839871</td>\n",
       "      <td>0.719525</td>\n",
       "      <td>0.957258</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.954653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49083424.9901.9901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894193</td>\n",
       "      <td>0.890853</td>\n",
       "      <td>0.799802</td>\n",
       "      <td>0.935380</td>\n",
       "      <td>0.958619</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219719525.2591.2591</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866862</td>\n",
       "      <td>0.884670</td>\n",
       "      <td>0.808776</td>\n",
       "      <td>0.873826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886645</td>\n",
       "      <td>0.994835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180191077.3470.3470</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869070</td>\n",
       "      <td>0.922005</td>\n",
       "      <td>0.966008</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.977763</td>\n",
       "      <td>0.938204</td>\n",
       "      <td>0.899313</td>\n",
       "      <td>0.990845</td>\n",
       "      <td>0.914077</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418301485.10.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944682</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827365</td>\n",
       "      <td>0.950664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature_politeness_==HASHEDGE==  \\\n",
       "111356473.3090.3090                              1.0   \n",
       "49083424.9901.9901                               0.0   \n",
       "219719525.2591.2591                              1.0   \n",
       "180191077.3470.3470                              1.0   \n",
       "418301485.10.0                                   0.0   \n",
       "\n",
       "                     feature_politeness_==Direct_question==  \\\n",
       "111356473.3090.3090                                     0.0   \n",
       "49083424.9901.9901                                      0.0   \n",
       "219719525.2591.2591                                     0.0   \n",
       "180191077.3470.3470                                     0.0   \n",
       "418301485.10.0                                          0.0   \n",
       "\n",
       "                     feature_politeness_==INDICATIVE==  \\\n",
       "111356473.3090.3090                                0.0   \n",
       "49083424.9901.9901                                 0.0   \n",
       "219719525.2591.2591                                0.0   \n",
       "180191077.3470.3470                                0.0   \n",
       "418301485.10.0                                     0.0   \n",
       "\n",
       "                     feature_politeness_==SUBJUNCTIVE==  \\\n",
       "111356473.3090.3090                                 0.0   \n",
       "49083424.9901.9901                                  0.0   \n",
       "219719525.2591.2591                                 0.0   \n",
       "180191077.3470.3470                                 0.0   \n",
       "418301485.10.0                                      0.0   \n",
       "\n",
       "                     feature_politeness_==1st_person==  \\\n",
       "111356473.3090.3090                                0.0   \n",
       "49083424.9901.9901                                 1.0   \n",
       "219719525.2591.2591                                0.0   \n",
       "180191077.3470.3470                                1.0   \n",
       "418301485.10.0                                     0.0   \n",
       "\n",
       "                     feature_politeness_==Please_start==  \\\n",
       "111356473.3090.3090                                  0.0   \n",
       "49083424.9901.9901                                   0.0   \n",
       "219719525.2591.2591                                  0.0   \n",
       "180191077.3470.3470                                  0.0   \n",
       "418301485.10.0                                       1.0   \n",
       "\n",
       "                     feature_politeness_==Direct_start==  \\\n",
       "111356473.3090.3090                                  0.0   \n",
       "49083424.9901.9901                                   0.0   \n",
       "219719525.2591.2591                                  1.0   \n",
       "180191077.3470.3470                                  1.0   \n",
       "418301485.10.0                                       0.0   \n",
       "\n",
       "                     feature_politeness_==Apologizing==  \\\n",
       "111356473.3090.3090                                 0.0   \n",
       "49083424.9901.9901                                  0.0   \n",
       "219719525.2591.2591                                 0.0   \n",
       "180191077.3470.3470                                 0.0   \n",
       "418301485.10.0                                      0.0   \n",
       "\n",
       "                     feature_politeness_==1st_person_pl.==  \\\n",
       "111356473.3090.3090                                    0.0   \n",
       "49083424.9901.9901                                     0.0   \n",
       "219719525.2591.2591                                    0.0   \n",
       "180191077.3470.3470                                    0.0   \n",
       "418301485.10.0                                         0.0   \n",
       "\n",
       "                     feature_politeness_==Indirect_(greeting)==  \\\n",
       "111356473.3090.3090                                         0.0   \n",
       "49083424.9901.9901                                          0.0   \n",
       "219719525.2591.2591                                         0.0   \n",
       "180191077.3470.3470                                         0.0   \n",
       "418301485.10.0                                              0.0   \n",
       "\n",
       "                           ...         km_2_dist  km_3_dist  km_4_dist  \\\n",
       "111356473.3090.3090        ...          0.729520   0.941425   1.000000   \n",
       "49083424.9901.9901         ...          1.000000   0.941099   1.000000   \n",
       "219719525.2591.2591        ...          0.866862   0.884670   0.808776   \n",
       "180191077.3470.3470        ...          0.869070   0.922005   0.966008   \n",
       "418301485.10.0             ...          0.944682   1.000000   0.827365   \n",
       "\n",
       "                     km_5_dist  km_0_dist_second  km_1_dist_second  \\\n",
       "111356473.3090.3090   1.000000          0.899890          0.839871   \n",
       "49083424.9901.9901    1.000000          0.894193          0.890853   \n",
       "219719525.2591.2591   0.873826          1.000000          1.000000   \n",
       "180191077.3470.3470   0.902196          0.977763          0.938204   \n",
       "418301485.10.0        0.950664          1.000000          1.000000   \n",
       "\n",
       "                     km_2_dist_second  km_3_dist_second  km_4_dist_second  \\\n",
       "111356473.3090.3090          0.719525          0.957258          0.906911   \n",
       "49083424.9901.9901           0.799802          0.935380          0.958619   \n",
       "219719525.2591.2591          1.000000          1.000000          0.886645   \n",
       "180191077.3470.3470          0.899313          0.990845          0.914077   \n",
       "418301485.10.0               1.000000          1.000000          1.000000   \n",
       "\n",
       "                     km_5_dist_second  \n",
       "111356473.3090.3090          0.954653  \n",
       "49083424.9901.9901           1.000000  \n",
       "219719525.2591.2591          0.994835  \n",
       "180191077.3470.3470          1.000000  \n",
       "418301485.10.0               1.000000  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it looks\n",
    "feature_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prediction Utils\n",
    "\n",
    "We're almost ready to do the prediction! First we need to define a few helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pred_single(inputs, X, y):\n",
    "    f_idx, (train_idx, test_idx) = inputs\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    base_clf = Pipeline([(\"scaler\", StandardScaler()), (\"featselect\", SelectPercentile(f_classif, 10)), (\"logreg\", LogisticRegression())])\n",
    "    clf = GridSearchCV(base_clf, {\"logreg__C\": [10**i for i in range(-4,4)], \"featselect__percentile\": list(range(10, 110, 10))})\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_scores = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    feature_weights = clf.best_estimator_.named_steps[\"logreg\"].coef_.flatten()\n",
    "    feature_mask = clf.best_estimator_.named_steps[\"featselect\"].get_support()\n",
    "    \n",
    "    hyperparams = clf.best_params_\n",
    "    \n",
    "    return (y_pred, y_scores, feature_weights, hyperparams, feature_mask)\n",
    "\n",
    "def run_pred(X, y, fnames, groups):\n",
    "    feature_weights = {}\n",
    "    scores = np.asarray([np.nan for i in range(len(y))])\n",
    "    y_pred = np.zeros(len(y))\n",
    "    hyperparameters = defaultdict(list)\n",
    "    splits = list(enumerate(LeaveOneGroupOut().split(X, y, groups)))\n",
    "    accs = []\n",
    "        \n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        prediction_results = p.map(partial(run_pred_single, X=X, y=y), splits)\n",
    "        \n",
    "    fselect_pvals_all = []\n",
    "    for i in range(len(splits)):\n",
    "        f_idx, (train_idx, test_idx) = splits[i]\n",
    "        y_pred_i, y_scores_i, weights_i, hyperparams_i, mask_i = prediction_results[i]\n",
    "        y_pred[test_idx] = y_pred_i\n",
    "        scores[test_idx] = y_scores_i\n",
    "        feature_weights[f_idx] = np.asarray([np.nan for _ in range(len(fnames))])\n",
    "        feature_weights[f_idx][mask_i] = weights_i\n",
    "        for param in hyperparams_i:\n",
    "            hyperparameters[param].append(hyperparams_i[param])   \n",
    "    \n",
    "    acc = np.mean(y_pred == y)\n",
    "    pvalue = stats.binom_test(sum(y_pred == y), n=len(y), alternative=\"greater\")\n",
    "                \n",
    "    coef_df = pd.DataFrame(feature_weights, index=fnames)\n",
    "    coef_df['mean_coef'] = coef_df.apply(np.nanmean, axis=1)\n",
    "    coef_df['std_coef'] = coef_df.apply(np.nanstd, axis=1)\n",
    "    return acc, coef_df[['mean_coef', 'std_coef']], scores, pd.DataFrame(hyperparameters), pvalue\n",
    "\n",
    "def get_labeled_pairs(pairs_df):\n",
    "    paired_labels = []\n",
    "    c0s = []\n",
    "    c1s = []\n",
    "    page_ids = []\n",
    "    for i, row in enumerate(pairs_df.itertuples()):\n",
    "        if i % 2 == 0:\n",
    "            c0s.append(row.conversation_id)\n",
    "            c1s.append(row.bad_conversation_id)\n",
    "        else:\n",
    "            c0s.append(row.bad_conversation_id)\n",
    "            c1s.append(row.conversation_id)\n",
    "        paired_labels.append(i%2)\n",
    "        page_ids.append(row.page_id)\n",
    "    return pd.DataFrame({\"c0\": c0s, \"c1\": c1s,\"first_convo_toxic\": paired_labels, \"page_id\": page_ids})\n",
    "\n",
    "\n",
    "def mode(seq):\n",
    "    vals, counts = np.unique(seq, return_counts=True)\n",
    "    return vals[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Prediction\n",
    "\n",
    "And at long last, the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels...\n",
      "Retrieving paired features...\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6141732283464567\n",
      "p-value: 4.7715e-09\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 50\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.170420  0.010455\n",
      "feature_politeness_==2nd_person_start==_second     -0.138383  0.008210\n",
      "feature_politeness_==Direct_question==_second      -0.111844  0.006030\n",
      "feature_politeness_==2nd_person_start==            -0.103344  0.006964\n",
      "feature_politeness_==Direct_question==             -0.100131  0.005493\n",
      "feature_politeness_==Indirect_(btw)==              -0.086440  0.003664\n",
      "feature_politeness_==Please_start==_second         -0.077534  0.004578\n",
      "km_3_dist_second                                   -0.046964  0.002626\n",
      "km_0_dist                                          -0.043200  0.006253\n",
      "feature_politeness_==Factuality==                  -0.033598  0.002096\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.033196  0.000408\n",
      "km_3_dist                                          -0.013236  0.002092\n",
      "feature_politeness_==Please_start==                -0.011113  0.001442\n",
      "km_1_dist_second                                   -0.008256  0.000000\n",
      "km_2_dist                                          -0.007035  0.007636\n",
      "feature_politeness_==1st_person==                  -0.000948  0.002072\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.003572  0.000919\n",
      "km_2_dist_second                                    0.010077  0.001713\n",
      "km_0_dist_second                                    0.011222  0.001514\n",
      "feature_politeness_==Deference==_second             0.015331  0.000303\n",
      "feature_politeness_==1st_person_pl.==_second        0.021676  0.001472\n",
      "km_4_dist                                           0.025352  0.002669\n",
      "feature_politeness_==Deference==                    0.033288  0.004902\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.044118  0.002442\n",
      "km_4_dist_second                                    0.044890  0.002930\n",
      "feature_politeness_==Hedges==_second                0.055143  0.002789\n",
      "feature_politeness_==1st_person==_second            0.057778  0.003163\n",
      "feature_politeness_==INDICATIVE==_second            0.065789  0.000000\n",
      "feature_politeness_==HASHEDGE==                     0.068589  0.003676\n",
      "feature_politeness_==Gratitude==                    0.069681  0.002897\n",
      "feature_politeness_==Apologizing==_second           0.074455  0.003541\n",
      "km_5_dist_second                                    0.080822  0.005323\n",
      "feature_politeness_==Gratitude==_second             0.080833  0.004780\n",
      "feature_politeness_==Hedges==                       0.081452  0.005340\n",
      "feature_politeness_==1st_person_start==_second      0.082326  0.004512\n",
      "km_5_dist                                           0.094801  0.007040\n",
      "feature_politeness_==HASHEDGE==_second              0.098174  0.006923\n",
      "feature_politeness_==Indirect_(greeting)==          0.134826  0.009525\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.145306  0.013275\n",
      "feature_politeness_==INDICATIVE==                        NaN       NaN\n",
      "feature_politeness_==Direct_start==                      NaN       NaN\n",
      "feature_politeness_==Apologizing==                       NaN       NaN\n",
      "feature_politeness_==1st_person_pl.==                    NaN       NaN\n",
      "feature_politeness_==1st_person_start==                  NaN       NaN\n",
      "feature_politeness_==Please==                            NaN       NaN\n",
      "feature_politeness_==2nd_person==                        NaN       NaN\n",
      "feature_politeness_==Direct_start==_second               NaN       NaN\n",
      "feature_politeness_==Please==_second                     NaN       NaN\n",
      "feature_politeness_==Factuality==_second                 NaN       NaN\n",
      "km_1_dist                                                NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/pandas/core/apply.py:242: RuntimeWarning: Mean of empty slice\n",
      "  labels=labels)\n",
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1434: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating labels...\")\n",
    "labeled_pairs_df = get_labeled_pairs(pairs_df)\n",
    "print(\"Retrieving paired features...\")\n",
    "X_c0 = feature_table.loc[labeled_pairs_df.c0].values\n",
    "X_c1 = feature_table.loc[labeled_pairs_df.c1].values\n",
    "X = X_c1 - X_c0\n",
    "y = labeled_pairs_df.first_convo_toxic.values\n",
    "print(\"Running leave-one-page-out prediction...\")\n",
    "accuracy, coefs, scores, hyperparams, pvalue = run_pred(X, y, feature_table.columns, labeled_pairs_df.page_id)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"p-value: %.4e\" % pvalue)\n",
    "print(\"C (mode):\", mode(hyperparams.logreg__C))\n",
    "print(\"Percent of features (mode):\", mode(hyperparams.featselect__percentile))\n",
    "print(\"Coefficents:\")\n",
    "print(coefs.sort_values(by=\"mean_coef\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
