{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "corpus = Corpus('/kitchen/convokit_corpora/tennis-corpus/')\n",
    "corpus.load_processed_text(['arcs_censored', 'tok_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.phrasing_motifs import QuestionSentences, PhrasingMotifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs = QuestionSentences(output_field='question_arcs', input_field='arcs_censored')\n",
    "corpus = qs.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_model = PhrasingMotifs('question_motifs','question_arcs',50,verbosity=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrasing_motif_info': {}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_model.aux_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting frequent itemsets for 83921 sets\n",
      "\tfirst pass: counting itemsets up to and including 5 items large\n",
      "\tfirst pass: 20000/83921 sets processed\n",
      "\tfirst pass: 40000/83921 sets processed\n",
      "\tfirst pass: 60000/83921 sets processed\n",
      "\tfirst pass: 80000/83921 sets processed\n",
      "\tsecond pass: counting itemsets more than 5 items large\n",
      "\tsecond pass: checking 6117 sets for itemsets of length 6\n",
      "\tsecond pass: checking 1791 sets for itemsets of length 7\n",
      "making itemset tree for 3628 itemsets\n",
      "deduplicating itemsets\n",
      "\tcounting itemset cooccurrences for 20000/80738 collections\n",
      "\tcounting itemset cooccurrences for 40000/80738 collections\n",
      "\tcounting itemset cooccurrences for 60000/80738 collections\n",
      "\tcounting itemset cooccurrences for 80000/80738 collections\n",
      "\tfinding supersets\n"
     ]
    }
   ],
   "source": [
    "pm_model.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('*',) 83921\n",
      "('what>*',) 12890\n",
      "('is_*',) 10563\n",
      "('how>*',) 9614\n",
      "('do>*',) 9043\n",
      "('think_*',) 7296\n",
      "('think_do',) 6284\n",
      "('think_*', 'think_do') 6284\n",
      "('is>*',) 6020\n",
      "('feel_*',) 5890\n",
      "('was_*',) 5593\n",
      "('is>*', 'is_*') 5450\n",
      "('did>*',) 4792\n",
      "('are_*',) 4132\n",
      "('feel_do',) 3438\n",
      "('feel_*', 'feel_do') 3438\n",
      "('are>*',) 3012\n",
      "('do>*', 'think_*') 2867\n",
      "('do>*', 'think_do') 2848\n",
      "('do>*', 'think_*', 'think_do') 2848\n",
      "('have_*',) 2737\n",
      "('can>*',) 2665\n",
      "('was>*',) 2481\n",
      "('what>do',) 2411\n",
      "('what>*', 'what>do') 2411\n"
     ]
    }
   ],
   "source": [
    "pm_model.print_top_phrasings(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/163948 utterances processed\n",
      "40000/163948 utterances processed\n",
      "60000/163948 utterances processed\n",
      "80000/163948 utterances processed\n",
      "100000/163948 utterances processed\n",
      "120000/163948 utterances processed\n",
      "140000/163948 utterances processed\n",
      "160000/163948 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = pm_model.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How hard was it with the crowd ?\n",
      "You may have answered this already .\n",
      "I came in late .\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_processed_text('2886_11.q','tok_str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'how>*': False,\n",
       "  'how>*__was_*': True,\n",
       "  'was_*': False,\n",
       "  'was_*__was_hard': True}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text('2886_11.q','question_motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you still a little bit stunned that you did win this match in the end after being down three points after the back and forth and back and forth that it kind of ended so quickly in your mind ?\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_processed_text('2886_10.q','tok_str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'are>*': False,\n",
       "  'are>*__are_*': True,\n",
       "  'are_*': False,\n",
       "  'are_*__are_still': True}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text('2886_10.q','question_motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.dump_processed_text(['question_motifs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing itemset counts\n",
      "writing downlinks\n",
      "writing itemset to ids\n",
      "writing meta information\n"
     ]
    }
   ],
   "source": [
    "pm_model.dump_model('/kitchen/convokit_corpora/tennis_pm_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pm_model = PhrasingMotifs('question_motifs_copy','question_arcs',50,verbosity=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading itemset counts\n",
      "reading downlinks\n",
      "reading itemset to ids\n",
      "reading meta information\n"
     ]
    }
   ],
   "source": [
    "new_pm_model.load_model('/kitchen/convokit_corpora/tennis-corpus/pm_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('*',) 83921\n",
      "('what>*',) 12890\n",
      "('is_*',) 10563\n",
      "('how>*',) 9614\n",
      "('do>*',) 9043\n",
      "('think_*',) 7296\n",
      "('think_do',) 6284\n",
      "('think_*', 'think_do') 6284\n",
      "('is>*',) 6020\n",
      "('feel_*',) 5890\n",
      "('was_*',) 5593\n",
      "('is>*', 'is_*') 5450\n",
      "('did>*',) 4792\n",
      "('are_*',) 4132\n",
      "('feel_do',) 3438\n",
      "('feel_*', 'feel_do') 3438\n",
      "('are>*',) 3012\n",
      "('do>*', 'think_*') 2867\n",
      "('do>*', 'think_do') 2848\n",
      "('do>*', 'think_*', 'think_do') 2848\n",
      "('have_*',) 2737\n",
      "('can>*',) 2665\n",
      "('was>*',) 2481\n",
      "('what>do',) 2411\n",
      "('what>*', 'what>do') 2411\n"
     ]
    }
   ],
   "source": [
    "new_pm_model.print_top_phrasings(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/163948 utterances processed\n",
      "40000/163948 utterances processed\n",
      "60000/163948 utterances processed\n",
      "80000/163948 utterances processed\n",
      "100000/163948 utterances processed\n",
      "120000/163948 utterances processed\n",
      "140000/163948 utterances processed\n",
      "160000/163948 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = new_pm_model.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'how>*': False,\n",
       "  'how>*__was_*': True,\n",
       "  'was_*': False,\n",
       "  'was_*__was_hard': True}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text('2886_11.q','question_motifs_copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'are>*': False,\n",
       "  'are>*__are_*': True,\n",
       "  'are_*': False,\n",
       "  'are_*__are_still': True}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text('2886_10.q','question_motifs_copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
