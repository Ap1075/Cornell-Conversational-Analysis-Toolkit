{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = '/kitchen/convokit_corpora/tennis-mini/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = convokit.Corpus(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversations.json  corpus.json  index.json  users.json  utterances.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "ls $ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_utt_id = '1681_14.a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yeah, but many friends went with me, Japanese guy. So I wasn't -- I wasn't like homesick. But now sometimes I get homesick.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_utterance(test_utt_id).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.replace(' -- ', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_prep = TextProcessor(preprocess_text, 'text')\n",
    "corpus = text_prep.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.processed_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yeah, but many friends went with me, Japanese guy. So I wasn't I wasn't like homesick. But now sometimes I get homesick.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "050/200 utterances processed\n",
      "100/200 utterances processed\n",
      "150/200 utterances processed\n"
     ]
    }
   ],
   "source": [
    "textparser = TextParser('parsed', input_field='text', verbosity=50)\n",
    "corpus = textparser.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'parsed'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.processed_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_parse = corpus.get_processed_text(test_utt_id, 'parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rt': 5,\n",
       " 'toks': [{'dep': 'intj', 'dn': [], 'tag': 'UH', 'tok': 'Yeah', 'up': 5},\n",
       "  {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "  {'dep': 'cc', 'dn': [], 'tag': 'CC', 'tok': 'but', 'up': 5},\n",
       "  {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'many', 'up': 4},\n",
       "  {'dep': 'nsubj', 'dn': [3, 10], 'tag': 'NNS', 'tok': 'friends', 'up': 5},\n",
       "  {'dep': 'ROOT', 'dn': [0, 1, 2, 4, 6, 8, 11], 'tag': 'VBD', 'tok': 'went'},\n",
       "  {'dep': 'prep', 'dn': [7], 'tag': 'IN', 'tok': 'with', 'up': 5},\n",
       "  {'dep': 'pobj', 'dn': [], 'tag': 'PRP', 'tok': 'me', 'up': 6},\n",
       "  {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "  {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'Japanese', 'up': 10},\n",
       "  {'dep': 'appos', 'dn': [9], 'tag': 'NN', 'tok': 'guy', 'up': 4},\n",
       "  {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 5}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texttagger = TextParser('tagged', 'tag', input_field='text')\n",
    "corpus = texttagger.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'toks': [{'tag': 'UH', 'tok': 'Yeah'},\n",
       "   {'tag': ',', 'tok': ','},\n",
       "   {'tag': 'CC', 'tok': 'but'},\n",
       "   {'tag': 'JJ', 'tok': 'many'},\n",
       "   {'tag': 'NNS', 'tok': 'friends'},\n",
       "   {'tag': 'VBD', 'tok': 'went'},\n",
       "   {'tag': 'IN', 'tok': 'with'},\n",
       "   {'tag': 'PRP', 'tok': 'me'},\n",
       "   {'tag': ',', 'tok': ','},\n",
       "   {'tag': 'JJ', 'tok': 'Japanese'},\n",
       "   {'tag': 'NN', 'tok': 'guy'},\n",
       "   {'tag': '.', 'tok': '.'}]},\n",
       " {'toks': [{'tag': 'RB', 'tok': 'So'},\n",
       "   {'tag': 'PRP', 'tok': 'I'},\n",
       "   {'tag': 'VBD', 'tok': 'was'},\n",
       "   {'tag': 'RB', 'tok': \"n't\"},\n",
       "   {'tag': 'PRP', 'tok': 'I'},\n",
       "   {'tag': 'VBD', 'tok': 'was'},\n",
       "   {'tag': 'RB', 'tok': \"n't\"},\n",
       "   {'tag': 'UH', 'tok': 'like'},\n",
       "   {'tag': 'NN', 'tok': 'homesick'},\n",
       "   {'tag': '.', 'tok': '.'}]},\n",
       " {'toks': [{'tag': 'CC', 'tok': 'But'},\n",
       "   {'tag': 'RB', 'tok': 'now'},\n",
       "   {'tag': 'RB', 'tok': 'sometimes'},\n",
       "   {'tag': 'PRP', 'tok': 'I'},\n",
       "   {'tag': 'VBP', 'tok': 'get'},\n",
       "   {'tag': 'NN', 'tok': 'homesick'},\n",
       "   {'tag': '.', 'tok': '.'}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.text_processing import TokensToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok_to_str = TokensToString('tok_str')\n",
    "corpus = tok_to_str.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeah , but many friends went with me , Japanese guy .\n",
      "So I was n't\n",
      "I was n't like homesick .\n",
      "But now sometimes I get homesick .\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_processed_text(test_utt_id, 'tok_str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_to_str = TokensToString('tok_tag', token_formatter=lambda x: '%s_%s' % (x['tok'].lower(), x['tag']),\n",
    "                           token_filter=lambda x: sum(ch.isalpha() for ch in x['tok'])>0)\n",
    "corpus = tag_to_str.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah_UH but_CC many_JJ friends_NNS went_VBD with_IN me_PRP japanese_JJ guy_NN\n",
      "so_RB i_PRP was_VBD n't_RB\n",
      "i_PRP was_VBD n't_RB like_UH homesick_NN\n",
      "but_CC now_RB sometimes_RB i_PRP get_VBP homesick_NN\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_processed_text(test_utt_id, 'tok_tag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextToArcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_arc = TextToArcs('arcs')\n",
    "corpus = text_to_arc.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['friends_*',\n",
       "  'friends_guy',\n",
       "  'friends_many',\n",
       "  'guy_*',\n",
       "  'guy_japanese',\n",
       "  'japanese_*',\n",
       "  'many_*',\n",
       "  'me_*',\n",
       "  'went_*',\n",
       "  'went_friends',\n",
       "  'went_with',\n",
       "  'went_yeah',\n",
       "  'with_*',\n",
       "  'with_me',\n",
       "  'yeah_*'],\n",
       " ['i_*', 'so>i', 'so_*', 'was_*', 'was_i', 'was_so'],\n",
       " ['homesick_*', 'i_*', 'like_*', 'was_*', 'was_homesick', 'was_i', 'was_like'],\n",
       " ['but>now',\n",
       "  'get_*',\n",
       "  'get_homesick',\n",
       "  'get_i',\n",
       "  'get_now',\n",
       "  'get_sometimes',\n",
       "  'homesick_*',\n",
       "  'i_*',\n",
       "  'now_*',\n",
       "  'sometimes_*']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'arcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_arc_mini = TextToArcs('arcs_mini', root_only=True)\n",
    "corpus = text_to_arc_mini.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['went_*', 'went_friends', 'went_with', 'went_yeah'],\n",
       " ['so>i', 'was_*', 'was_i', 'was_so'],\n",
       " ['was_*', 'was_homesick', 'was_i', 'was_like'],\n",
       " ['but>now', 'get_*', 'get_homesick', 'get_i', 'get_now', 'get_sometimes']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'arcs_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.phrasing_motifs import CensorNouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "censor_nouns = CensorNouns('parsed_censored')\n",
    "corpus = censor_nouns.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rt': 5,\n",
       "  'toks': [{'dep': 'intj', 'dn': [], 'tag': 'UH', 'tok': 'yeah', 'up': 5},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "   {'dep': 'cc', 'dn': [], 'tag': 'CC', 'tok': 'but', 'up': 5},\n",
       "   {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'many', 'up': 4},\n",
       "   {'dep': 'nsubj', 'dn': [3, 10], 'tag': 'NNS', 'tok': 'NN~', 'up': 5},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 2, 4, 6, 8, 11], 'tag': 'VBD', 'tok': 'went'},\n",
       "   {'dep': 'prep', 'dn': [7], 'tag': 'IN', 'tok': 'with', 'up': 5},\n",
       "   {'dep': 'pobj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 6},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "   {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'japanese', 'up': 10},\n",
       "   {'dep': 'appos', 'dn': [9], 'tag': 'NN', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 5}]},\n",
       " {'rt': 2,\n",
       "  'toks': [{'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'so', 'up': 2},\n",
       "   {'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 2},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 3], 'tag': 'VBD', 'tok': 'was'},\n",
       "   {'dep': 'neg', 'dn': [], 'tag': 'RB', 'tok': \"n't\", 'up': 2}]},\n",
       " {'rt': 1,\n",
       "  'toks': [{'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 1},\n",
       "   {'dep': 'ROOT', 'dn': [0, 2, 3, 4, 5], 'tag': 'VBD', 'tok': 'was'},\n",
       "   {'dep': 'neg', 'dn': [], 'tag': 'RB', 'tok': \"n't\", 'up': 1},\n",
       "   {'dep': 'prep', 'dn': [], 'tag': 'UH', 'tok': 'like', 'up': 1},\n",
       "   {'dep': 'acomp', 'dn': [], 'tag': 'NN', 'tok': 'NN~', 'up': 1},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 1}]},\n",
       " {'rt': 4,\n",
       "  'toks': [{'dep': 'cc', 'dn': [], 'tag': 'CC', 'tok': 'but', 'up': 4},\n",
       "   {'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'now', 'up': 4},\n",
       "   {'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'sometimes', 'up': 4},\n",
       "   {'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 2, 3, 5, 6], 'tag': 'VBP', 'tok': 'get'},\n",
       "   {'dep': 'acomp', 'dn': [], 'tag': 'NN', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 4}]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'parsed_censored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_arc_mini_censored = TextToArcs('arcs_censored', input_field='parsed_censored', root_only=True)\n",
    "corpus = text_to_arc_mini_censored.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['went_*', 'went_with', 'went_yeah'],\n",
       " ['was_*', 'was_so'],\n",
       " ['was_*', 'was_like'],\n",
       " ['but>now', 'get_*', 'get_now', 'get_sometimes']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_processed_text(test_utt_id, 'arcs_censored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_tokens_and_sentences(sents, aux_input={'sent_sep': '\\n', 'tok_sep': ' '}):\n",
    "    return aux_input.get('sent_sep','\\n').join(aux_input.get('tok_sep',' ')\n",
    "                         .join(sent) for sent in sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_to_string = TextProcessor(join_tokens_and_sentences, \n",
    "                              output_field='arc_string', input_field='arcs',\n",
    "                             aux_input={'sent_sep': '\\n', 'tok_sep': ', '})\n",
    "corpus = arc_to_string.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends_*, friends_guy, friends_many, guy_*, guy_japanese, japanese_*, many_*, me_*, went_*, went_friends, went_with, went_yeah, with_*, with_me, yeah_*\n",
      "i_*, so>i, so_*, was_*, was_i, was_so\n",
      "homesick_*, i_*, like_*, was_*, was_homesick, was_i, was_like\n",
      "but>now, get_*, get_homesick, get_i, get_now, get_sometimes, homesick_*, i_*, now_*, sometimes_*\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_processed_text(test_utt_id, 'arc_string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'parsed', 'tagged', 'tok_str', 'tok_tag', 'arcs', 'arcs_mini', 'parsed_censored', 'arcs_censored', 'arc_string'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.processed_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.dump_processed_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversations.json                   processed_text.parsed.json\r\n",
      "corpus.json                          processed_text.tagged.json\r\n",
      "index.json                           processed_text.text.json\r\n",
      "processed_text.arcs_censored.json    processed_text.tok_str.json\r\n",
      "processed_text.arcs.json             processed_text.tok_tag.json\r\n",
      "processed_text.arcs_mini.json        users.json\r\n",
      "processed_text.arc_string.json       utterances.jsonl\r\n",
      "processed_text.parsed_censored.json\r\n"
     ]
    }
   ],
   "source": [
    "ls $ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_corpus = convokit.Corpus(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus.processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_corpus.load_processed_text(['arcs', 'tok_str', 'parsed_censored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arcs', 'tok_str', 'parsed_censored'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus.processed_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rt': 5,\n",
       "  'toks': [{'dep': 'intj', 'dn': [], 'tag': 'UH', 'tok': 'yeah', 'up': 5},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "   {'dep': 'cc', 'dn': [], 'tag': 'CC', 'tok': 'but', 'up': 5},\n",
       "   {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'many', 'up': 4},\n",
       "   {'dep': 'nsubj', 'dn': [3, 10], 'tag': 'NNS', 'tok': 'NN~', 'up': 5},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 2, 4, 6, 8, 11], 'tag': 'VBD', 'tok': 'went'},\n",
       "   {'dep': 'prep', 'dn': [7], 'tag': 'IN', 'tok': 'with', 'up': 5},\n",
       "   {'dep': 'pobj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 6},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': ',', 'tok': ',', 'up': 5},\n",
       "   {'dep': 'amod', 'dn': [], 'tag': 'JJ', 'tok': 'japanese', 'up': 10},\n",
       "   {'dep': 'appos', 'dn': [9], 'tag': 'NN', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 5}]},\n",
       " {'rt': 2,\n",
       "  'toks': [{'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'so', 'up': 2},\n",
       "   {'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 2},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 3], 'tag': 'VBD', 'tok': 'was'},\n",
       "   {'dep': 'neg', 'dn': [], 'tag': 'RB', 'tok': \"n't\", 'up': 2}]},\n",
       " {'rt': 1,\n",
       "  'toks': [{'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 1},\n",
       "   {'dep': 'ROOT', 'dn': [0, 2, 3, 4, 5], 'tag': 'VBD', 'tok': 'was'},\n",
       "   {'dep': 'neg', 'dn': [], 'tag': 'RB', 'tok': \"n't\", 'up': 1},\n",
       "   {'dep': 'prep', 'dn': [], 'tag': 'UH', 'tok': 'like', 'up': 1},\n",
       "   {'dep': 'acomp', 'dn': [], 'tag': 'NN', 'tok': 'NN~', 'up': 1},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 1}]},\n",
       " {'rt': 4,\n",
       "  'toks': [{'dep': 'cc', 'dn': [], 'tag': 'CC', 'tok': 'but', 'up': 4},\n",
       "   {'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'now', 'up': 4},\n",
       "   {'dep': 'advmod', 'dn': [], 'tag': 'RB', 'tok': 'sometimes', 'up': 4},\n",
       "   {'dep': 'nsubj', 'dn': [], 'tag': 'PRP', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'ROOT', 'dn': [0, 1, 2, 3, 5, 6], 'tag': 'VBP', 'tok': 'get'},\n",
       "   {'dep': 'acomp', 'dn': [], 'tag': 'NN', 'tok': 'NN~', 'up': 4},\n",
       "   {'dep': 'punct', 'dn': [], 'tag': '.', 'tok': '.', 'up': 4}]}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus.get_processed_text(test_utt_id, 'parsed_censored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
