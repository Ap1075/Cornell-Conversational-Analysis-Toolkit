{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Conversations Gone Awry With Convokit\n",
    "\n",
    "This interactive tutorial demonstrates how to predict whether a conversation will eventually lead to a personal attack, as seen in the paper [Conversations Gone Awry: Detecting Early Signs of Conversational Failure](http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html), using the tools provided by convokit. It also serves as an illustration of how to use two of convokit's main features: question typology and politeness strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import json\n",
    "import itertools\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "from convokit import Corpus, QuestionTypology, download, MotifsExtractor, QuestionTypologyUtils, PolitenessStrategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Conversations Gone Awry corpus, provided as part of convokit\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\")):\n",
    "    download(\"conversations-gone-awry-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a convokit Corpus object from the downloaded data. The Corpus class provides functionality for\n",
    "# convenient manipulation of text corpora.\n",
    "awry_corpus = Corpus(filename=os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract prompt types features\n",
    "\n",
    "In this step, we will extract the first of the two types of pragmatic features seen in the paper: prompt types. We can learn prompt types and compute types for each utterance in the corpus using convokit's QuestionTypology class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train the QuestionTypology object on convokit's wiki corpus. Let's first download the corpus...\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"wiki-corpus\")):\n",
    "    download(\"wiki-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a QuestionTypology object on the downloaded wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building q-a matrices\n",
      "matrix dir /home/jonathan/research/Cornell-Conversational-Analysis-Toolkit/convokit/downloads/wiki-corpus-awry-matrix exists!\n",
      "\treading arcs and motifs\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tbuilding matrices\n",
      "\twriting stuff\n",
      "reading question tidxes\n",
      "reading question leaves\n",
      "reading answer tidxes\n",
      "reading question didxes\n",
      "reading answer didxes\n",
      "reading question terms\n",
      "reading answer terms\n",
      "reading docs\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# some parameters to get us started. Note that \"dataset name\" refers not to the name of the *source* dataset,\n",
    "# but the name we want to give to trained output files of the QuestionTypology object. We could have given\n",
    "# any name we liked - we chose \"wiki-corpus-awry\" to keep things clear.\n",
    "dataset_name = \"wiki-corpus-awry\"\n",
    "num_clusters = 6\n",
    "\n",
    "# load the wiki corpus into a convokit Corpus object\n",
    "data_dir = os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), 'downloads')\n",
    "corpus = Corpus(filename=os.path.join(data_dir, 'wiki-corpus'))\n",
    "\n",
    "# if this is our first time running this example, we need to fit motifs on the\n",
    "# dataset. If we have run it before, just load the previously computed motifs\n",
    "motifs_dir = os.path.join(data_dir, dataset_name + \"-motifs\")\n",
    "if not os.path.exists(motifs_dir):\n",
    "    motifs_dir = None\n",
    "\n",
    "questionTypology = QuestionTypology(corpus, data_dir, dataset_name=dataset_name, motifs_dir=motifs_dir,\n",
    "                                    num_dims=50, num_clusters=6, question_threshold=100, answer_threshold=100, \n",
    "                                    verbose=1000000, random_seed=2018, min_support=20,\n",
    "                                    questions_only=False, enforce_formatting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the QuestionTypology object has been trained, we can use it to compute prompt types for our awry corpus (notice that this is a different corpus from what the QuestionTypology object was trained on!). For our purposes, we want the raw features, which are distances from the centers of the KMeans clusters corresponding to each prompt type. We can get these using the `get_qtype_dists` method. Note that in most other situations, where we want just the prompt type, we can use the QuestionTypology object as a Callable, which will return an integer prompt type for each utterance in the corpus. We could also use the `compute_type` function, which is aliased to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = questionTypology.get_qtype_dists(awry_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.100313</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.052824</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.063603</td>\n",
       "      <td>I notice that earier that  moved wiki_link to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "      <td>Chen was known in the poker world as \"William\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.048260</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.021051</td>\n",
       "      <td>0.985920</td>\n",
       "      <td>I see what you saying I just read his pokersta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.018610</td>\n",
       "      <td>1.163208</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.110955</td>\n",
       "      <td>No more than two editors advocated deletion.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>In the future please don't close Afds when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.044573</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.099157</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.022813</td>\n",
       "      <td>That simply isn't true.  If you read the comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.102745</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>Somehow, I suspect you may wish to participate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "      <td>I assume your deliberate lying has a point, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.121714</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.117303</td>\n",
       "      <td>1.166274</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.001746</td>\n",
       "      <td>== Could you stop reverting my corrections ==\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>If you have problems with my edits to the 4WD ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.100313   0.925354   1.052824   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.048260   0.885811   0.764113   1.021051   \n",
       "143890867.11944.11926   0.934407   0.973923   1.018610   1.163208   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.044573   0.976042   0.979892   1.099157   0.934318   \n",
       "144052463.12169.12169   0.924036   1.102745   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.121714   0.692300   1.117303   1.166274   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \\\n",
       "146743638.12667.12652   1.063603   \n",
       "146842219.12874.12874   0.931161   \n",
       "146860774.13072.13072   0.985920   \n",
       "143890867.11944.11926   1.110955   \n",
       "143902946.11991.11991   0.839036   \n",
       "143945536.12065.12065   1.022813   \n",
       "144052463.12169.12169   0.963547   \n",
       "144065917.12226.12226   0.844266   \n",
       "127296808.516.516       1.001746   \n",
       "127296808.534.516       0.760987   \n",
       "\n",
       "                                                                 content  \n",
       "146743638.12667.12652  I notice that earier that  moved wiki_link to ...  \n",
       "146842219.12874.12874  Chen was known in the poker world as \"William\"...  \n",
       "146860774.13072.13072  I see what you saying I just read his pokersta...  \n",
       "143890867.11944.11926  No more than two editors advocated deletion.  ...  \n",
       "143902946.11991.11991  In the future please don't close Afds when you...  \n",
       "143945536.12065.12065  That simply isn't true.  If you read the comme...  \n",
       "144052463.12169.12169  Somehow, I suspect you may wish to participate...  \n",
       "144065917.12226.12226  I assume your deliberate lying has a point, bu...  \n",
       "127296808.516.516        == Could you stop reverting my corrections ==\\n  \n",
       "127296808.534.516      If you have problems with my edits to the 4WD ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at what the output looks like\n",
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a little bit of cleaning up of the prompt types table. First off, we don't need the content column, as we are just interested in using the prompt type features themselves. Second, in the paper we assigned a max distance cutoff, such that distances were capped at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = prompt_types.drop(columns=\"content\")\n",
    "prompt_types[prompt_types > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.000000   0.925354   1.000000   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.000000   0.885811   0.764113   1.000000   \n",
       "143890867.11944.11926   0.934407   0.973923   1.000000   1.000000   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.000000   0.976042   0.979892   1.000000   0.934318   \n",
       "144052463.12169.12169   0.924036   1.000000   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.000000   0.692300   1.000000   1.000000   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \n",
       "146743638.12667.12652   1.000000  \n",
       "146842219.12874.12874   0.931161  \n",
       "146860774.13072.13072   0.985920  \n",
       "143890867.11944.11926   1.000000  \n",
       "143902946.11991.11991   0.839036  \n",
       "143945536.12065.12065   1.000000  \n",
       "144052463.12169.12169   0.963547  \n",
       "144065917.12226.12226   0.844266  \n",
       "127296808.516.516       1.000000  \n",
       "127296808.534.516       0.760987  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract politeness strategies features\n",
    "\n",
    "Now we will extract the second type of pragmatic features described in the paper: politeness strategies. We can do this using convokit's PolitenessStrategies class. This class does not require any training, so we can just apply it directly to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The politeness strategy features themselves can be accessed via the `feature_df` field of the PolitenessStrategies object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    1   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    0   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  1   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  1   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  1   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              0   \n",
       "146842219.12874.12874                              0   \n",
       "146860774.13072.13072                              0   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              1   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              0   \n",
       "144065917.12226.12226                              0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 0   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "146743638.12652.12652                                       0   \n",
       "146743638.12667.12652                                       1   \n",
       "146842219.12874.12874                                       0   \n",
       "146860774.13072.13072                                       0   \n",
       "143890867.11926.11926                                       0   \n",
       "143890867.11944.11926                                       0   \n",
       "143902946.11991.11991                                       0   \n",
       "143945536.12065.12065                                       0   \n",
       "144052463.12169.12169                                       0   \n",
       "144065917.12226.12226                                       0   \n",
       "\n",
       "                       feature_politeness_==Gratitude==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 1   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                                      ...                   \\\n",
       "146743638.12652.12652                 ...                    \n",
       "146743638.12667.12652                 ...                    \n",
       "146842219.12874.12874                 ...                    \n",
       "146860774.13072.13072                 ...                    \n",
       "143890867.11926.11926                 ...                    \n",
       "143890867.11944.11926                 ...                    \n",
       "143902946.11991.11991                 ...                    \n",
       "143945536.12065.12065                 ...                    \n",
       "144052463.12169.12169                 ...                    \n",
       "144065917.12226.12226                 ...                    \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==Factuality==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==HASPOSITIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   1   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   1   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==HASNEGATIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   1   \n",
       "144065917.12226.12226                                   1   \n",
       "\n",
       "                       feature_politeness_==Indirect_(greeting)==  \\\n",
       "146743638.12652.12652                                           0   \n",
       "146743638.12667.12652                                           0   \n",
       "146842219.12874.12874                                           0   \n",
       "146860774.13072.13072                                           0   \n",
       "143890867.11926.11926                                           0   \n",
       "143890867.11944.11926                                           0   \n",
       "143902946.11991.11991                                           0   \n",
       "143945536.12065.12065                                           0   \n",
       "144052463.12169.12169                                           0   \n",
       "144065917.12226.12226                                           0   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        0   \n",
       "146842219.12874.12874                                        0   \n",
       "146860774.13072.13072                                        0   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        0   \n",
       "\n",
       "                       feature_politeness_==Hedges==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              1   \n",
       "146842219.12874.12874                              1   \n",
       "146860774.13072.13072                              1   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              0   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              1   \n",
       "144065917.12226.12226                              1   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        1   \n",
       "146842219.12874.12874                                        1   \n",
       "146860774.13072.13072                                        1   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        1   \n",
       "\n",
       "                       feature_politeness_==Please_start==  \n",
       "146743638.12652.12652                                    0  \n",
       "146743638.12667.12652                                    0  \n",
       "146842219.12874.12874                                    0  \n",
       "146860774.13072.13072                                    0  \n",
       "143890867.11926.11926                                    0  \n",
       "143890867.11944.11926                                    0  \n",
       "143902946.11991.11991                                    1  \n",
       "143945536.12065.12065                                    0  \n",
       "144052463.12169.12169                                    0  \n",
       "144065917.12226.12226                                    1  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_strategies = ps.feature_df\n",
    "politeness_strategies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create pair data\n",
    "\n",
    "The prediction task defined in the paper is a paired task. The corpus downloaded from convokit already includes metadata about how conversations were paired for the paper, so we don't need to do any of the hard work here. Instead, we'll format the pair information into a table for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to directly map comment IDs to their conversations. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for comment_id in awry_corpus.utterances:\n",
    "    comment = awry_corpus.utterances[comment_id]\n",
    "    # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "    # them as they are not utterances\n",
    "    if not comment.other[\"is_section_header\"]:\n",
    "        comment_ids.append(comment_id)\n",
    "        convo_ids.append(comment.root)\n",
    "        timestamps.append(comment.timestamp)\n",
    "        page_ids.append(comment.other[\"awry_info\"][\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for comment in awry_corpus.utterances.values():\n",
    "    if comment.other[\"awry_info\"][\"conversation_has_personal_attack\"] and comment.root not in awry_convo_ids:\n",
    "        awry_convo_ids.add(comment.root)\n",
    "        good_convo_map[comment.root] = comment.other[\"awry_info\"][\"pair_id\"]\n",
    "        page_id_map[comment.root] = comment.other[\"awry_info\"][\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we will augment the pairs dataframe with the IDs of the first and second comment for both\n",
    "# the bad and good conversation. This will come in handy for constructing the feature matrix.\n",
    "first_ids = []\n",
    "second_ids = []\n",
    "first_ids_bad = []\n",
    "second_ids_bad = []\n",
    "for row in pairs_df.itertuples():\n",
    "    # \"first two\" is defined in terms of time of posting\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==row.conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids.append(comments_sorted.iloc[0].name)\n",
    "    second_ids.append(comments_sorted.iloc[1].name)\n",
    "    comments_sorted_bad = comment_df[comment_df.conversation_id==row.bad_conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids_bad.append(comments_sorted_bad.iloc[0].name)\n",
    "    second_ids_bad.append(comments_sorted_bad.iloc[1].name)\n",
    "pairs_df = pairs_df.assign(first_id=first_ids, second_id=second_ids, \n",
    "                           bad_first_id=first_ids_bad, bad_second_id=second_ids_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Construct feature matrix\n",
    "\n",
    "Now that we have the pair data, we can construct a table of pragmatic features for each pair, to use in prediction. This table will consist of the prompt types and politeness strategies for the first and second comment of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_convo(convo_id, first_comment_id, second_comment_id):\n",
    "\n",
    "    # get prompt type features\n",
    "    try:\n",
    "        first_prompts = prompt_types.loc[first_comment_id]\n",
    "    except:\n",
    "        first_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=prompt_types.columns)\n",
    "    try:\n",
    "        second_prompts = prompt_types.loc[second_comment_id].rename({c: c + \"_second\" for c in prompt_types.columns})\n",
    "    except:\n",
    "        second_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=[c + \"_second\" for c in prompt_types.columns])\n",
    "    prompts = first_prompts.append(second_prompts)\n",
    "    # get politeness strategies features\n",
    "    first_politeness = politeness_strategies.loc[first_comment_id]\n",
    "    second_politeness = politeness_strategies.loc[second_comment_id].rename({c: c + \"_second\" for c in politeness_strategies.columns})\n",
    "    politeness = first_politeness.append(second_politeness)\n",
    "    return politeness.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = np.concatenate((pairs_df.conversation_id.values, pairs_df.bad_conversation_id.values))\n",
    "feats = [features_for_convo(row.conversation_id, row.first_id, row.second_id) for row in pairs_df.itertuples()] + \\\n",
    "        [features_for_convo(row.bad_conversation_id, row.bad_first_id, row.bad_second_id) for row in pairs_df.itertuples()]\n",
    "feature_table = pd.DataFrame(data=np.vstack([f.values for f in feats]), columns=feats[0].index, index=convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper, we dropped the sentiment lexicon based features (HASPOSITIVE and HASNEGATIVE), opting\n",
    "# to instead use them as a baseline. We do this here as well to be consistent with the paper.\n",
    "feature_table = feature_table.drop(columns=[\"feature_politeness_==HASPOSITIVE==\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==\",\n",
    "                                            \"feature_politeness_==HASPOSITIVE==_second\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==_second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>...</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>km_0_dist_second</th>\n",
       "      <th>km_1_dist_second</th>\n",
       "      <th>km_2_dist_second</th>\n",
       "      <th>km_3_dist_second</th>\n",
       "      <th>km_4_dist_second</th>\n",
       "      <th>km_5_dist_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334577218.13132.13132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929931</td>\n",
       "      <td>0.858900</td>\n",
       "      <td>0.907218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.993224</td>\n",
       "      <td>0.915760</td>\n",
       "      <td>0.902573</td>\n",
       "      <td>0.946732</td>\n",
       "      <td>0.973231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500435599.1836.1836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.994861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961873</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875793</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161712789.406.406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996368</td>\n",
       "      <td>0.849388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.954515</td>\n",
       "      <td>0.861167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21267717.3144.3144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>0.921120</td>\n",
       "      <td>0.733448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454816971.89765.89765</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "334577218.13132.13132                                    0.0   \n",
       "500435599.1836.1836                                      0.0   \n",
       "161712789.406.406                                        0.0   \n",
       "21267717.3144.3144                                       0.0   \n",
       "454816971.89765.89765                                    0.0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "334577218.13132.13132                                  1.0   \n",
       "500435599.1836.1836                                    0.0   \n",
       "161712789.406.406                                      0.0   \n",
       "21267717.3144.3144                                     0.0   \n",
       "454816971.89765.89765                                  0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "334577218.13132.13132                                1.0   \n",
       "500435599.1836.1836                                  0.0   \n",
       "161712789.406.406                                    0.0   \n",
       "21267717.3144.3144                                   0.0   \n",
       "454816971.89765.89765                                1.0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "334577218.13132.13132                                 0.0   \n",
       "500435599.1836.1836                                   0.0   \n",
       "161712789.406.406                                     0.0   \n",
       "21267717.3144.3144                                    0.0   \n",
       "454816971.89765.89765                                 0.0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "334577218.13132.13132                                 0.0   \n",
       "500435599.1836.1836                                   0.0   \n",
       "161712789.406.406                                     0.0   \n",
       "21267717.3144.3144                                    0.0   \n",
       "454816971.89765.89765                                 0.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "334577218.13132.13132                                0.0   \n",
       "500435599.1836.1836                                  0.0   \n",
       "161712789.406.406                                    0.0   \n",
       "21267717.3144.3144                                   0.0   \n",
       "454816971.89765.89765                                0.0   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "334577218.13132.13132                            0.0   \n",
       "500435599.1836.1836                              0.0   \n",
       "161712789.406.406                                1.0   \n",
       "21267717.3144.3144                               0.0   \n",
       "454816971.89765.89765                            0.0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "334577218.13132.13132                               0.0   \n",
       "500435599.1836.1836                                 0.0   \n",
       "161712789.406.406                                   0.0   \n",
       "21267717.3144.3144                                  0.0   \n",
       "454816971.89765.89765                               0.0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "334577218.13132.13132                                     0.0   \n",
       "500435599.1836.1836                                       0.0   \n",
       "161712789.406.406                                         0.0   \n",
       "21267717.3144.3144                                        0.0   \n",
       "454816971.89765.89765                                     0.0   \n",
       "\n",
       "                       feature_politeness_==Gratitude==        ...         \\\n",
       "334577218.13132.13132                               0.0        ...          \n",
       "500435599.1836.1836                                 0.0        ...          \n",
       "161712789.406.406                                   1.0        ...          \n",
       "21267717.3144.3144                                  0.0        ...          \n",
       "454816971.89765.89765                               0.0        ...          \n",
       "\n",
       "                       km_2_dist  km_3_dist  km_4_dist  km_5_dist  \\\n",
       "334577218.13132.13132   0.929931   0.858900   0.907218   1.000000   \n",
       "500435599.1836.1836     0.999952   0.994861   1.000000   0.961873   \n",
       "161712789.406.406       1.000000   1.000000   0.996368   0.849388   \n",
       "21267717.3144.3144      1.000000   1.000000   1.000000   1.000000   \n",
       "454816971.89765.89765   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "                       km_0_dist_second  km_1_dist_second  km_2_dist_second  \\\n",
       "334577218.13132.13132          0.991664          0.993224          0.915760   \n",
       "500435599.1836.1836            0.820513          1.000000          0.875793   \n",
       "161712789.406.406              1.000000          0.961678          1.000000   \n",
       "21267717.3144.3144             0.811102          0.869245          0.921120   \n",
       "454816971.89765.89765          0.965988          1.000000          1.000000   \n",
       "\n",
       "                       km_3_dist_second  km_4_dist_second  km_5_dist_second  \n",
       "334577218.13132.13132          0.902573          0.946732          0.973231  \n",
       "500435599.1836.1836            0.845019          1.000000          0.863766  \n",
       "161712789.406.406              0.999943          0.954515          0.861167  \n",
       "21267717.3144.3144             0.733448          1.000000          0.883718  \n",
       "454816971.89765.89765          1.000000          1.000000          1.000000  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it looks\n",
    "feature_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prediction Utils\n",
    "\n",
    "We're almost ready to do the prediction! First we need to define a few helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(seq):\n",
    "    vals, counts = np.unique(seq, return_counts=True)\n",
    "    return vals[np.argmax(counts)]\n",
    "\n",
    "def run_pred_single(inputs, X, y):\n",
    "    f_idx, (train_idx, test_idx) = inputs\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    base_clf = Pipeline([(\"scaler\", StandardScaler()), (\"featselect\", SelectPercentile(f_classif, 10)), (\"logreg\", LogisticRegression())])\n",
    "    clf = GridSearchCV(base_clf, {\"logreg__C\": [10**i for i in range(-4,4)], \"featselect__percentile\": list(range(10, 110, 10))})\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_scores = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    feature_weights = clf.best_estimator_.named_steps[\"logreg\"].coef_.flatten()\n",
    "    feature_mask = clf.best_estimator_.named_steps[\"featselect\"].get_support()\n",
    "    \n",
    "    hyperparams = clf.best_params_\n",
    "    \n",
    "    return (y_pred, y_scores, feature_weights, hyperparams, feature_mask)\n",
    "\n",
    "def run_pred(X, y, fnames, groups):\n",
    "    feature_weights = {}\n",
    "    scores = np.asarray([np.nan for i in range(len(y))])\n",
    "    y_pred = np.zeros(len(y))\n",
    "    hyperparameters = defaultdict(list)\n",
    "    splits = list(enumerate(LeaveOneGroupOut().split(X, y, groups)))\n",
    "    accs = []\n",
    "        \n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        prediction_results = p.map(partial(run_pred_single, X=X, y=y), splits)\n",
    "        \n",
    "    fselect_pvals_all = []\n",
    "    for i in range(len(splits)):\n",
    "        f_idx, (train_idx, test_idx) = splits[i]\n",
    "        y_pred_i, y_scores_i, weights_i, hyperparams_i, mask_i = prediction_results[i]\n",
    "        y_pred[test_idx] = y_pred_i\n",
    "        scores[test_idx] = y_scores_i\n",
    "        feature_weights[f_idx] = np.asarray([np.nan for _ in range(len(fnames))])\n",
    "        feature_weights[f_idx][mask_i] = weights_i\n",
    "        for param in hyperparams_i:\n",
    "            hyperparameters[param].append(hyperparams_i[param])   \n",
    "    \n",
    "    acc = np.mean(y_pred == y)\n",
    "    pvalue = stats.binom_test(sum(y_pred == y), n=len(y), alternative=\"greater\")\n",
    "                \n",
    "    coef_df = pd.DataFrame(feature_weights, index=fnames)\n",
    "    coef_df['mean_coef'] = coef_df.apply(np.nanmean, axis=1)\n",
    "    coef_df['std_coef'] = coef_df.apply(np.nanstd, axis=1)\n",
    "    return acc, coef_df[['mean_coef', 'std_coef']], scores, pd.DataFrame(hyperparameters), pvalue\n",
    "\n",
    "def get_labeled_pairs(pairs_df):\n",
    "    paired_labels = []\n",
    "    c0s = []\n",
    "    c1s = []\n",
    "    page_ids = []\n",
    "    for i, row in enumerate(pairs_df.itertuples()):\n",
    "        if i % 2 == 0:\n",
    "            c0s.append(row.conversation_id)\n",
    "            c1s.append(row.bad_conversation_id)\n",
    "        else:\n",
    "            c0s.append(row.bad_conversation_id)\n",
    "            c1s.append(row.conversation_id)\n",
    "        paired_labels.append(i%2)\n",
    "        page_ids.append(row.page_id)\n",
    "    return pd.DataFrame({\"c0\": c0s, \"c1\": c1s,\"first_convo_toxic\": paired_labels, \"page_id\": page_ids})\n",
    "\n",
    "def get_feature_subset(labeled_pairs_df, feature_list):\n",
    "    prompt_type_names = [\"km_%d_dist\" % i for i in range(6)] + [\"km_%d_dist_second\" % i for i in range(6)]\n",
    "    politeness_names = [f for f in feature_table.columns if f not in prompt_type_names]\n",
    "    \n",
    "    features_to_use = []\n",
    "    if \"prompt_types\" in feature_list:\n",
    "        features_to_use += prompt_type_names\n",
    "    if \"politeness_strategies\" in feature_list:\n",
    "        features_to_use += politeness_names\n",
    "        \n",
    "    feature_subset = feature_table[features_to_use]\n",
    "    \n",
    "    c0_feats = feature_subset.loc[labeled_pairs_df.c0].values\n",
    "    c1_feats = feature_subset.loc[labeled_pairs_df.c1].values\n",
    "    \n",
    "    return c0_feats, c1_feats, features_to_use\n",
    "\n",
    "def run_pipeline(feature_set):\n",
    "    print(\"Running prediction task for feature set\", \"+\".join(feature_set))\n",
    "    print(\"Generating labels...\")\n",
    "    labeled_pairs_df = get_labeled_pairs(pairs_df)\n",
    "    print(\"Computing paired features...\")\n",
    "    X_c0, X_c1, feature_names = get_feature_subset(labeled_pairs_df, feature_set)\n",
    "    X = X_c1 - X_c0\n",
    "    print(\"Using\", X.shape[1], \"features\")\n",
    "    y = labeled_pairs_df.first_convo_toxic.values\n",
    "    print(\"Running leave-one-page-out prediction...\")\n",
    "    accuracy, coefs, scores, hyperparams, pvalue = run_pred(X, y, feature_names, labeled_pairs_df.page_id)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"p-value: %.4e\" % pvalue)\n",
    "    print(\"C (mode):\", mode(hyperparams.logreg__C))\n",
    "    print(\"Percent of features (mode):\", mode(hyperparams.featselect__percentile))\n",
    "    print(\"Coefficents:\")\n",
    "    print(coefs.sort_values(by=\"mean_coef\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Prediction\n",
    "\n",
    "Finally, we run the prediction task on each possible combination of pragmatic features: prompt types, politeness strategies, and both combined. We generate a table like Table 3 from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction task for feature set politeness_strategies\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 38 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6157480314960629\n",
      "p-value: 2.9586e-09\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 70\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.163711  0.071940\n",
      "feature_politeness_==2nd_person_start==_second     -0.124865  0.052696\n",
      "feature_politeness_==2nd_person_start==            -0.112045  0.049253\n",
      "feature_politeness_==Direct_question==_second      -0.108904  0.046623\n",
      "feature_politeness_==Direct_question==             -0.089929  0.036005\n",
      "feature_politeness_==Please_start==_second         -0.084492  0.036633\n",
      "feature_politeness_==Indirect_(btw)==              -0.074002  0.038853\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.032392  0.014516\n",
      "feature_politeness_==Factuality==                  -0.026775  0.013795\n",
      "feature_politeness_==Direct_start==                -0.019770  0.016859\n",
      "feature_politeness_==Please==                      -0.018108  0.010442\n",
      "feature_politeness_==Please_start==                -0.017521  0.007287\n",
      "feature_politeness_==Direct_start==_second         -0.010665  0.009199\n",
      "feature_politeness_==1st_person_pl.==              -0.008829  0.006007\n",
      "feature_politeness_==Factuality==_second           -0.005294  0.004058\n",
      "feature_politeness_==INDICATIVE==                  -0.004690  0.002847\n",
      "feature_politeness_==2nd_person==                  -0.003690  0.004653\n",
      "feature_politeness_==Please==_second                0.001638  0.001437\n",
      "feature_politeness_==1st_person_start==             0.003241  0.004912\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.004793  0.002655\n",
      "feature_politeness_==Apologizing==                  0.008643  0.005858\n",
      "feature_politeness_==Deference==_second             0.009531  0.004918\n",
      "feature_politeness_==1st_person==                   0.010498  0.004134\n",
      "feature_politeness_==1st_person_pl.==_second        0.017011  0.008379\n",
      "feature_politeness_==Deference==                    0.020639  0.013355\n",
      "feature_politeness_==Hedges==_second                0.024370  0.009449\n",
      "feature_politeness_==INDICATIVE==_second            0.031623  0.022352\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.039268  0.017754\n",
      "feature_politeness_==Hedges==                       0.054614  0.022767\n",
      "feature_politeness_==Apologizing==_second           0.060054  0.028351\n",
      "feature_politeness_==1st_person==_second            0.061370  0.026182\n",
      "feature_politeness_==Gratitude==                    0.067106  0.028292\n",
      "feature_politeness_==HASHEDGE==                     0.072342  0.034301\n",
      "feature_politeness_==Gratitude==_second             0.082968  0.034824\n",
      "feature_politeness_==1st_person_start==_second      0.087078  0.036821\n",
      "feature_politeness_==HASHEDGE==_second              0.104224  0.050314\n",
      "feature_politeness_==Indirect_(greeting)==          0.137248  0.064106\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.145372  0.082282\n",
      "Running prediction task for feature set prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 12 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.5984251968503937\n",
      "p-value: 3.9872e-07\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 100\n",
      "Coefficents:\n",
      "                  mean_coef  std_coef\n",
      "km_2_dist         -0.106185  0.019508\n",
      "km_2_dist_second  -0.076551  0.013559\n",
      "km_3_dist_second  -0.057837  0.010198\n",
      "km_3_dist         -0.052581  0.008789\n",
      "km_5_dist         -0.012602  0.001995\n",
      "km_0_dist_second   0.002451  0.003295\n",
      "km_0_dist          0.028247  0.003881\n",
      "km_5_dist_second   0.028546  0.002477\n",
      "km_4_dist_second   0.055431  0.009246\n",
      "km_1_dist          0.058603  0.009962\n",
      "km_1_dist_second   0.090620  0.015988\n",
      "km_4_dist          0.108099  0.019648\n",
      "Running prediction task for feature set politeness_strategies+prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 50 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6299212598425197\n",
      "p-value: 2.9879e-11\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 60\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.049739  0.062651\n",
      "feature_politeness_==2nd_person_start==_second     -0.039761  0.049111\n",
      "feature_politeness_==Direct_question==_second      -0.034138  0.042115\n",
      "feature_politeness_==2nd_person_start==            -0.031876  0.038125\n",
      "km_2_dist                                          -0.026354  0.028961\n",
      "feature_politeness_==Direct_question==             -0.026233  0.030026\n",
      "feature_politeness_==Please_start==_second         -0.023511  0.026816\n",
      "feature_politeness_==Indirect_(btw)==              -0.018316  0.028224\n",
      "km_2_dist_second                                   -0.016954  0.014946\n",
      "km_3_dist_second                                   -0.016815  0.017106\n",
      "km_3_dist                                          -0.012158  0.009674\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.010150  0.006501\n",
      "feature_politeness_==Factuality==                  -0.008642  0.004716\n",
      "feature_politeness_==Direct_start==                -0.005713  0.000879\n",
      "feature_politeness_==Please==                      -0.005508  0.000600\n",
      "km_0_dist_second                                   -0.004438  0.004967\n",
      "feature_politeness_==Please_start==                -0.003664  0.002423\n",
      "feature_politeness_==INDICATIVE==                  -0.003320  0.000405\n",
      "feature_politeness_==1st_person_pl.==              -0.002249  0.000524\n",
      "feature_politeness_==2nd_person==                  -0.001718  0.000529\n",
      "feature_politeness_==Factuality==_second           -0.001605  0.000508\n",
      "feature_politeness_==Direct_start==_second         -0.000847  0.000497\n",
      "km_0_dist                                           0.001122  0.012753\n",
      "feature_politeness_==Apologizing==                  0.001452  0.000543\n",
      "feature_politeness_==Please==_second                0.001662  0.000625\n",
      "km_5_dist                                           0.002775  0.000436\n",
      "feature_politeness_==1st_person==                   0.003219  0.002504\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.003648  0.000615\n",
      "feature_politeness_==1st_person_start==             0.003987  0.002675\n",
      "feature_politeness_==Deference==                    0.005552  0.000673\n",
      "feature_politeness_==Deference==_second             0.005703  0.000669\n",
      "feature_politeness_==1st_person_pl.==_second        0.006134  0.001875\n",
      "feature_politeness_==INDICATIVE==_second            0.007137  0.000672\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.009772  0.012324\n",
      "km_5_dist_second                                    0.010065  0.011496\n",
      "feature_politeness_==Hedges==_second                0.011862  0.010547\n",
      "feature_politeness_==Hedges==                       0.014978  0.015506\n",
      "feature_politeness_==Apologizing==_second           0.016792  0.024415\n",
      "km_4_dist_second                                    0.017154  0.015940\n",
      "km_1_dist                                           0.019216  0.018936\n",
      "feature_politeness_==1st_person==_second            0.020168  0.024319\n",
      "km_1_dist_second                                    0.021704  0.020572\n",
      "feature_politeness_==Gratitude==                    0.021763  0.026397\n",
      "feature_politeness_==HASHEDGE==                     0.023895  0.028308\n",
      "feature_politeness_==1st_person_start==_second      0.025378  0.027975\n",
      "feature_politeness_==Gratitude==_second             0.025488  0.029476\n",
      "feature_politeness_==HASHEDGE==_second              0.030979  0.036128\n",
      "km_4_dist                                           0.034127  0.040434\n",
      "feature_politeness_==Indirect_(greeting)==          0.036122  0.043678\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.040076  0.052489\n"
     ]
    }
   ],
   "source": [
    "feature_combos = [[\"politeness_strategies\"], [\"prompt_types\"], [\"politeness_strategies\", \"prompt_types\"]]\n",
    "combo_names = []\n",
    "accs = []\n",
    "for combo in feature_combos:\n",
    "    combo_names.append(\"+\".join(combo).replace(\"_\", \" \"))\n",
    "    accuracy = run_pipeline(combo)\n",
    "    accs.append(accuracy)\n",
    "results_df = pd.DataFrame({\"Accuracy\": accs}, index=combo_names)\n",
    "results_df.index.name = \"Feature set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politeness strategies</th>\n",
       "      <td>0.615748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt types</th>\n",
       "      <td>0.598425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politeness strategies+prompt types</th>\n",
       "      <td>0.629921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy\n",
       "Feature set                                 \n",
       "politeness strategies               0.615748\n",
       "prompt types                        0.598425\n",
       "politeness strategies+prompt types  0.629921"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the table\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Comparing features exhibited\n",
    "\n",
    "We can also compare how often the pragmatic devices we extracted occur in the initial exchanges of conversations that turn awry, vs. conversations that stay on track. We will compute log-odds ratios of each device, comparing the awry and on-track conversations; we will also compute significance values from binomal tests comparing the proportion of awry-turning conversations exhibiting a particular device to the proportion of on-track conversations.\n",
    "\n",
    "Since we've already got the pragmatic features precomputed, and our dataset of pairs compiled, it remains to compute the effect sizes and statistical significances, and plot these values, producing a plot like Figure 2 from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up the politeness features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_name(feat):\n",
    "    new_feat = feat.replace('feature_politeness','').replace('==','').replace('_', ' ')\n",
    "    split = new_feat.split()\n",
    "    first, rest = split[0], ' '.join(split[1:]).lower()\n",
    "    if first[0].isalpha():\n",
    "        first = first.title()\n",
    "    if 'Hashedge' in first:\n",
    "        return 'Hedge (lexicon)'\n",
    "    if 'Hedges' in first:\n",
    "        return 'Hedge (dep. tree)'\n",
    "    if 'greeting' in feat:\n",
    "        return 'Greetings'\n",
    "    cleaner_str = first + ' ' + rest\n",
    "    cleaner_str = cleaner_str.replace('2nd', '2$\\mathregular{^{nd}}$').replace('1st', '1$\\mathregular{^{st}}$')\n",
    "    return cleaner_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_strategies = politeness_strategies[[col for col in politeness_strategies.columns \n",
    "                              if col not in ['feature_politeness_==HASNEGATIVE==', 'feature_politeness_==HASPOSITIVE==']]]\n",
    "politeness_strategies.columns = [clean_feature_name(col) for col in politeness_strategies.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up prompt types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type_names = ['Prompt: Casual remark', 'Prompt: Moderation', 'Prompt: Opinion', \n",
    "                     'Prompt: Coordination', 'Prompt: Factual check', 'Prompt: Action statement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are now counting the number of times comments were assigned to *particular* prompt types, \n",
    "# we will use cluster assignments rather than distances\n",
    "prompt_type_assignments = np.zeros_like(prompt_types)\n",
    "prompt_type_assignments[np.arange(len(prompt_types)),prompt_types.values.argmin(axis=1)] = 1\n",
    "prompt_type_assignment_df = pd.DataFrame(columns=prompt_type_names, index=prompt_types.index, \n",
    "                                        data=prompt_type_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a table of combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_features = pd.concat([prompt_type_assignment_df, politeness_strategies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group features by clean versus toxic conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_first_comment_features =pairs_df[['bad_first_id']].join(all_features, how='left', on='bad_first_id')[all_features.columns]\n",
    "ntox_first_comment_features =pairs_df[['first_id']].join(all_features, how='left', on='first_id')[all_features.columns]\n",
    "\n",
    "tox_second_comment_features =pairs_df[['bad_second_id']].join(all_features, how='left', on='bad_second_id')[all_features.columns]\n",
    "ntox_second_comment_features =pairs_df[['second_id']].join(all_features, how='left', on='second_id')[all_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_stars(x):\n",
    "    if x < .001: return '***'\n",
    "    elif x < .01: return '**'\n",
    "    elif x < .05: return '*'\n",
    "    else: return ''\n",
    "def compare_tox(df_ntox, df_tox,  min_n=0):\n",
    "    cols = df_ntox.columns\n",
    "    num_feats_in_tox = df_tox[cols].sum().astype(int).rename('num_feat_tox')\n",
    "    num_nfeats_in_tox = (1 - df_tox[cols]).sum().astype(int).rename('num_nfeat_tox')\n",
    "    num_feats_in_ntox = df_ntox[cols].sum().astype(int).rename('num_feat_ntox')\n",
    "    num_nfeats_in_ntox = (1 - df_ntox[cols]).sum().astype(int).rename('num_nfeat_ntox')\n",
    "    prop_tox = df_tox[cols].mean().rename('prop_tox')\n",
    "    ref_prop_ntox = df_ntox[cols].mean().rename('prop_ntox')\n",
    "    n_tox = len(df_tox)\n",
    "    df = pd.concat([\n",
    "        num_feats_in_tox, \n",
    "        num_nfeats_in_tox,\n",
    "        num_feats_in_ntox,\n",
    "        num_nfeats_in_ntox,\n",
    "        prop_tox,\n",
    "        ref_prop_ntox,\n",
    "    ], axis=1)\n",
    "    df['num_total'] = df.num_feat_tox + df.num_feat_ntox\n",
    "    df['log_odds'] = np.log(df.num_feat_tox) - np.log(df.num_nfeat_tox) \\\n",
    "        + np.log(df.num_nfeat_ntox) - np.log(df.num_feat_ntox)\n",
    "    df['abs_log_odds'] = np.abs(df.log_odds)\n",
    "    df['binom_p'] = df.apply(lambda x: stats.binom_test(x.num_feat_tox, n_tox, x.prop_ntox), axis=1)\n",
    "    df = df[df.num_total >= min_n]\n",
    "    df['p'] = df['binom_p'].apply(lambda x: '%.3f' % x)\n",
    "    df['pstars'] = df['binom_p'].apply(get_p_stars)\n",
    "    return df.sort_values('log_odds', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_comparisons = compare_tox(ntox_first_comment_features, tox_first_comment_features)\n",
    "second_comparisons = compare_tox(ntox_second_comment_features, tox_second_comment_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are now ready to plot these comparisons. the following (rather intimidating) helper function \n",
    "# produces a nicely-formatted plot:\n",
    "def draw_figure(ax, first_cmp, second_cmp, title='', prompt_types=6, min_log_odds=.2, min_freq=50,xlim=.85):\n",
    "\n",
    "    # selecting and sorting the features to plot, given minimum effect sizes and statistical significance\n",
    "    frequent_feats = first_cmp[first_cmp.num_total >= min_freq].index.union(second_cmp[second_cmp.num_total >= min_freq].index)\n",
    "    lrg_effect_feats = first_cmp[(first_cmp.abs_log_odds >= .2)\n",
    "                                & (first_cmp.binom_p < .05)].index.union(second_cmp[(second_cmp.abs_log_odds >= .2)\n",
    "                                                                                  & (second_cmp.binom_p < .05)].index)\n",
    "    feats_to_include = frequent_feats.intersection(lrg_effect_feats)\n",
    "    feat_order = sorted(feats_to_include, key=lambda x: first_cmp.loc[x].log_odds, reverse=True)\n",
    "\n",
    "    # parameters determining the look of the figure\n",
    "    colors = ['darkorchid', 'seagreen']\n",
    "    shapes = ['d', 's']    \n",
    "    eps = .02\n",
    "    star_eps = .035\n",
    "    xlim = xlim\n",
    "    min_log = .2\n",
    "    gap_prop = 2\n",
    "    label_size = 14\n",
    "    title_size=18\n",
    "    radius = 144\n",
    "    features = feat_order\n",
    "    ax.invert_yaxis()\n",
    "    ax.plot([0,0], [0, len(features)/gap_prop], color='black')\n",
    "    \n",
    "    # for each figure we plot the point according to effect size in the first and second comment, \n",
    "    # and add axis labels denoting statistical significance\n",
    "    yticks = []\n",
    "    yticklabels = []\n",
    "    for f_idx, feat in enumerate(features):\n",
    "        curr_y = (f_idx + .5)/gap_prop\n",
    "        yticks.append(curr_y)\n",
    "        try:\n",
    "            \n",
    "            first_p = first_cmp.loc[feat].binom_p\n",
    "            second_p = second_cmp.loc[feat].binom_p            \n",
    "            if first_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                first_face = \"white\"\n",
    "            elif first_p >= 0.05:\n",
    "                first_face = 'white'\n",
    "            else:\n",
    "                first_face = colors[0]\n",
    "            if second_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                second_face = \"white\"\n",
    "            elif second_p >= 0.05:\n",
    "                second_face = 'white'\n",
    "            else:\n",
    "                second_face = colors[1]\n",
    "            ax.plot([-1 * xlim, xlim], [curr_y, curr_y], '--', color='grey', zorder=0, linewidth=.5)\n",
    "            \n",
    "            ax.scatter([first_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[0], marker=shapes[0],\n",
    "                        zorder=20, facecolors=first_face)\n",
    "            ax.scatter([second_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[1], marker=shapes[1], \n",
    "                       zorder=10, facecolors=second_face)\n",
    "            \n",
    "            first_pstr_len = len(get_p_stars(first_p))\n",
    "            second_pstr_len = len(get_p_stars(second_p))\n",
    "            p_str = np.array([' '] * 8)\n",
    "            if first_pstr_len > 0:\n",
    "                p_str[:first_pstr_len] = '*'\n",
    "            if second_pstr_len > 0:\n",
    "                p_str[-second_pstr_len:] = '⁺'\n",
    "            \n",
    "            feat_str = feat + '\\n' + ''.join(p_str)\n",
    "            yticklabels.append(feat_str)\n",
    "        except Exception as e:\n",
    "            yticklabels.append('')\n",
    "    \n",
    "    # add the axis labels\n",
    "    ax.set_xlabel('log-odds ratio', fontsize=14, family='serif')\n",
    "    ax.set_xticks([-xlim-.05, -.5, 0, .5, xlim])\n",
    "    ax.set_xticklabels(['on-track', -.5, 0, .5, 'awry'], fontsize=14, family='serif')\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels, fontsize=16, family='serif')\n",
    "    ax.tick_params(axis='both',  which='both', bottom='off',  top='off',left='off')\n",
    "    if title != '':\n",
    "        ax.text(0, (len(features) + 2.25)/ gap_prop, title, fontsize=title_size, family='serif',horizontalalignment='center',)\n",
    "    return feat_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(5,10))\n",
    "_ = draw_figure(ax, first_comparisons, second_comparisons, 'First & second comment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
