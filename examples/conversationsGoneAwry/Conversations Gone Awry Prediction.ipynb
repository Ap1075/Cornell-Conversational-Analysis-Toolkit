{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Conversations Gone Awry With Convokit\n",
    "\n",
    "This interactive tutorial demonstrates how to predict whether a conversation will eventually lead to a personal attack, as seen in the paper [Conversations Gone Awry: Detecting Early Signs of Conversational Failure](http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html), using the tools provided by convokit. It also serves as an illustration of how to use two of convokit's main features: question typology and politeness strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import json\n",
    "import itertools\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "from convokit import Corpus, QuestionTypology, download, MotifsExtractor, QuestionTypologyUtils, PolitenessStrategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Conversations Gone Awry corpus, provided as part of convokit\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\")):\n",
    "    download(\"conversations-gone-awry-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a convokit Corpus object from the downloaded data. The Corpus class provides functionality for\n",
    "# convenient manipulation of text corpora.\n",
    "awry_corpus = Corpus(filename=os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract prompt types features\n",
    "\n",
    "In this step, we will extract the first of the two types of pragmatic features seen in the paper: prompt types. We can learn prompt types and compute types for each utterance in the corpus using convokit's QuestionTypology class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train the QuestionTypology object on convokit's wiki corpus. Let's first download the corpus...\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"wiki-corpus\")):\n",
    "    download(\"wiki-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a QuestionTypology object on the downloaded wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prefix /scratch/convokit_spacy_dump/spacy for spacy\n",
      "loading spacy NLP\n",
      "running motif extraction pipeline\n",
      "loading spacy vocab\n",
      "loading spacy vocab\n",
      "getting question arcs\n",
      "reading spacy\n",
      "\twriting arcs\n",
      "making motif tree\n",
      "\treading arcs\n",
      "\tcounting itemsets\n",
      "\tfirst pass\n",
      "\tand then the rest\n",
      "\t 6 18623\n",
      "\t 7 4867\n",
      "\t 8 2724\n",
      "\t 9 1295\n",
      "\t 10 867\n",
      "\t 11 534\n",
      "\t 12 188\n",
      "\t 13 116\n",
      "\t 14 20\n",
      "\t 15 20\n",
      "\twriting itemsets\n",
      "\tbuilding tree\n",
      "fitting motifs to questions\n",
      "\treading tree\n",
      "\tfitting arcsets\n",
      "\twriting fits\n",
      "handling redundant motifs\n",
      "\treading raw fits\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tcounting cooccs\n",
      "\tdeduplicating\n",
      "\twriting\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tmaking new entries\n",
      "done motif extraction\n",
      "running answer arc pipeline\n",
      "\tmotif dir /home/jonathan/research/Cornell-Conversational-Analysis-Toolkit/convokit/downloads/wiki-corpus-awry-motifs exists!\n",
      "loading spacy vocab\n",
      "loading spacy vocab\n",
      "getting answer arcs\n",
      "reading spacy\n",
      "\twriting arcs\n",
      "done answer arc extraction\n",
      "building q-a matrices\n",
      "\treading arcs and motifs\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tbuilding matrices\n",
      "\twriting stuff\n",
      "reading question tidxes\n",
      "reading question leaves\n",
      "reading answer tidxes\n",
      "reading question didxes\n",
      "reading answer didxes\n",
      "reading question terms\n",
      "reading answer terms\n",
      "reading docs\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# some parameters to get us started. Note that \"dataset name\" refers not to the name of the *source* dataset,\n",
    "# but the name we want to give to trained output files of the QuestionTypology object. We could have given\n",
    "# any name we liked - we chose \"wiki-corpus-awry\" to keep things clear.\n",
    "dataset_name = \"wiki-corpus-awry\"\n",
    "num_clusters = 6\n",
    "\n",
    "# load the wiki corpus into a convokit Corpus object\n",
    "data_dir = os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), 'downloads')\n",
    "corpus = Corpus(filename=os.path.join(data_dir, 'wiki-corpus'))\n",
    "\n",
    "# if this is our first time running this example, we need to fit motifs on the\n",
    "# dataset. If we have run it before, just load the previously computed motifs\n",
    "motifs_dir = os.path.join(data_dir, dataset_name + \"-motifs\")\n",
    "if not os.path.exists(motifs_dir):\n",
    "    motifs_dir = None\n",
    "\n",
    "questionTypology = QuestionTypology(corpus, data_dir, dataset_name=dataset_name, motifs_dir=motifs_dir,\n",
    "                                    num_dims=50, num_clusters=6, question_threshold=100, answer_threshold=100, \n",
    "                                    verbose=1000000, random_seed=2018, min_support=20,\n",
    "                                    questions_only=False, enforce_formatting=False,\n",
    "                                    spacy_dir=\"/scratch/convokit_spacy_dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the QuestionTypology object has been trained, we can use it to compute prompt types for our awry corpus (notice that this is a different corpus from what the QuestionTypology object was trained on!). For our purposes, we want the raw features, which are distances from the centers of the KMeans clusters corresponding to each prompt type. We can get these using the `get_qtype_dists` method. Note that in most other situations, where we want just the prompt type, we can use the QuestionTypology object as a Callable, which will return an integer prompt type for each utterance in the corpus. We could also use the `compute_type` function, which is aliased to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = questionTypology.get_qtype_dists(awry_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.100313</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.052824</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.063603</td>\n",
       "      <td>I notice that earier that  moved wiki_link to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "      <td>Chen was known in the poker world as \"William\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.048260</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.021051</td>\n",
       "      <td>0.985920</td>\n",
       "      <td>I see what you saying I just read his pokersta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.018610</td>\n",
       "      <td>1.163208</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.110955</td>\n",
       "      <td>No more than two editors advocated deletion.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>In the future please don't close Afds when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.044573</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.099157</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.022813</td>\n",
       "      <td>That simply isn't true.  If you read the comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.102745</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>Somehow, I suspect you may wish to participate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "      <td>I assume your deliberate lying has a point, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.121714</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.117303</td>\n",
       "      <td>1.166274</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.001746</td>\n",
       "      <td>== Could you stop reverting my corrections ==\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>If you have problems with my edits to the 4WD ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.100313   0.925354   1.052824   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.048260   0.885811   0.764113   1.021051   \n",
       "143890867.11944.11926   0.934407   0.973923   1.018610   1.163208   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.044573   0.976042   0.979892   1.099157   0.934318   \n",
       "144052463.12169.12169   0.924036   1.102745   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.121714   0.692300   1.117303   1.166274   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \\\n",
       "146743638.12667.12652   1.063603   \n",
       "146842219.12874.12874   0.931161   \n",
       "146860774.13072.13072   0.985920   \n",
       "143890867.11944.11926   1.110955   \n",
       "143902946.11991.11991   0.839036   \n",
       "143945536.12065.12065   1.022813   \n",
       "144052463.12169.12169   0.963547   \n",
       "144065917.12226.12226   0.844266   \n",
       "127296808.516.516       1.001746   \n",
       "127296808.534.516       0.760987   \n",
       "\n",
       "                                                                 content  \n",
       "146743638.12667.12652  I notice that earier that  moved wiki_link to ...  \n",
       "146842219.12874.12874  Chen was known in the poker world as \"William\"...  \n",
       "146860774.13072.13072  I see what you saying I just read his pokersta...  \n",
       "143890867.11944.11926  No more than two editors advocated deletion.  ...  \n",
       "143902946.11991.11991  In the future please don't close Afds when you...  \n",
       "143945536.12065.12065  That simply isn't true.  If you read the comme...  \n",
       "144052463.12169.12169  Somehow, I suspect you may wish to participate...  \n",
       "144065917.12226.12226  I assume your deliberate lying has a point, bu...  \n",
       "127296808.516.516        == Could you stop reverting my corrections ==\\n  \n",
       "127296808.534.516      If you have problems with my edits to the 4WD ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at what the output looks like\n",
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a little bit of cleaning up of the prompt types table. First off, we don't need the content column, as we are just interested in using the prompt type features themselves. Second, in the paper we assigned a max distance cutoff, such that distances were capped at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = prompt_types.drop(columns=\"content\")\n",
    "prompt_types[prompt_types > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.000000   0.925354   1.000000   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.000000   0.885811   0.764113   1.000000   \n",
       "143890867.11944.11926   0.934407   0.973923   1.000000   1.000000   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.000000   0.976042   0.979892   1.000000   0.934318   \n",
       "144052463.12169.12169   0.924036   1.000000   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.000000   0.692300   1.000000   1.000000   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \n",
       "146743638.12667.12652   1.000000  \n",
       "146842219.12874.12874   0.931161  \n",
       "146860774.13072.13072   0.985920  \n",
       "143890867.11944.11926   1.000000  \n",
       "143902946.11991.11991   0.839036  \n",
       "143945536.12065.12065   1.000000  \n",
       "144052463.12169.12169   0.963547  \n",
       "144065917.12226.12226   0.844266  \n",
       "127296808.516.516       1.000000  \n",
       "127296808.534.516       0.760987  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract politeness strategies features\n",
    "\n",
    "Now we will extract the second type of pragmatic features described in the paper: politeness strategies. We can do this using convokit's PolitenessStrategies class. This class does not require any training, so we can just apply it directly to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The politeness strategy features themselves can be accessed via the `feature_df` field of the PolitenessStrategies object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Factuality==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        0   \n",
       "146842219.12874.12874                                        0   \n",
       "146860774.13072.13072                                        0   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==HASNEGATIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   1   \n",
       "144065917.12226.12226                                   1   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  1   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  1   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        1   \n",
       "146842219.12874.12874                                        1   \n",
       "146860774.13072.13072                                        1   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        1   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "146743638.12652.12652                                       0   \n",
       "146743638.12667.12652                                       1   \n",
       "146842219.12874.12874                                       0   \n",
       "146860774.13072.13072                                       0   \n",
       "143890867.11926.11926                                       0   \n",
       "143890867.11944.11926                                       0   \n",
       "143902946.11991.11991                                       0   \n",
       "143945536.12065.12065                                       0   \n",
       "144052463.12169.12169                                       0   \n",
       "144065917.12226.12226                                       0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  1   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                                     ...                 \\\n",
       "146743638.12652.12652                ...                  \n",
       "146743638.12667.12652                ...                  \n",
       "146842219.12874.12874                ...                  \n",
       "146860774.13072.13072                ...                  \n",
       "143890867.11926.11926                ...                  \n",
       "143890867.11944.11926                ...                  \n",
       "143902946.11991.11991                ...                  \n",
       "143945536.12065.12065                ...                  \n",
       "144052463.12169.12169                ...                  \n",
       "144065917.12226.12226                ...                  \n",
       "\n",
       "                       feature_politeness_==Hedges==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              1   \n",
       "146842219.12874.12874                              1   \n",
       "146860774.13072.13072                              1   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              0   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              1   \n",
       "144065917.12226.12226                              1   \n",
       "\n",
       "                       feature_politeness_==Indirect_(greeting)==  \\\n",
       "146743638.12652.12652                                           0   \n",
       "146743638.12667.12652                                           0   \n",
       "146842219.12874.12874                                           0   \n",
       "146860774.13072.13072                                           0   \n",
       "143890867.11926.11926                                           0   \n",
       "143890867.11944.11926                                           0   \n",
       "143902946.11991.11991                                           0   \n",
       "143945536.12065.12065                                           0   \n",
       "144052463.12169.12169                                           0   \n",
       "144065917.12226.12226                                           0   \n",
       "\n",
       "                       feature_politeness_==HASPOSITIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   1   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   1   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    1   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    0   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==HASHEDGE==  \\\n",
       "146743638.12652.12652                                0   \n",
       "146743638.12667.12652                                1   \n",
       "146842219.12874.12874                                1   \n",
       "146860774.13072.13072                                1   \n",
       "143890867.11926.11926                                0   \n",
       "143890867.11944.11926                                1   \n",
       "143902946.11991.11991                                0   \n",
       "143945536.12065.12065                                0   \n",
       "144052463.12169.12169                                1   \n",
       "144065917.12226.12226                                1   \n",
       "\n",
       "                       feature_politeness_==Please_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    0   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    1   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    1   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              0   \n",
       "146842219.12874.12874                              0   \n",
       "146860774.13072.13072                              0   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              1   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              0   \n",
       "144065917.12226.12226                              0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \n",
       "146743638.12652.12652                                 0  \n",
       "146743638.12667.12652                                 0  \n",
       "146842219.12874.12874                                 0  \n",
       "146860774.13072.13072                                 0  \n",
       "143890867.11926.11926                                 0  \n",
       "143890867.11944.11926                                 0  \n",
       "143902946.11991.11991                                 0  \n",
       "143945536.12065.12065                                 0  \n",
       "144052463.12169.12169                                 0  \n",
       "144065917.12226.12226                                 0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_strategies = ps.feature_df\n",
    "politeness_strategies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create pair data\n",
    "\n",
    "The prediction task defined in the paper is a paired task. The corpus downloaded from convokit already includes metadata about how conversations were paired for the paper, so we don't need to do any of the hard work here. Instead, we'll format the pair information into a table for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to directly map conversation IDs to their comments. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for comment_id in awry_corpus.utterances:\n",
    "    comment = awry_corpus.utterances[comment_id]\n",
    "    # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "    # them as they are not utterances\n",
    "    if not comment.other[\"is_section_header\"]:\n",
    "        comment_ids.append(comment_id)\n",
    "        convo_ids.append(comment.root)\n",
    "        timestamps.append(comment.timestamp)\n",
    "        page_ids.append(comment.other[\"awry_info\"][\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for comment in awry_corpus.utterances.values():\n",
    "    if comment.other[\"awry_info\"][\"conversation_has_personal_attack\"] and comment.root not in awry_convo_ids:\n",
    "        awry_convo_ids.add(comment.root)\n",
    "        good_convo_map[comment.root] = comment.other[\"awry_info\"][\"pair_id\"]\n",
    "        page_id_map[comment.root] = comment.other[\"awry_info\"][\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Construct feature matrix\n",
    "\n",
    "Now that we have the pair data, we can construct a table of pragmatic features for each pair, to use in prediction. This table will consist of the prompt types and politeness strategies for the first and second comment of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_convo(convo_id):\n",
    "    \n",
    "    # first, get the first two comments (IDs) by timestamp in the conversation\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==convo_id].sort_values(by=\"timestamp\")\n",
    "    first_id = comments_sorted.iloc[0].name\n",
    "    second_id = comments_sorted.iloc[1].name\n",
    "    # get prompt type features\n",
    "    try:\n",
    "        first_prompts = prompt_types.loc[first_id]\n",
    "    except:\n",
    "        first_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=prompt_types.columns)\n",
    "    try:\n",
    "        second_prompts = prompt_types.loc[second_id].rename({c: c + \"_second\" for c in prompt_types.columns})\n",
    "    except:\n",
    "        second_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=[c + \"_second\" for c in prompt_types.columns])\n",
    "    prompts = first_prompts.append(second_prompts)\n",
    "    # get politeness strategies features\n",
    "    first_politeness = politeness_strategies.loc[first_id]\n",
    "    second_politeness = politeness_strategies.loc[second_id].rename({c: c + \"_second\" for c in politeness_strategies.columns})\n",
    "    politeness = first_politeness.append(second_politeness)\n",
    "    return politeness.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = pairs_df.bad_conversation_id.append(pairs_df.conversation_id, ignore_index=True)\n",
    "feats = [features_for_convo(cid) for cid in convo_ids]\n",
    "feature_table = pd.DataFrame(data=np.vstack([f.values for f in feats]), columns=feats[0].index, index=convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper, we dropped the sentiment lexicon based features (HASPOSITIVE and HASNEGATIVE), opting\n",
    "# to instead use them as a baseline. We do this here as well to be consistent with the paper.\n",
    "feature_table = feature_table.drop(columns=[\"feature_politeness_==HASPOSITIVE==\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==\",\n",
    "                                            \"feature_politeness_==HASPOSITIVE==_second\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==_second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>...</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>km_0_dist_second</th>\n",
       "      <th>km_1_dist_second</th>\n",
       "      <th>km_2_dist_second</th>\n",
       "      <th>km_3_dist_second</th>\n",
       "      <th>km_4_dist_second</th>\n",
       "      <th>km_5_dist_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18396841.5729.5729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977602</td>\n",
       "      <td>0.993605</td>\n",
       "      <td>0.883546</td>\n",
       "      <td>0.917872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730552237.426.426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916550</td>\n",
       "      <td>0.828698</td>\n",
       "      <td>0.965470</td>\n",
       "      <td>0.844919</td>\n",
       "      <td>0.982614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242190235.3043.3043</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918752</td>\n",
       "      <td>0.667591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906846</td>\n",
       "      <td>0.811177</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.899894</td>\n",
       "      <td>0.720774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59573834.9091.9091</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.809121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924410</td>\n",
       "      <td>0.994450</td>\n",
       "      <td>0.887890</td>\n",
       "      <td>0.976113</td>\n",
       "      <td>0.916845</td>\n",
       "      <td>0.988414</td>\n",
       "      <td>0.940218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448449304.24597.24597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980467</td>\n",
       "      <td>0.970249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863152</td>\n",
       "      <td>0.969705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Factuality==  \\\n",
       "18396841.5729.5729                                   0.0   \n",
       "730552237.426.426                                    0.0   \n",
       "242190235.3043.3043                                  0.0   \n",
       "59573834.9091.9091                                   0.0   \n",
       "448449304.24597.24597                                0.0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "18396841.5729.5729                                    0.0   \n",
       "730552237.426.426                                     1.0   \n",
       "242190235.3043.3043                                   0.0   \n",
       "59573834.9091.9091                                    0.0   \n",
       "448449304.24597.24597                                 0.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "18396841.5729.5729                                         1.0   \n",
       "730552237.426.426                                          1.0   \n",
       "242190235.3043.3043                                        0.0   \n",
       "59573834.9091.9091                                         0.0   \n",
       "448449304.24597.24597                                      0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "18396841.5729.5729                                       0.0   \n",
       "730552237.426.426                                        0.0   \n",
       "242190235.3043.3043                                      0.0   \n",
       "59573834.9091.9091                                       0.0   \n",
       "448449304.24597.24597                                    0.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "18396841.5729.5729                                   1.0   \n",
       "730552237.426.426                                    1.0   \n",
       "242190235.3043.3043                                  0.0   \n",
       "59573834.9091.9091                                   0.0   \n",
       "448449304.24597.24597                                0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "18396841.5729.5729                                         1.0   \n",
       "730552237.426.426                                          0.0   \n",
       "242190235.3043.3043                                        1.0   \n",
       "59573834.9091.9091                                         1.0   \n",
       "448449304.24597.24597                                      0.0   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "18396841.5729.5729                                   0.0   \n",
       "730552237.426.426                                    0.0   \n",
       "242190235.3043.3043                                  0.0   \n",
       "59573834.9091.9091                                   0.0   \n",
       "448449304.24597.24597                                0.0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "18396841.5729.5729                                        1.0   \n",
       "730552237.426.426                                         1.0   \n",
       "242190235.3043.3043                                       0.0   \n",
       "59573834.9091.9091                                        0.0   \n",
       "448449304.24597.24597                                     0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "18396841.5729.5729                                   1.0   \n",
       "730552237.426.426                                    1.0   \n",
       "242190235.3043.3043                                  1.0   \n",
       "59573834.9091.9091                                   1.0   \n",
       "448449304.24597.24597                                0.0   \n",
       "\n",
       "                       feature_politeness_==Gratitude==        ...         \\\n",
       "18396841.5729.5729                                  0.0        ...          \n",
       "730552237.426.426                                   0.0        ...          \n",
       "242190235.3043.3043                                 0.0        ...          \n",
       "59573834.9091.9091                                  0.0        ...          \n",
       "448449304.24597.24597                               0.0        ...          \n",
       "\n",
       "                       km_2_dist  km_3_dist  km_4_dist  km_5_dist  \\\n",
       "18396841.5729.5729      0.977602   0.993605   0.883546   0.917872   \n",
       "730552237.426.426       0.916550   0.828698   0.965470   0.844919   \n",
       "242190235.3043.3043     0.918752   0.667591   1.000000   0.906846   \n",
       "59573834.9091.9091      0.928329   0.809121   1.000000   0.924410   \n",
       "448449304.24597.24597   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "                       km_0_dist_second  km_1_dist_second  km_2_dist_second  \\\n",
       "18396841.5729.5729             1.000000          0.844026          1.000000   \n",
       "730552237.426.426              0.982614          1.000000          0.999800   \n",
       "242190235.3043.3043            0.811177          0.997071          0.899894   \n",
       "59573834.9091.9091             0.994450          0.887890          0.976113   \n",
       "448449304.24597.24597          1.000000          0.980467          0.970249   \n",
       "\n",
       "                       km_3_dist_second  km_4_dist_second  km_5_dist_second  \n",
       "18396841.5729.5729             1.000000          0.760097          1.000000  \n",
       "730552237.426.426              1.000000          1.000000          1.000000  \n",
       "242190235.3043.3043            0.720774          1.000000          0.926196  \n",
       "59573834.9091.9091             0.916845          0.988414          0.940218  \n",
       "448449304.24597.24597          1.000000          0.863152          0.969705  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it looks\n",
    "feature_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prediction Utils\n",
    "\n",
    "We're almost ready to do the prediction! First we need to define a few helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(seq):\n",
    "    vals, counts = np.unique(seq, return_counts=True)\n",
    "    return vals[np.argmax(counts)]\n",
    "\n",
    "def run_pred_single(inputs, X, y):\n",
    "    f_idx, (train_idx, test_idx) = inputs\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    base_clf = Pipeline([(\"scaler\", StandardScaler()), (\"featselect\", SelectPercentile(f_classif, 10)), (\"logreg\", LogisticRegression())])\n",
    "    clf = GridSearchCV(base_clf, {\"logreg__C\": [10**i for i in range(-4,4)], \"featselect__percentile\": list(range(10, 110, 10))})\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_scores = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    feature_weights = clf.best_estimator_.named_steps[\"logreg\"].coef_.flatten()\n",
    "    feature_mask = clf.best_estimator_.named_steps[\"featselect\"].get_support()\n",
    "    \n",
    "    hyperparams = clf.best_params_\n",
    "    \n",
    "    return (y_pred, y_scores, feature_weights, hyperparams, feature_mask)\n",
    "\n",
    "def run_pred(X, y, fnames, groups):\n",
    "    feature_weights = {}\n",
    "    scores = np.asarray([np.nan for i in range(len(y))])\n",
    "    y_pred = np.zeros(len(y))\n",
    "    hyperparameters = defaultdict(list)\n",
    "    splits = list(enumerate(LeaveOneGroupOut().split(X, y, groups)))\n",
    "    accs = []\n",
    "        \n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        prediction_results = p.map(partial(run_pred_single, X=X, y=y), splits)\n",
    "        \n",
    "    fselect_pvals_all = []\n",
    "    for i in range(len(splits)):\n",
    "        f_idx, (train_idx, test_idx) = splits[i]\n",
    "        y_pred_i, y_scores_i, weights_i, hyperparams_i, mask_i = prediction_results[i]\n",
    "        y_pred[test_idx] = y_pred_i\n",
    "        scores[test_idx] = y_scores_i\n",
    "        feature_weights[f_idx] = np.asarray([np.nan for _ in range(len(fnames))])\n",
    "        feature_weights[f_idx][mask_i] = weights_i\n",
    "        for param in hyperparams_i:\n",
    "            hyperparameters[param].append(hyperparams_i[param])   \n",
    "    \n",
    "    acc = np.mean(y_pred == y)\n",
    "    pvalue = stats.binom_test(sum(y_pred == y), n=len(y), alternative=\"greater\")\n",
    "                \n",
    "    coef_df = pd.DataFrame(feature_weights, index=fnames)\n",
    "    coef_df['mean_coef'] = coef_df.apply(np.nanmean, axis=1)\n",
    "    coef_df['std_coef'] = coef_df.apply(np.nanstd, axis=1)\n",
    "    return acc, coef_df[['mean_coef', 'std_coef']], scores, pd.DataFrame(hyperparameters), pvalue\n",
    "\n",
    "def get_labeled_pairs(pairs_df):\n",
    "    paired_labels = []\n",
    "    c0s = []\n",
    "    c1s = []\n",
    "    page_ids = []\n",
    "    for i, row in enumerate(pairs_df.itertuples()):\n",
    "        if i % 2 == 0:\n",
    "            c0s.append(row.conversation_id)\n",
    "            c1s.append(row.bad_conversation_id)\n",
    "        else:\n",
    "            c0s.append(row.bad_conversation_id)\n",
    "            c1s.append(row.conversation_id)\n",
    "        paired_labels.append(i%2)\n",
    "        page_ids.append(row.page_id)\n",
    "    return pd.DataFrame({\"c0\": c0s, \"c1\": c1s,\"first_convo_toxic\": paired_labels, \"page_id\": page_ids})\n",
    "\n",
    "def get_feature_subset(labeled_pairs_df, feature_list):\n",
    "    prompt_type_names = [\"km_%d_dist\" % i for i in range(6)] + [\"km_%d_dist_second\" % i for i in range(6)]\n",
    "    politeness_names = [f for f in feature_table.columns if f not in prompt_type_names]\n",
    "    \n",
    "    features_to_use = []\n",
    "    if \"prompt_types\" in feature_list:\n",
    "        features_to_use += prompt_type_names\n",
    "    if \"politeness_strategies\" in feature_list:\n",
    "        features_to_use += politeness_names\n",
    "        \n",
    "    feature_subset = feature_table[features_to_use]\n",
    "    \n",
    "    c0_feats = feature_subset.loc[labeled_pairs_df.c0].values\n",
    "    c1_feats = feature_subset.loc[labeled_pairs_df.c1].values\n",
    "    \n",
    "    return c0_feats, c1_feats, features_to_use\n",
    "\n",
    "def run_pipeline(feature_set):\n",
    "    print(\"Running prediction task for feature set\", \"+\".join(feature_set))\n",
    "    print(\"Generating labels...\")\n",
    "    labeled_pairs_df = get_labeled_pairs(pairs_df)\n",
    "    print(\"Computing paired features...\")\n",
    "    X_c0, X_c1, feature_names = get_feature_subset(labeled_pairs_df, feature_set)\n",
    "    X = X_c1 - X_c0\n",
    "    print(\"Using\", X.shape[1], \"features\")\n",
    "    y = labeled_pairs_df.first_convo_toxic.values\n",
    "    print(\"Running leave-one-page-out prediction...\")\n",
    "    accuracy, coefs, scores, hyperparams, pvalue = run_pred(X, y, feature_names, labeled_pairs_df.page_id)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"p-value: %.4e\" % pvalue)\n",
    "    print(\"C (mode):\", mode(hyperparams.logreg__C))\n",
    "    print(\"Percent of features (mode):\", mode(hyperparams.featselect__percentile))\n",
    "    print(\"Coefficents:\")\n",
    "    print(coefs.sort_values(by=\"mean_coef\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Prediction\n",
    "\n",
    "Finally, we run the prediction task on each possible combination of pragmatic features: prompt types, politeness strategies, and both combined. We generate a table like Table 3 from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction task for feature set politeness_strategies\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 38 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.5874015748031496\n",
      "p-value: 6.0529e-06\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 100\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.112704  0.107882\n",
      "feature_politeness_==2nd_person_start==_second     -0.079780  0.072436\n",
      "feature_politeness_==2nd_person_start==            -0.072872  0.067336\n",
      "feature_politeness_==Direct_question==_second      -0.071110  0.065946\n",
      "feature_politeness_==Indirect_(btw)==              -0.061000  0.061282\n",
      "feature_politeness_==Direct_question==             -0.059573  0.053435\n",
      "feature_politeness_==Please_start==_second         -0.052808  0.047269\n",
      "feature_politeness_==Direct_start==                -0.039835  0.023080\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.034726  0.018835\n",
      "feature_politeness_==Factuality==                  -0.028882  0.014759\n",
      "feature_politeness_==Direct_start==_second         -0.024380  0.017072\n",
      "feature_politeness_==Please==                      -0.023515  0.012058\n",
      "feature_politeness_==Please_start==                -0.019470  0.009047\n",
      "feature_politeness_==1st_person_pl.==              -0.012456  0.005532\n",
      "feature_politeness_==2nd_person==                  -0.010285  0.006415\n",
      "feature_politeness_==INDICATIVE==                  -0.005562  0.002794\n",
      "feature_politeness_==Factuality==_second           -0.000732  0.006481\n",
      "feature_politeness_==1st_person_start==             0.002157  0.008301\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.004458  0.005719\n",
      "feature_politeness_==Deference==_second             0.007487  0.005311\n",
      "feature_politeness_==Please==_second                0.009275  0.006951\n",
      "feature_politeness_==Hedges==_second                0.015531  0.013020\n",
      "feature_politeness_==1st_person==                   0.017142  0.009592\n",
      "feature_politeness_==Apologizing==                  0.018323  0.011095\n",
      "feature_politeness_==1st_person_pl.==_second        0.020256  0.010220\n",
      "feature_politeness_==Deference==                    0.028496  0.016452\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.029827  0.026618\n",
      "feature_politeness_==Hedges==                       0.042173  0.038929\n",
      "feature_politeness_==1st_person==_second            0.046420  0.044425\n",
      "feature_politeness_==Apologizing==_second           0.046997  0.043223\n",
      "feature_politeness_==Gratitude==                    0.048556  0.045248\n",
      "feature_politeness_==HASHEDGE==                     0.050103  0.045875\n",
      "feature_politeness_==INDICATIVE==_second            0.050163  0.032254\n",
      "feature_politeness_==Gratitude==_second             0.054841  0.049080\n",
      "feature_politeness_==1st_person_start==_second      0.059685  0.053794\n",
      "feature_politeness_==HASHEDGE==_second              0.068023  0.062965\n",
      "feature_politeness_==Indirect_(greeting)==          0.093295  0.089871\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.099405  0.104349\n",
      "Running prediction task for feature set prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 12 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6031496062992125\n",
      "p-value: 1.1304e-07\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 80\n",
      "Coefficents:\n",
      "                  mean_coef  std_coef\n",
      "km_2_dist         -0.011558  0.016463\n",
      "km_2_dist_second  -0.009471  0.012332\n",
      "km_3_dist         -0.008663  0.010139\n",
      "km_3_dist_second  -0.007581  0.009679\n",
      "km_0_dist_second  -0.004423  0.004355\n",
      "km_5_dist         -0.002511  0.005541\n",
      "km_0_dist          0.004806  0.012898\n",
      "km_4_dist_second   0.008368  0.009995\n",
      "km_5_dist_second   0.008501  0.011687\n",
      "km_1_dist          0.008751  0.010690\n",
      "km_1_dist_second   0.011269  0.015015\n",
      "km_4_dist          0.012143  0.017057\n",
      "Running prediction task for feature set politeness_strategies+prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 50 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6236220472440945\n",
      "p-value: 2.4594e-10\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 100\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.022530  0.034892\n",
      "feature_politeness_==2nd_person_start==_second     -0.018523  0.027757\n",
      "feature_politeness_==Direct_question==_second      -0.015822  0.023787\n",
      "feature_politeness_==2nd_person_start==            -0.015364  0.022045\n",
      "km_2_dist                                          -0.013837  0.017221\n",
      "feature_politeness_==Direct_question==             -0.013080  0.017658\n",
      "feature_politeness_==Please_start==_second         -0.011910  0.015880\n",
      "km_2_dist_second                                   -0.010307  0.010425\n",
      "km_3_dist_second                                   -0.009197  0.010587\n",
      "km_3_dist                                          -0.008944  0.008035\n",
      "feature_politeness_==Indirect_(btw)==              -0.005021  0.014883\n",
      "km_0_dist_second                                   -0.004501  0.004053\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.001366  0.003553\n",
      "feature_politeness_==Factuality==                  -0.001047  0.001039\n",
      "feature_politeness_==Please_start==                -0.000967  0.000565\n",
      "km_0_dist                                          -0.000966  0.005778\n",
      "feature_politeness_==Please==                      -0.000807  0.000686\n",
      "feature_politeness_==Direct_start==                -0.000353  0.000772\n",
      "feature_politeness_==INDICATIVE==                  -0.000313  0.000398\n",
      "feature_politeness_==1st_person_pl.==              -0.000241  0.000241\n",
      "feature_politeness_==Factuality==_second           -0.000157  0.000228\n",
      "feature_politeness_==2nd_person==                  -0.000127  0.000213\n",
      "feature_politeness_==Please==_second                0.000054  0.000217\n",
      "feature_politeness_==Direct_start==_second          0.000113  0.000170\n",
      "feature_politeness_==Apologizing==                  0.000240  0.000158\n",
      "km_5_dist                                           0.000584  0.000347\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.000752  0.000434\n",
      "feature_politeness_==Deference==                    0.000797  0.000675\n",
      "feature_politeness_==Deference==_second             0.000819  0.000739\n",
      "feature_politeness_==INDICATIVE==_second            0.000863  0.000919\n",
      "feature_politeness_==1st_person_pl.==_second        0.000969  0.000791\n",
      "feature_politeness_==1st_person==                   0.000978  0.000435\n",
      "feature_politeness_==1st_person_start==             0.001076  0.000563\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.002936  0.006242\n",
      "km_5_dist_second                                    0.003257  0.006171\n",
      "feature_politeness_==Apologizing==_second           0.004736  0.012393\n",
      "feature_politeness_==Hedges==_second                0.007038  0.007422\n",
      "feature_politeness_==Hedges==                       0.007867  0.009579\n",
      "feature_politeness_==1st_person==_second            0.009399  0.013895\n",
      "feature_politeness_==Gratitude==                    0.010006  0.014934\n",
      "km_4_dist_second                                    0.010080  0.010705\n",
      "km_1_dist                                           0.011015  0.012447\n",
      "feature_politeness_==HASHEDGE==                     0.011627  0.016483\n",
      "feature_politeness_==Gratitude==_second             0.012546  0.017067\n",
      "km_1_dist_second                                    0.013022  0.014260\n",
      "feature_politeness_==1st_person_start==_second      0.013130  0.016894\n",
      "feature_politeness_==HASHEDGE==_second              0.015319  0.021145\n",
      "km_4_dist                                           0.016565  0.023231\n",
      "feature_politeness_==Indirect_(greeting)==          0.017212  0.024754\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.017616  0.028822\n"
     ]
    }
   ],
   "source": [
    "feature_combos = [[\"politeness_strategies\"], [\"prompt_types\"], [\"politeness_strategies\", \"prompt_types\"]]\n",
    "combo_names = []\n",
    "accs = []\n",
    "for combo in feature_combos:\n",
    "    combo_names.append(\"+\".join(combo).replace(\"_\", \" \"))\n",
    "    accuracy = run_pipeline(combo)\n",
    "    accs.append(accuracy)\n",
    "results_df = pd.DataFrame({\"Accuracy\": accs}, index=combo_names)\n",
    "results_df.index.name = \"Feature set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politeness strategies</th>\n",
       "      <td>0.587402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt types</th>\n",
       "      <td>0.603150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politeness strategies+prompt types</th>\n",
       "      <td>0.623622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy\n",
       "Feature set                                 \n",
       "politeness strategies               0.587402\n",
       "prompt types                        0.603150\n",
       "politeness strategies+prompt types  0.623622"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the table\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
