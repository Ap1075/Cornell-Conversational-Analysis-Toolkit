{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_dir = '/sauna/fake-news'\n",
    "# politics_dir = '/sauna/reddit_201810_raw/corpus/pokemontrades_banlist~-~politics/politics'\n",
    "\n",
    "gifs_corpus = '/sauna/reddit_201810_raw/corpus/gif_to_gyf_test~-~gifs/gifs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=gifs_corpus)\n",
    "# corpus = Corpus(filename=os.path.join(fake_news_dir, 'relationships_trunc_paired'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time: 01 Oct 2017\n",
    "# End time: 01 Oct 2018\n",
    "start_time = 1506816000\n",
    "end_time = 1538352000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_convo_ids = [convo.id for convo in corpus.iter_conversations() if start_time <= convo.meta['timestamp'] <= end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_convo_ids = set(valid_convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119711"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.filter_conversations_by(lambda convo: convo.id in valid_convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 841739\n",
      "Number of Utterances: 4276196\n",
      "Number of Conversations: 119711\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus.dump('politeness_trunc', base_path=fake_news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = corpus.utterance_threads(include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 10 comments in each thread\n",
    "thread_pfxs = corpus.utterance_threads(prefix_len=10, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1645994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "thread_roots_by_self_post = defaultdict(list)\n",
    "for top_level_comment, thread in threads.items():\n",
    "    rt = thread[next(iter(thread))].root\n",
    "    thread_roots_by_self_post[rt].append(top_level_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate positive and negative examples based on task\n",
    "import random\n",
    "def generate_pos_neg(task: str, post_to_thread_obj, threads, thread_pfxs):\n",
    "    pos, neg = [], []\n",
    "    if task == \"comment-growth\":\n",
    "        for post_id, thread_roots in post_to_thread_obj.items():\n",
    "            has_pos = [root for root in thread_roots if len(threads[root]) >= 15]\n",
    "            has_neg = [root for root in thread_roots if len(threads[root]) == 10]\n",
    "            \n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg))\n",
    "    elif task == \"commenter-growth\":\n",
    "        for post_id, thread_roots in post_to_thread_obj.items():\n",
    "            has_pos, has_neg = [], []\n",
    "            for root in thread_roots:\n",
    "                if len(threads[root]) >= 20:\n",
    "                    if len(set(c.user.name for c in threads[root].values())) >= \\\n",
    "                        len(set(c.user.name for c in thread_pfxs[root].values())) * 2:\n",
    "                            has_pos.append(root)\n",
    "                    else:\n",
    "                        has_neg.append(root)\n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg))\n",
    "    print(\"- {} positive, {} negative pts for {} task\".format(len(pos), len(neg), task))\n",
    "    \n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 2010 positive, 2010 negative pts for comment-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_comment_growth, neg_comment_growth = generate_pos_neg(\"comment-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1640 positive, 1640 negative pts for commenter-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_commenter_growth, neg_commenter_growth = generate_pos_neg(\"commenter-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_to_convo = {thread_id: convo_id for convo_id, thread_ids in thread_roots_by_self_post.items() for thread_id in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "commenter_growth_convos = set()\n",
    "for thread_id in pos_commenter_growth + neg_commenter_growth:\n",
    "    commenter_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_growth_convos = set()\n",
    "for thread_id in pos_comment_growth + neg_comment_growth:\n",
    "    comment_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_convos = comment_growth_convos.union(commenter_growth_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.filter_conversations_by(lambda convo: convo.id in paired_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus.dump('atheism_trunc_paired', base_path=fake_news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:182: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"norm.max\": lambda l: np.max(l) / np.sum(l),\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:187: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan,\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2614: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:194: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan\n"
     ]
    }
   ],
   "source": [
    "hc = convokit.HyperConvo(prefix_len=10, min_thread_len=10, include_root=False)\n",
    "hyperconvo_feats = hc.retrieve_feats(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats = hc.retrieve_motif_pathway_stats(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_counts = hc.retrieve_motif_counts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads_motifs = hc.retrieve_motifs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_df = pd.DataFrame.from_dict(hyperconvo_feats, orient='index')\n",
    "hyperconv_feat_names = list(hyperconv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats_df = pd.DataFrame.from_dict(path_stats, orient='index')\n",
    "columns = ['PATH-'+', '.join(filter(lambda x: type(x) == str, col)).strip() for col in path_stats_df.columns.values]\n",
    "path_stats_df.columns = columns\n",
    "path_feat_names = list(path_stats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_counts_df = pd.DataFrame.from_dict(motif_counts, orient='index')\n",
    "motif_feat_names = list(motif_counts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_users(thread):\n",
    "    return len(set(utt.user.name for utt in thread.values()))\n",
    "\n",
    "thread_to_usercount = dict()\n",
    "for thread_id in thread_pfxs:\n",
    "    thread_to_usercount[thread_id] = {\"num_users\": get_num_users(thread_pfxs[thread_id])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users_df = pd.DataFrame.from_dict(thread_to_usercount, orient='index')\n",
    "num_users_feat = ['num_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "feats_df = pd.concat([hyperconv_df, path_stats_df, motif_counts_df, num_users_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1645994, 261)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads = {k: v for k, v in corpus.utterance_threads(include_root=False).items() if k in valid_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 10 comments in each thread\n",
    "# thread_pfxs = {k: v for k, v in corpus.utterance_threads(prefix_len=10, include_root=False).items() if k in valid_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1645994"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(feats_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK: comment-growth\n",
      "\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconvo, cv_accuracy: 0.6228\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconv-usercount, cv_accuracy: 0.6244\n",
      "- motif, cv_accuracy: 0.6228\n",
      "- motif-usercount, cv_accuracy: 0.6228\n",
      "- motifpaths, cv_accuracy: 0.6397\n",
      "- motifpaths-usercount, cv_accuracy: 0.6342\n",
      "- motif-all, cv_accuracy: 0.6372\n",
      "- motif-all+usercount, cv_accuracy: 0.6328\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconv-motif, cv_accuracy: 0.6260\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconv-paths, cv_accuracy: 0.6254\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconvo-motifall, cv_accuracy: 0.6238\n",
      "Excluded 34 data point(s) that contained NaN values.\n",
      "- hyperconvo-motifall, cv_accuracy: 0.6239\n",
      "- usercount, cv_accuracy: 0.6204\n",
      "TASK: commenter-growth\n",
      "\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconvo, cv_accuracy: 0.5601\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconv-usercount, cv_accuracy: 0.5601\n",
      "- motif, cv_accuracy: 0.5439\n",
      "- motif-usercount, cv_accuracy: 0.5439\n",
      "- motifpaths, cv_accuracy: 0.5598\n",
      "- motifpaths-usercount, cv_accuracy: 0.5561\n",
      "- motif-all, cv_accuracy: 0.5561\n",
      "- motif-all+usercount, cv_accuracy: 0.5567\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconv-motif, cv_accuracy: 0.5547\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconv-paths, cv_accuracy: 0.5657\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconvo-motifall, cv_accuracy: 0.5682\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "- hyperconvo-motifall, cv_accuracy: 0.5664\n",
      "- usercount, cv_accuracy: 0.5494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "for task in [\"comment-growth\", \"commenter-growth\"]: #, \"post-deleted\", \"user-deleted\"\n",
    "    print(\"TASK: {}\\n\".format(task))\n",
    "    \n",
    "    if task == \"comment-growth\":\n",
    "        pos, neg = pos_comment_growth, neg_comment_growth\n",
    "    elif task == \"commenter-growth\":\n",
    "        pos, neg = pos_commenter_growth, neg_commenter_growth\n",
    "#     pos, neg = generate_pos_neg(task, thread_roots_by_self_post, threads, thread_pfxs)\n",
    "    for feature_set, name in [(hyperconv_feat_names, \"hyperconvo\"),\n",
    "                        (hyperconv_feat_names + num_users_feat, \"hyperconv-usercount\"),\n",
    "                        (motif_feat_names, \"motif\"),\n",
    "                        (motif_feat_names, \"motif-usercount\"),\n",
    "                        (path_feat_names, \"motifpaths\"),\n",
    "                        (path_feat_names + num_users_feat, \"motifpaths-usercount\"),\n",
    "                        (motif_feat_names + path_feat_names, \"motif-all\"),\n",
    "                        (motif_feat_names + path_feat_names + num_users_feat, \"motif-all+usercount\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names, \"hyperconv-motif\"),\n",
    "                        (hyperconv_feat_names + path_feat_names, \"hyperconv-paths\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names + path_feat_names, \"hyperconvo-motifall\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names + path_feat_names + num_users_feat, \"hyperconvo-motifall\"),\n",
    "                        (num_users_feat, \"usercount\")\n",
    "                       ]:\n",
    "        clf = Pipeline([(\"standardScaler\", StandardScaler()), (\"logreg\", LogisticRegression(solver='liblinear'))])      \n",
    "#         loo = LeaveOneOut()\n",
    "        pp = convokit.PairedPrediction()\n",
    "        X, y = pp._generate_paired_X_y(feats_df[feature_set], pos, neg)\n",
    "\n",
    "#         clf.fit(X, y)\n",
    "#         clf.score(X, y)\n",
    "#         print(X.shape)\n",
    "#         print(X[0])\n",
    "#         print(y.shape)\n",
    "        scores = cross_val_score(clf, X, y, cv=20)\n",
    "        print(\"- {}, cv_accuracy: {:.4f}\".format(name, scores.mean()))\n",
    "\n",
    "\n",
    "#         print(\"Feature set: {}\".format(name))\n",
    "#         pp.fit_predict(feats_df[feature_set], pos, neg, test_size=0.2)\n",
    "#         pp.print_extreme_coefs(feature_set, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
