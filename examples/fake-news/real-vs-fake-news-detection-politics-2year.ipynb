{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/caleb/Cornell-Conversational-Analysis-Toolkit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"../..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, Conversation, Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_dir = '/sauna/fake-news'\n",
    "politics_dir = '/sauna/reddit_201810_raw/corpus/pokemontrades_banlist~-~politics/politics'\n",
    "donald_dir = '/sauna/reddit_201810_raw/corpus/TheTwoBeerQueers~-~The_Donald/The_Donald/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_urls = {'breitbart.com', 'dcgazette.com', \"dailymail.co.uk\", \n",
    "                  \"lewrockwell.com\", \"newswars.com\", \"gellerreport.com\",\n",
    "                  \"dcclothesline.com\", \"thegatewaypundit.com\", \"trueactivist.com\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_sites = ['BBC', 'Business Insider', 'Buzzfeed', 'CBS News', 'CNN', 'Daily Beast', \n",
    "                   'FT Westminster Blog', 'FiveThirtyEight', 'Fortune', 'Mercury News', 'NPR',\n",
    "                   'National Review', 'New Yorker', 'Newsweek', 'PBS', 'Politico', 'Real Clear Politics', 'Reuters',\n",
    "                   'Slate', 'The American Conservative', 'The Denver Post', 'The Guardian', 'The Hill', 'The New York Times',\n",
    "                   'The Verge', 'USA Today', 'Vox', 'WSJ Washington Wire', 'Washington Monthly', 'Washington Post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_urls = {'bbc.com', 'businessinsider.com', 'buzzfeed.com', 'cbsnews.com', 'cnn.com', 'thedailybeast.com',\n",
    "                  'ft.com', 'fivethirtyeight.com', 'fortune.com', 'mercurynews.com', 'npr.org', 'nationalreview.com',\n",
    "                  'newyorker.com', 'newsweek.com', 'pbs.org', 'politico.com', 'realclearpol', 'reuters.com',\n",
    "                  'slate.com', 'theamericanconservative.com', 'denverpost.com', 'theguardian.com', 'thehill.com',\n",
    "                  'nytimes.com', 'theverge.com', 'usatoday.com', 'vox.com', 'wsj.com', 'washingtonmonthly.com', \n",
    "                  'washingtonpost.com'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_corpus = Corpus(filename=politics_dir)\n",
    "# donald_corpus = Corpus(filename=os.path.join(fake_news_dir, 'donald_corpus_valid_convos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time: 01 Oct 2017\n",
    "# End time: 01 Oct 2018\n",
    "start_time = 1475280000\n",
    "end_time = 1538352000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "real_news_convos = defaultdict(set)\n",
    "fake_news_convos = defaultdict(set)\n",
    "for convo in politics_corpus.iter_conversations():\n",
    "    if start_time <= convo.meta['timestamp'] <= end_time:\n",
    "        if convo.meta['domain'] in real_news_urls:\n",
    "            real_news_convos[convo.meta['domain']].add(convo.id)\n",
    "        elif convo.meta['domain'] in fake_news_urls:\n",
    "            fake_news_convos[convo.meta['domain']].add(convo.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politico.com: 21395\n",
      "thehill.com: 55517\n",
      "washingtonpost.com: 78430\n",
      "cnn.com: 28123\n",
      "nytimes.com: 36655\n",
      "buzzfeed.com: 6202\n",
      "businessinsider.com: 9968\n",
      "npr.org: 7665\n",
      "reuters.com: 16612\n",
      "usatoday.com: 9017\n",
      "ft.com: 582\n",
      "theguardian.com: 14605\n",
      "fivethirtyeight.com: 1678\n",
      "nationalreview.com: 2222\n",
      "thedailybeast.com: 10615\n",
      "pbs.org: 1410\n",
      "vox.com: 9811\n",
      "newyorker.com: 2534\n",
      "bbc.com: 5475\n",
      "cbsnews.com: 6077\n",
      "fortune.com: 1453\n",
      "slate.com: 5701\n",
      "mercurynews.com: 599\n",
      "wsj.com: 5005\n",
      "theverge.com: 981\n",
      "newsweek.com: 9283\n",
      "theamericanconservative.com: 282\n",
      "denverpost.com: 678\n",
      "washingtonmonthly.com: 502\n",
      "Total posts: 349077\n"
     ]
    }
   ],
   "source": [
    "for k, v in real_news_convos.items():\n",
    "    print(\"{}: {}\".format(k, len(v)))\n",
    "    \n",
    "print(\"Total posts:\", sum([len(v) for v in real_news_convos.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breitbart.com: 5861\n",
      "dailymail.co.uk: 3071\n",
      "thegatewaypundit.com: 683\n",
      "lewrockwell.com: 30\n",
      "trueactivist.com: 19\n",
      "dcclothesline.com: 16\n",
      "gellerreport.com: 4\n",
      "newswars.com: 2\n",
      "Total posts: 9686\n"
     ]
    }
   ],
   "source": [
    "for k, v in fake_news_convos.items():\n",
    "    print(\"{}: {}\".format(k, len(v)))\n",
    "    \n",
    "print(\"Total posts:\", sum([len(v) for v in fake_news_convos.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "real_news_convos_ids = list(chain.from_iterable(real_news_convos.values()))\n",
    "fake_news_convos_ids = list(chain.from_iterable(fake_news_convos.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_convos_ids = set(real_news_convos_ids + fake_news_convos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 1772618\n",
      "Number of Utterances: 89059584\n",
      "Number of Conversations: 3243950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "politics_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_corpus.filter_conversations_by(func=lambda convo: convo.id in valid_convos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 599761\n",
      "Number of Utterances: 20075242\n",
      "Number of Conversations: 358763\n"
     ]
    }
   ],
   "source": [
    "politics_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a223bbd9ea1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolitics_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'politics_corpus_valid_convos_2year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfake_news_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, name, base_path, save_to_existing_path)\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mKeyId\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mKeyConvoRoot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                     \u001b[0mKeyText\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m                     \u001b[0mKeyUser\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mKeyMeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_helper_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutterances_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "politics_corpus.dump('politics_corpus_valid_convos_2year', base_path=fake_news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_pfxs = politics_corpus.utterance_threads(prefix_len=8, include_root=False)\n",
    "convos_with_valid_len = set()\n",
    "convo_to_thread = defaultdict(list)\n",
    "for thread_id, utts in thread_pfxs.items():\n",
    "    if len(utts) >= 8:\n",
    "        convos_with_valid_len.add(utts[next(iter(utts))].root)\n",
    "        convo_to_thread[utts[next(iter(utts))].root].append(thread_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "for convo, threads in convo_to_thread.items():\n",
    "    convo_to_thread[convo] = choice(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_to_convo = {v: k for k, v in convo_to_thread.items() if len(v) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_thread_ids = [convo_to_thread[convo_id] for convo_id in real_news_convos_ids if len(convo_to_thread[convo_id]) > 0]\n",
    "fake_news_thread_ids = [convo_to_thread[convo_id] for convo_id in fake_news_convos_ids if len(convo_to_thread[convo_id]) > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86760"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_news_thread_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3033"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_news_thread_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "real_news_thread_sample = sample(real_news_thread_ids, len(fake_news_thread_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_convos_sample = [thread_to_convo[thread_id] for thread_id in real_news_thread_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_long_convos = [thread_to_convo[thread_id] for thread_id in fake_news_thread_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_convos = set(real_news_convos_sample).union(fake_news_long_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_threads = fake_news_thread_ids + real_news_thread_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6066"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(balanced_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paired_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_corpus.filter_conversations_by(func=lambda convo: convo.id in paired_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_corpus.dump('politics_corpus_paired_2year', base_path=fake_news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donald_corpus = Corpus(filename=os.path.join(fake_news_dir, 'donald_corpus_paired'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 121768\n",
      "Number of Utterances: 812227\n",
      "Number of Conversations: 6066\n"
     ]
    }
   ],
   "source": [
    "politics_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = convokit.HyperConvo(min_thread_len=8, prefix_len=8, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_feats = hc.retrieve_motif_counts(politics_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_threads = set(balanced_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_feats = {k: v for k, v in motif_feats.items() if k in balanced_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_counts_df = pd.DataFrame.from_dict(motif_feats, orient='index')\n",
    "motif_feat_names = list(motif_counts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:182: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"norm.max\": lambda l: np.max(l) / np.sum(l),\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:187: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan,\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2614: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:194: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan\n"
     ]
    }
   ],
   "source": [
    "hyperconv_feats = hc.retrieve_feats(politics_corpus)\n",
    "hyperconv_feats = {k: v for k, v in hyperconv_feats.items() if k in balanced_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_df = pd.DataFrame.from_dict(hyperconv_feats, orient='index')\n",
    "hyperconv_feat_names = list(hyperconv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_feats = hc.retrieve_motif_pathway_stats(politics_corpus)\n",
    "path_feats = {k: v for k, v in path_feats.items() if k in balanced_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats_df = pd.DataFrame.from_dict(path_feats, orient='index')\n",
    "columns = ['PATH-'+', '.join(filter(lambda x: type(x) == str, col)).strip() for col in path_stats_df.columns.values]\n",
    "path_stats_df.columns = columns\n",
    "path_feat_names = list(path_stats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.concat([hyperconv_df, path_stats_df, motif_counts_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df['volume'] = [len(set(utt.user.name for utt in thread_pfxs[thread_id].values())) for thread_id in feats_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_thread_ids = set(fake_news_thread_ids)\n",
    "y = [int(thread_id in fake_news_thread_ids) for thread_id in list(feats_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6066, 262)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df_no_na = feats_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5897"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats_df_no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2918"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feats_df_no_na['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_extreme_coefs(clf, feature_names, num_features: int = 5):\n",
    "    coefs = clf.named_steps['logreg'].coef_[0].tolist()\n",
    "\n",
    "    assert len(feature_names) == len(coefs)\n",
    "\n",
    "    feats_coefs = sorted(list(zip(feature_names, coefs)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print()\n",
    "    print(\"TOP {} FEATURES\".format(num_features))\n",
    "    for ft, coef in feats_coefs[:num_features]:\n",
    "        print(\"{}: {:.3f}\".format(ft, coef))\n",
    "    print()\n",
    "    print(\"BOTTOM {} FEATURES\".format(num_features))\n",
    "    for ft, coef in feats_coefs[-num_features:]:\n",
    "        print(\"{}: {:.3f}\".format(ft, coef))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- hyperconvo, train: 0.6084, test: 0.6008\n",
      "- volume, train: 0.5391, test: 0.5288\n",
      "- hyperconv-volume, train: 0.6076, test: 0.6000\n",
      "- motifs, train: 0.5595, test: 0.5610\n",
      "- motifs-volume, train: 0.5629, test: 0.5576\n",
      "- motifpaths, train: 0.5652, test: 0.5653\n",
      "- motifpaths-volume, train: 0.5699, test: 0.5627\n",
      "- hyperconv-motif, train: 0.6129, test: 0.5975\n",
      "- hyperconv-paths, train: 0.6127, test: 0.5856\n",
      "- hyperconvo-motifall, train: 0.6127, test: 0.5864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "for feature_set, name in [(hyperconv_feat_names, \"hyperconvo\"),\n",
    "                        ([\"volume\"], \"volume\"),\n",
    "                        (hyperconv_feat_names + [\"volume\"], \"hyperconv-volume\"),\n",
    "                        (motif_feat_names, \"motifs\"),\n",
    "                        (motif_feat_names + [\"volume\"], \"motifs-volume\"),\n",
    "                        (path_feat_names, \"motifpaths\"),\n",
    "                        (path_feat_names + [\"volume\"], \"motifpaths-volume\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names, \"hyperconv-motif\"),\n",
    "                        (hyperconv_feat_names + path_feat_names, \"hyperconv-paths\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names + path_feat_names, \"hyperconvo-motifall\"),\n",
    "                       ]:\n",
    "    clf = Pipeline([(\"standardScaler\", StandardScaler()), (\"logreg\", LogisticRegression(solver='liblinear'))])      \n",
    "\n",
    "    X = np.array(feats_df_no_na[feature_set])\n",
    "    y = np.array(feats_df_no_na['y'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(\"- {}, train: {:.4f}, test: {:.4f}\".format(name, train_score, test_score))\n",
    "#     print_extreme_coefs(clf, feature_set, num_features = 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_pfxs = politics_corpus.utterance_threads(prefix_len=8, include_root=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_pfx_texts = {k: \" \".join([utt.text for utt in v.values()]) for k, v in thread_pfxs.items() if k in balanced_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [int(thread_id in real_news_thread_sample) for thread_id in list(feats_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids, y_train, y_test = train_test_split(list(balanced_threads), y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=0.05, max_df=0.7, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.fit_transform([thread_pfx_texts[train_id] for train_id in train_ids]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform([thread_pfx_texts[test_id] for test_id in test_ids]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BoW, train: 0.6358, test: 0.5049\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([(\"standardScaler\", StandardScaler()), (\"logreg\", LogisticRegression(solver='liblinear'))])      \n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(\"- {}, train: {:.4f}, test: {:.4f}\".format(\"BoW\", train_score, test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 10 FEATURES\n",
      "http www: 0.280\n",
      "https www: 0.271\n",
      "fake: 0.141\n",
      "get: 0.137\n",
      "will: 0.132\n",
      "all: 0.131\n",
      "have been: 0.130\n",
      "kind of: 0.119\n",
      "the gop: 0.114\n",
      "than: 0.106\n",
      "\n",
      "BOTTOM 10 FEATURES\n",
      "gop: -0.105\n",
      "information: -0.107\n",
      "to get: -0.120\n",
      "out: -0.122\n",
      "would: -0.123\n",
      "kind: -0.127\n",
      "http: -0.132\n",
      "https: -0.136\n",
      "been: -0.215\n",
      "www: -0.372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extreme_coefs(clf, cv.get_feature_names(), num_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
