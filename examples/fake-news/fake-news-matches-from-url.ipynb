{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_dir = '/sauna/fake-news'\n",
    "news_dir = '/sauna/reddit_201810_raw/corpus/newreddits_nsfw~-~news/news/'\n",
    "donald_dir = '/sauna/reddit_201810_raw/corpus/TheTwoBeerQueers~-~The_Donald/The_Donald/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/caleb/Cornell-Conversational-Analysis-Toolkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "from convokit import Corpus, Conversation, Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_corpus = Corpus(filename=donald_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus = Corpus(filename=news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_to_convo_dict(corpus: Corpus):\n",
    "    url_to_convo = dict()\n",
    "    for convo in corpus.iter_conversations():\n",
    "        url = convo.meta['url']\n",
    "        if url in url_to_convo:\n",
    "            convo1_len = len(list(url_to_convo[url].iter_utterances()))\n",
    "            convo2_len = len(list(convo.iter_utterances()))\n",
    "            if convo2_len > convo1_len:\n",
    "                url_to_convo[url] = convo\n",
    "        else:\n",
    "            url_to_convo[url] = convo\n",
    "    return url_to_convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_convo_donald = get_url_to_convo_dict(donald_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_convo_news = get_url_to_convo_dict(news_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3514345"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_to_convo_donald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543168"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_to_convo_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_urls = set(url_to_convo_donald.keys() & url_to_convo_news.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of common urls: 54022\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of common urls:\", len(common_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://medium.com/@fightfortheftr/at-t-paid-200-000-to-trumps-attorney-michael-cohen-and-the-payments-stop-right-after-trump-s-3356687f4827',\n",
       " 'http://www.breitbart.com/texas/2016/08/18/thousands-middle-eastern-illegal-immigrants-busted-forged-papers-border/',\n",
       " 'https://www.bostonglobe.com/metro/2018/06/13/about-face-hospital-will-disperse-portraits-past-white-male-luminaries-put-focus-diversity/0pICgbpsw7QoHFFJQQEZOJ/story.html',\n",
       " 'http://www.sgvtribune.com/government-and-politics/20170329/west-covina-walnut-leaders-say-sanctuary-state-bill-would-let-felons-go-free',\n",
       " 'https://www.nytimes.com/2017/01/25/us/politics/cia-detainee-prisons.html?_r=0',\n",
       " 'https://www.google.com/amp/s/amp.cnn.com/cnn/2017/08/24/us/charleston-active-shooter/index.html',\n",
       " 'http://www.cbsnews.com/news/france-terrorist-act-thwarted-arrest-seven-strasbourg-marseille/',\n",
       " 'https://nypost.com/2018/10/12/the-moment-a-kids-backpack-got-him-accused-of-sexual-assault/',\n",
       " 'http://www.bbc.com/news/world-us-canada-38721056',\n",
       " 'http://www.foxnews.com/politics/2017/08/15/rudy-giuliani-hospitalized-after-fall-report-says.html']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(common_urls)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_convo_ids = {url_to_convo_donald[url].id for url in common_urls}\n",
    "news_convo_ids = {url_to_convo_news[url].id for url in common_urls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_corpus.filter_conversations_by(lambda convo: convo.id in donald_convo_ids)\n",
    "news_corpus.filter_conversations_by(lambda convo: convo.id in news_convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_corpus.dump('donald_corpus', base_path='/sauna/fake-news/fake-news-url-match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus.dump('news_corpus', base_path='/sauna/fake-news/fake-news-url-match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_corpus = Corpus(filename='/sauna/fake-news/fake-news-url-match/donald_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus = Corpus(filename='/sauna/fake-news/fake-news-url-match/news_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = convokit.HyperConvo(prefix_len=8, min_thread_len=8, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:182: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"norm.max\": lambda l: np.max(l) / np.sum(l),\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:187: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan,\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2614: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py:194: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7fa6b55ce650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc.fit_transform(donald_corpus)\n",
    "hc.fit_transform(news_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_convo_pairs = []\n",
    "for url in common_urls:\n",
    "    donald_convo = url_to_convo_donald[url]\n",
    "    news_convo = url_to_convo_news[url]\n",
    "    \n",
    "    if \"hyperconvo\" in news_convo.meta and \"hyperconvo\" in donald_convo.meta:\n",
    "        valid_convo_pairs.append((news_convo, donald_convo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 900 valid conversation pairs\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} valid conversation pairs\".format(len(valid_convo_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset corpus to conversations that have threads of sufficient length\n",
    "donald_convo_trunc = set([x[1].id for x in valid_convo_pairs])\n",
    "news_convo_trunc = set([x[0].id for x in valid_convo_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_corpus.filter_conversations_by(lambda convo: convo.id in donald_convo_trunc)\n",
    "news_corpus.filter_conversations_by(lambda convo: convo.id in news_convo_trunc)\n",
    "\n",
    "donald_corpus.dump('donald_corpus_trunc', base_path='/sauna/fake-news/fake-news-url-match')\n",
    "news_corpus.dump('news_corpus_trunc', base_path='/sauna/fake-news/fake-news-url-match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_convo_ids = [x[0].id for x in valid_convo_pairs] # news\n",
    "neg_convo_ids = [x[1].id for x in valid_convo_pairs] # donald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_pairs = []\n",
    "for news_convo, donald_convo in valid_convo_pairs:\n",
    "    news_thread_id = random.choice(list(news_convo.meta['hyperconvo'].keys()))\n",
    "    donald_thread_id = random.choice(list(donald_convo.meta['hyperconvo'].keys()))\n",
    "    thread_pairs.append((news_thread_id, donald_thread_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_thread_ids = [x for x, y in thread_pairs]\n",
    "neg_thread_ids = [y for x, y in thread_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_to_thread = dict()\n",
    "for idx in range(len(pos_convo_ids)):\n",
    "    convo_to_thread[pos_convo_ids[idx]] = pos_thread_ids[idx]\n",
    "    convo_to_thread[neg_convo_ids[idx]] = neg_thread_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for corpus metadata: subreddit. Overwriting with other corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for corpus metadata: num_posts. Overwriting with other corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for corpus metadata: num_comments. Overwriting with other corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for corpus metadata: num_user. Overwriting with other corpus's metadata.\n"
     ]
    }
   ],
   "source": [
    "corpus = news_corpus.merge(donald_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_ids = set(pos_thread_ids + neg_thread_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats = {k: v for k, v in hc.retrieve_motif_pathway_stats(corpus).items() if k in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_motifs = hc.retrieve_motifs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_motif_count = {thread_id: hc._latent_motif_count(motif_dict, trans=False)[0] for thread_id, motif_dict in threads_motifs.items() if thread_id in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_counts = {k: v for k, v in hc.retrieve_motif_counts(corpus).items() if k in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconvo_feats = {k: v for k, v in hc.retrieve_feats(corpus).items() if k in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 10 comments in each thread\n",
    "thread_pfxs = corpus.utterance_threads(prefix_len=8, include_root=False)\n",
    "\n",
    "def get_num_users(thread):\n",
    "    return len(set(utt.user.name for utt in thread.values()))\n",
    "\n",
    "thread_to_usercount = dict()\n",
    "for thread_id in thread_pfxs:\n",
    "    if thread_id in thread_ids:\n",
    "        thread_to_usercount[thread_id] = {\"num_users\": get_num_users(thread_pfxs[thread_id])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_df = pd.DataFrame.from_dict(hyperconvo_feats, orient='index')\n",
    "hyperconv_feat_names = list(hyperconv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats_df = pd.DataFrame.from_dict(path_stats, orient='index')\n",
    "columns = ['PATH-'+', '.join(filter(lambda x: type(x) == str, col)).strip() for col in path_stats_df.columns.values]\n",
    "path_stats_df.columns = columns\n",
    "path_feat_names = list(path_stats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_counts_df = pd.DataFrame.from_dict(motif_counts, orient='index')\n",
    "motif_feat_names = list(motif_counts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "latentmotif_df = pd.DataFrame.from_dict(latent_motif_count, orient='index')\n",
    "latentmotif_df.columns = ['LATENT_'+c for c in latentmotif_df.columns]\n",
    "latent_motif_feat_names = list(latentmotif_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users_df = pd.DataFrame.from_dict(thread_to_usercount, orient='index')\n",
    "num_users_feat = ['num_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 144)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperconv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_counts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latentmotif_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 277)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.concat([hyperconv_df, path_stats_df, motif_counts_df, latentmotif_df, num_users_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 277)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import PairedPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK: Predicing if a thread is from r/news\n",
      "\n",
      "Feature set: hyperconvo\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.6676\n",
      "Test accuracy: 0.5966\n",
      "\n",
      "TOP 5 FEATURES\n",
      "mean-nonzero[outdegree over C->c responses]: 0.502\n",
      "mean-nonzero[outdegree over C->C responses]: 0.502\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.485\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.485\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.422\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "prop-nonzero[indegree over C->C mid-thread responses]: -0.587\n",
      "max[indegree over C->C mid-thread responses]: -0.695\n",
      "entropy[outdegree over C->c responses]: -0.701\n",
      "entropy[outdegree over C->C responses]: -0.701\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.768\n",
      "\n",
      "Feature set: hyperconv-usercount\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.6705\n",
      "Test accuracy: 0.5909\n",
      "\n",
      "TOP 5 FEATURES\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.497\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.497\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.424\n",
      "norm.2nd-largest[outdegree over C->C mid-thread responses]: 0.424\n",
      "max[outdegree over C->c mid-thread responses]: 0.382\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "entropy[indegree over C->c mid-thread responses]: -0.386\n",
      "prop-nonzero[indegree over C->C mid-thread responses]: -0.558\n",
      "max[indegree over C->C mid-thread responses]: -0.670\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.770\n",
      "num_users: -1.462\n",
      "\n",
      "Feature set: latentmotif\n",
      "Train accuracy: 0.6236\n",
      "Test accuracy: 0.5833\n",
      "\n",
      "TOP 5 FEATURES\n",
      "LATENT_INCOMING_TRIADS: 0.301\n",
      "LATENT_INCOMING_1TO3_TRIADS: 0.294\n",
      "LATENT_UNIDIRECTIONAL_TRIADS: 0.171\n",
      "LATENT_SINGLE_EDGE_TRIADS: 0.134\n",
      "LATENT_OUTGOING_3TO1_TRIADS: 0.080\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "LATENT_DIRECIPROCAL_2TO3_TRIADS: -0.011\n",
      "LATENT_INCOMING_RECIPROCAL_TRIADS: -0.122\n",
      "LATENT_DIRECTED_CYCLE_1TO3_TRIADS: -0.175\n",
      "LATENT_DIRECIPROCAL_TRIADS: -0.396\n",
      "LATENT_NO_EDGE_TRIADS: -1.091\n",
      "\n",
      "Feature set: latentmotif-usercount\n",
      "Train accuracy: 0.6292\n",
      "Test accuracy: 0.5833\n",
      "\n",
      "TOP 5 FEATURES\n",
      "num_users: 0.553\n",
      "LATENT_INCOMING_1TO3_TRIADS: 0.277\n",
      "LATENT_INCOMING_TRIADS: 0.235\n",
      "LATENT_UNIDIRECTIONAL_TRIADS: 0.144\n",
      "LATENT_INCOMING_2TO3_TRIADS: 0.083\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "LATENT_DYADIC_TRIADS: -0.030\n",
      "LATENT_INCOMING_RECIPROCAL_TRIADS: -0.134\n",
      "LATENT_DIRECTED_CYCLE_1TO3_TRIADS: -0.181\n",
      "LATENT_DIRECIPROCAL_TRIADS: -0.387\n",
      "LATENT_NO_EDGE_TRIADS: -1.421\n",
      "\n",
      "Feature set: motifpaths\n",
      "Train accuracy: 0.6486\n",
      "Test accuracy: 0.5833\n",
      "\n",
      "TOP 5 FEATURES\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS: 0.309\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS, DIRECIPROCAL_2TO3_TRIADS: 0.252\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS: 0.241\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, DIRECTED_CYCLE_1TO3_TRIADS: 0.235\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS: 0.210\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, OUTGOING_3TO1_TRIADS, DIRECTED_CYCLE_1TO3_TRIADS, DIRECIPROCAL_2TO3_TRIADS: -0.282\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, OUTGOING_3TO1_TRIADS, INCOMING_RECIPROCAL_TRIADS: -0.298\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS: -0.332\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, DYADIC_TRIADS, INCOMING_1TO3_TRIADS, DIRECIPROCAL_TRIADS, DIRECIPROCAL_2TO3_TRIADS: -0.388\n",
      "PATH-NO_EDGE_TRIADS: -0.612\n",
      "\n",
      "Feature set: motifpaths-usercount\n",
      "Train accuracy: 0.6514\n",
      "Test accuracy: 0.5722\n",
      "\n",
      "TOP 5 FEATURES\n",
      "num_users: 0.549\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS: 0.300\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS, DIRECIPROCAL_2TO3_TRIADS: 0.243\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, INCOMING_TRIADS, INCOMING_1TO3_TRIADS, DIRECTED_CYCLE_1TO3_TRIADS: 0.225\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, INCOMING_1TO3_TRIADS, OUTGOING_RECIPROCAL_TRIADS: 0.225\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, OUTGOING_3TO1_TRIADS, DIRECTED_CYCLE_1TO3_TRIADS, DIRECIPROCAL_2TO3_TRIADS: -0.281\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, UNIDIRECTIONAL_TRIADS, OUTGOING_3TO1_TRIADS, INCOMING_RECIPROCAL_TRIADS: -0.305\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS, DYADIC_TRIADS, INCOMING_1TO3_TRIADS, DIRECIPROCAL_TRIADS, DIRECIPROCAL_2TO3_TRIADS: -0.398\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS: -0.543\n",
      "PATH-NO_EDGE_TRIADS: -0.832\n",
      "\n",
      "Feature set: hyperconv-motif\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.6790\n",
      "Test accuracy: 0.5739\n",
      "\n",
      "TOP 5 FEATURES\n",
      "max[outdegree over C->c mid-thread responses]: 0.536\n",
      "max[outdegree over C->C mid-thread responses]: 0.536\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.418\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.418\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.417\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "entropy[outdegree over C->C responses]: -0.389\n",
      "NO_EDGE_TRIADS: -0.528\n",
      "max[indegree over C->C mid-thread responses]: -0.635\n",
      "SINGLE_EDGE_TRIADS: -0.681\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.725\n",
      "\n",
      "Feature set: hyperconv-paths\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.7190\n",
      "Test accuracy: 0.5739\n",
      "\n",
      "TOP 5 FEATURES\n",
      "max[outdegree over C->c mid-thread responses]: 0.608\n",
      "max[outdegree over C->C mid-thread responses]: 0.608\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.395\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.395\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.390\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "2nd-largest[outdegree over C->C mid-thread responses]: -0.457\n",
      "max[indegree over C->C mid-thread responses]: -0.585\n",
      "PATH-NO_EDGE_TRIADS, SINGLE_EDGE_TRIADS: -0.629\n",
      "PATH-NO_EDGE_TRIADS: -0.777\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.853\n",
      "\n",
      "Feature set: hyperconv-latent\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.6847\n",
      "Test accuracy: 0.5966\n",
      "\n",
      "TOP 5 FEATURES\n",
      "max[outdegree over C->c mid-thread responses]: 0.544\n",
      "max[outdegree over C->C mid-thread responses]: 0.544\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.473\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.473\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.399\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "entropy[outdegree over C->C responses]: -0.408\n",
      "LATENT_SINGLE_EDGE_TRIADS: -0.574\n",
      "max[indegree over C->C mid-thread responses]: -0.610\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.704\n",
      "LATENT_NO_EDGE_TRIADS: -0.909\n",
      "\n",
      "Feature set: hyperconvo-motifall\n",
      "Excluded 23 data point(s) that contained NaN values.\n",
      "Train accuracy: 0.7190\n",
      "Test accuracy: 0.5852\n",
      "\n",
      "TOP 5 FEATURES\n",
      "max[outdegree over C->c mid-thread responses]: 0.615\n",
      "max[outdegree over C->C mid-thread responses]: 0.615\n",
      "entropy[outdegree over C->c mid-thread responses]: 0.394\n",
      "entropy[outdegree over C->C mid-thread responses]: 0.394\n",
      "norm.2nd-largest[outdegree over C->c mid-thread responses]: 0.388\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "entropy[indegree over C->c mid-thread responses]: -0.425\n",
      "2nd-largest[outdegree over C->c mid-thread responses]: -0.455\n",
      "2nd-largest[outdegree over C->C mid-thread responses]: -0.455\n",
      "max[indegree over C->C mid-thread responses]: -0.577\n",
      "mean-nonzero[indegree over C->C mid-thread responses]: -0.853\n",
      "\n",
      "Feature set: usercount\n",
      "Train accuracy: 0.5958\n",
      "Test accuracy: 0.5389\n",
      "\n",
      "TOP 5 FEATURES\n",
      "num_users: -0.420\n",
      "\n",
      "BOTTOM 5 FEATURES\n",
      "num_users: -0.420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(2019)\n",
    "print(\"TASK: {}\\n\".format(\"Predicing if a thread is from r/news\"))\n",
    "    \n",
    "for feature_set, name in [(hyperconv_feat_names, \"hyperconvo\"),\n",
    "                    (hyperconv_feat_names + num_users_feat, \"hyperconv-usercount\"),\n",
    "                    (latent_motif_feat_names, \"latentmotif\"),\n",
    "                    (latent_motif_feat_names + num_users_feat, \"latentmotif-usercount\"),\n",
    "                    (path_feat_names, \"motifpaths\"),\n",
    "                    (path_feat_names + num_users_feat, \"motifpaths-usercount\"),\n",
    "                    (hyperconv_feat_names + motif_feat_names, \"hyperconv-motif\"),\n",
    "                    (hyperconv_feat_names + path_feat_names, \"hyperconv-paths\"),\n",
    "                    (hyperconv_feat_names + latent_motif_feat_names, \"hyperconv-latent\"),\n",
    "                    (hyperconv_feat_names + motif_feat_names + path_feat_names + latent_motif_feat_names, \"hyperconvo-motifall\"),\n",
    "                    (num_users_feat, \"usercount\")\n",
    "                   ]:\n",
    "    pp = PairedPrediction()\n",
    "    print(\"Feature set: {}\".format(name))\n",
    "    pp.fit_predict(feats_df[feature_set], pos_thread_ids, neg_thread_ids, test_size=0.2)\n",
    "    pp.print_extreme_coefs(feature_set, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative BoW paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_text = dict()\n",
    "for thread_id in thread_ids:\n",
    "    threads_text[thread_id] = {\"text\": \" \".join(utt.text for utt in thread_pfxs[thread_id].values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame.from_dict(threads_text, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "pos_neg_train, pos_neg_test = train_test_split(list(zip(pos_thread_ids, neg_thread_ids)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = [x[0] for x in pos_neg_train]\n",
    "neg_train = [x[1] for x in pos_neg_train] \n",
    "pos_test = [x[0] for x in pos_neg_test]\n",
    "neg_test = [x[1] for x in pos_neg_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_df = text_df.loc[pos_train + neg_train]\n",
    "test_text_df = text_df.loc[pos_test + neg_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=0.01, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>e3ka4ly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dzugzsa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d8vstww</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dfb128r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e8ho9zb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1838 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         000  06  10  100  11  12  13  14  15  16  ...  yesterday  yet  york  \\\n",
       "e3ka4ly    0   1   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "dzugzsa    0   0   0    0   0   0   0   2   0   0  ...          0    2     0   \n",
       "d8vstww    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "dfb128r    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "e8ho9zb    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "\n",
       "         young  your  yourself  youtu  youtube  yup  zero  \n",
       "e3ka4ly      0     1         0      0        0    0     0  \n",
       "dzugzsa      2     7         0      0        0    0     0  \n",
       "d8vstww      0     0         0      0        0    0     0  \n",
       "dfb128r      0     0         0      0        0    0     0  \n",
       "e8ho9zb      0     0         0      0        0    0     0  \n",
       "\n",
       "[5 rows x 1838 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_arr = cv.fit_transform(train_text_df['text'])\n",
    "train_text_transform_df = pd.DataFrame(train_text_arr.toarray(), columns=cv.get_feature_names(), index=train_text_df.index)\n",
    "train_text_transform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>do7v72z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dwyzf3e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dflvadr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dxxw1f7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cvl1059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1838 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         000  06  10  100  11  12  13  14  15  16  ...  yesterday  yet  york  \\\n",
       "do7v72z    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "dwyzf3e    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "dflvadr    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "dxxw1f7    0   0   0    0   0   0   0   0   0   0  ...          0    0     0   \n",
       "cvl1059    0   0   0    0   0   1   0   0   0   0  ...          0    0     0   \n",
       "\n",
       "         young  your  yourself  youtu  youtube  yup  zero  \n",
       "do7v72z      0     1         0      0        0    0     0  \n",
       "dwyzf3e      0     1         0      0        0    0     0  \n",
       "dflvadr      0     0         0      0        0    0     0  \n",
       "dxxw1f7      0     0         0      0        0    0     0  \n",
       "cvl1059      0     0         0      0        0    0     0  \n",
       "\n",
       "[5 rows x 1838 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_arr = cv.transform(test_text_df['text'])\n",
    "test_text_transform_df = pd.DataFrame(test_text_arr.toarray(), columns=cv.get_feature_names(), index=test_text_df.index)   \n",
    "test_text_transform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "def _generate_paired_X_y(feats: DataFrame, pos_ids, neg_ids):\n",
    "\n",
    "    X, y = [], []\n",
    "    flip = True\n",
    "\n",
    "    excluded = 0\n",
    "    for idx in range(len(pos_ids)):\n",
    "        pos_feats = np.array(feats.loc[pos_ids[idx]])\n",
    "        neg_feats = np.array(feats.loc[neg_ids[idx]])\n",
    "\n",
    "        if (np.isnan(pos_feats).any() or np.isnan(neg_feats).any()):\n",
    "            excluded += 1\n",
    "            continue\n",
    "\n",
    "        if flip:\n",
    "            y.append(1)\n",
    "            diff = pos_feats - neg_feats\n",
    "        else:\n",
    "            y.append(0)\n",
    "            diff = neg_feats - pos_feats\n",
    "\n",
    "        X.append(diff)\n",
    "        flip = not flip\n",
    "\n",
    "    if excluded > 0:\n",
    "        print(\"Excluded {} data point(s) that contained NaN values.\".format(excluded))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = _generate_paired_X_y(train_text_transform_df, pos_train, neg_train)\n",
    "X_test, y_test = _generate_paired_X_y(test_text_transform_df, pos_test, neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline([(\"standardScaler\", StandardScaler()), (\"logreg\", LogisticRegression(solver='liblinear'))])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- cumulative_bow: 1.0000 train, 0.7667 test\n"
     ]
    }
   ],
   "source": [
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "print(\"- {}: {:.4f} train, {:.4f} test\".format(\"cumulative_bow\", train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_extreme_coefs(clf, feature_names, num_features: int = 5):\n",
    "    coefs = clf.named_steps['logreg'].coef_[0].tolist()\n",
    "\n",
    "    assert len(feature_names) == len(coefs)\n",
    "\n",
    "    feats_coefs = sorted(list(zip(feature_names, coefs)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print()\n",
    "    print(\"TOP {} FEATURES\".format(num_features))\n",
    "    for ft, coef in feats_coefs[:num_features]:\n",
    "        print(\"{}: {:.3f}\".format(ft, coef))\n",
    "    print()\n",
    "    print(\"BOTTOM {} FEATURES\".format(num_features))\n",
    "    for ft, coef in feats_coefs[-num_features:]:\n",
    "        print(\"{}: {:.3f}\".format(ft, coef))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 20 FEATURES\n",
      "removed: 0.750\n",
      "wing: 0.343\n",
      "anything: 0.312\n",
      "assume: 0.272\n",
      "before: 0.262\n",
      "states: 0.258\n",
      "comes: 0.241\n",
      "reference: 0.237\n",
      "places: 0.232\n",
      "people: 0.230\n",
      "effect: 0.229\n",
      "doesn: 0.229\n",
      "worst: 0.225\n",
      "focus: 0.222\n",
      "ban: 0.216\n",
      "saudi: 0.216\n",
      "nonsense: 0.214\n",
      "children: 0.212\n",
      "blaming: 0.209\n",
      "fox: 0.207\n",
      "\n",
      "BOTTOM 20 FEATURES\n",
      "quite: -0.203\n",
      "total: -0.203\n",
      "created: -0.203\n",
      "please: -0.205\n",
      "uses: -0.208\n",
      "maga: -0.211\n",
      "win: -0.212\n",
      "sub: -0.215\n",
      "special: -0.222\n",
      "interview: -0.226\n",
      "white: -0.236\n",
      "now: -0.238\n",
      "holding: -0.241\n",
      "png: -0.242\n",
      "leaders: -0.244\n",
      "youtube: -0.244\n",
      "soros: -0.250\n",
      "kek: -0.281\n",
      "pede: -0.286\n",
      "cuck: -0.333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extreme_coefs(clf, cv.get_feature_names(), num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
